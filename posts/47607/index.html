<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>linux_system | 陌上花开缓缓归</title><meta name="description" content="###　操作系统　包括三部分:  cpu i&#x2F;o memory(内存)  (硬盘)DISK : 存放OS,还有一个bootloader小程序也在上边bootloader:主要功能用来加载OS的,能够让OS从硬盘加载到内存中去，然后让cpu执行操作系统．BIOS : 基本I&#x2F;O处理系统 BIOS准备BOIS在内存中的分布 空闲内存BOIS空闲内存 BIOS会从一个确定的地址开始执行  POST(加电"><meta name="keywords" content="linxu"><meta name="author" content="lys-studys"><meta name="copyright" content="lys-studys"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="shortcut icon" href="/img/timg.jpeg"><link rel="canonical" href="http://example.com/posts/47607/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta name="yandex-verification" content="{&quot;theme_color&quot;:{&quot;enable&quot;:true,&quot;main&quot;:&quot;#49B1F5&quot;,&quot;paginator&quot;:&quot;#00c4b6&quot;,&quot;button_hover&quot;:&quot;#FF7242&quot;,&quot;text_selection&quot;:&quot;#00c4b6&quot;,&quot;link_color&quot;:&quot;#99a9bf&quot;,&quot;meta_color&quot;:&quot;#858585&quot;,&quot;hr_color&quot;:&quot;#A4D8FA&quot;,&quot;code_foreground&quot;:&quot;#F47466&quot;,&quot;code_background&quot;:&quot;rgba(27, 31, 35, .05)&quot;,&quot;toc_color&quot;:&quot;#00c4b6&quot;,&quot;blockquote_padding_color&quot;:&quot;#49b1f5&quot;,&quot;blockquote_background_color&quot;:&quot;#49b1f5&quot;}}"/><meta property="og:type" content="article"><meta property="og:title" content="linux_system"><meta property="og:url" content="http://example.com/posts/47607/"><meta property="og:site_name" content="陌上花开缓缓归"><meta property="og:description" content="###　操作系统　包括三部分:  cpu i&#x2F;o memory(内存)  (硬盘)DISK : 存放OS,还有一个bootloader小程序也在上边bootloader:主要功能用来加载OS的,能够让OS从硬盘加载到内存中去，然后让cpu执行操作系统．BIOS : 基本I&#x2F;O处理系统 BIOS准备BOIS在内存中的分布 空闲内存BOIS空闲内存 BIOS会从一个确定的地址开始执行  POST(加电"><meta property="og:image" content="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg"><meta property="article:published_time" content="2020-11-10T06:09:26.000Z"><meta property="article:modified_time" content="2020-11-27T15:37:51.201Z"><meta name="twitter:card" content="summary"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css"><script>var GLOBAL_CONFIG = { 
  root: '/',
  hexoversion: '5.2.0',
  algolia: undefined,
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  bookmark: {
    message_prev: 'Press',
    message_next: 'to bookmark this page'
  },
  runtime: 'days',
  date_suffix: {"one_hour":"Just","hours":"hours ago","day":"days ago"},
  copyright: {"limitCount":50,"languages":{"author":"Author: lys-studys","link":"Link: ","source":"Source: 陌上花开缓缓归","info":"Copyright is owned by the author. For commercial reprints, please contact the author for authorization. For non-commercial reprints, please indicate the source."}},
  ClickShowText: {"text":"I,LOVE,YOU","fontSize":"15px"},
  medium_zoom: false,
  fancybox: true,
  Snackbar: {"bookmark":{"message_prev":"Press","message_next":"to bookmark this page"},"chs_to_cht":"Traditional Chinese Activated Manually","cht_to_chs":"Simplified Chinese Activated Manually","day_to_night":"Dark Mode Activated Manually","night_to_day":"Light Mode Activated Manually","bgLight":"#49b1f5","bgDark":"#121212","position":"bottom-left"},
  justifiedGallery: {
    js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
    css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
  },
  baiduPush: false,
  isPhotoFigcaption: true,
  islazyload: true,
  isanchor: false
};

var saveToLocal = {
  set: function setWithExpiry(key, value, ttl) {
    const now = new Date()
    const expiryDay = ttl * 86400000
    const item = {
      value: value,
      expiry: now.getTime() + expiryDay,
    }
    localStorage.setItem(key, JSON.stringify(item))
    },

  get: function getWithExpiry(key) {
    const itemStr = localStorage.getItem(key)

    if (!itemStr) {
      return undefined
    }
    const item = JSON.parse(itemStr)
    const now = new Date()

    if (now.getTime() > item.expiry) {
      localStorage.removeItem(key)
      return undefined
    }
    return item.value
  }
}</script><script id="config_change">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: true,
  isSidebar: true,
  postUpdate: '2020-11-27 23:37:51'
}</script><noscript><style type="text/css">
#nav {
  opacity: 1
}
.justified-gallery img {
  opacity: 1
}
</style></noscript><script>var activateDarkMode = function () {
  document.documentElement.setAttribute('data-theme', 'dark')
  if (document.querySelector('meta[name="theme-color"]') !== null) {
    document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
  }
}
var activateLightMode = function () {
  document.documentElement.setAttribute('data-theme', 'light')
  if (document.querySelector('meta[name="theme-color"]') !== null) {
    document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
  }
}

var autoChangeMode = 'true'
var t = saveToLocal.get('theme')
if (autoChangeMode === '1') {
  var isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
  var isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
  var isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
  var hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

  if (t === undefined) {
    if (isLightMode) activateLightMode()
    else if (isDarkMode) activateDarkMode()
    else if (isNotSpecified || hasNoSupport) {
      var now = new Date()
      var hour = now.getHours()
      var isNight = hour <= 6 || hour >= 18
      isNight ? activateDarkMode() : activateLightMode()
    }
    window.matchMedia('(prefers-color-scheme: dark)').addListener(function (e) {
      if (saveToLocal.get('theme') === undefined) {
        e.matches ? activateDarkMode() : activateLightMode()
      }
    })
  } else if (t === 'light') activateLightMode()
  else activateDarkMode()
} else if (autoChangeMode === '2') {
  now = new Date()
  hour = now.getHours()
  isNight = hour <= 6 || hour >= 18
  if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
  else if (t === 'light') activateLightMode()
  else activateDarkMode()
} else {
  if (t === 'dark') activateDarkMode()
  else if (t === 'light') activateLightMode()
}</script><link rel="stylesheet" href="./source/css/background.css"><meta name="generator" content="Hexo 5.2.0"><link rel="alternate" href="/atom.xml" title="陌上花开缓缓归" type="application/atom+xml">
</head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">Loading...</div></div></div><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" data-lazy-src="/img/avatar.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">Articles</div><div class="length_num">63</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">Tags</div><div class="length_num">27</div></a></div></div><div class="mobile_data_item is-center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">Categories</div><div class="length_num">23</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> List</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/music/"><i class="fa-fw fas fa-music"></i><span> Music</span></a></li><li><a class="site-page" href="/movies/"><i class="fa-fw fas fa-video"></i><span> Movie</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/messageboard/"><i class="fa-fw fa fa-paper-plane"></i><span> message</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div></div></div><div id="body-wrap"><div id="web_bg" data-type="photo"></div><div id="sidebar"><i class="fas fa-arrow-right on" id="toggle-sidebar"></i><div class="sidebar-toc"><div class="sidebar-toc__title">Catalog</div><div class="sidebar-toc__progress"><span class="progress-notice">You've read</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-4"><a class="toc-link" href="#BIOS%E5%87%86%E5%A4%87"><span class="toc-number">1.</span> <span class="toc-text">BIOS准备</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8A%A0%E8%BD%BDbootloader"><span class="toc-number">2.</span> <span class="toc-text">加载bootloader</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E4%B8%8E%E8%AE%BE%E5%A4%87%E5%92%8C%E7%A8%8B%E5%BA%8F%E4%BA%A4%E4%BA%92"><span class="toc-number">3.</span> <span class="toc-text">操作系统与设备和程序交互</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-%E5%86%85%E5%AD%98%E5%88%86%E5%B1%82%E4%BD%93%E7%B3%BB"><span class="toc-number">4.</span> <span class="toc-text">计算机体系结构&#x2F;内存分层体系</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84"><span class="toc-number">4.1.</span> <span class="toc-text">计算机体系结构</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%9C%A8%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E4%B8%AD%E7%AE%A1%E7%90%86%E5%86%85%E5%AD%98%E7%9A%84%E4%B8%8D%E5%90%8C%E6%96%B9%E6%B3%95"><span class="toc-number">4.2.</span> <span class="toc-text">在操作系统中管理内存的不同方法</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%AE%9E%E7%8E%B0%E9%AB%98%E5%BA%A6%E4%BE%9D%E8%B5%96%E4%B8%8E%E7%A1%AC%E4%BB%B6"><span class="toc-number">4.3.</span> <span class="toc-text">实现高度依赖与硬件</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9C%B0%E5%9D%80%E7%A9%BA%E9%97%B4-amp-%E5%9C%B0%E5%9D%80%E7%94%9F%E6%88%90"><span class="toc-number">5.</span> <span class="toc-text">地址空间&amp;地址生成</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E9%80%BB%E8%BE%91%E5%9C%B0%E5%9D%80%E7%94%9F%E6%88%90"><span class="toc-number">5.1.</span> <span class="toc-text">逻辑地址生成</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E7%89%A9%E7%90%86%E5%9C%B0%E5%9D%80%E7%94%9F%E6%88%90"><span class="toc-number">5.2.</span> <span class="toc-text">物理地址生成</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8%E5%86%85%E5%AD%98%E7%9A%84%E7%BA%A6%E6%9D%9F"><span class="toc-number">5.3.</span> <span class="toc-text">线程安全内存的约束</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%BF%9E%E7%BB%AD%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D"><span class="toc-number">5.4.</span> <span class="toc-text">连续内存分配</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#%E5%86%85%E5%AD%98%E7%A2%8E%E7%89%87%E9%97%AE%E9%A2%98"><span class="toc-number">5.4.1.</span> <span class="toc-text">内存碎片问题</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#%E5%88%86%E5%8C%BA%E7%9A%84%E5%8A%A8%E6%80%81%E5%88%86%E9%85%8D"><span class="toc-number">5.4.2.</span> <span class="toc-text">分区的动态分配</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#%E5%8E%8B%E7%BC%A9%E5%BC%8F%E7%A2%8E%E7%89%87%E6%95%B4%E7%90%86"><span class="toc-number">5.4.3.</span> <span class="toc-text">压缩式碎片整理</span></a></li></ol></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%9D%9E%E8%BF%9E%E7%BB%AD%E5%86%85%E5%AD%98%E7%9A%84%E5%88%86%E9%85%8D-%E5%88%86%E6%AE%B5"><span class="toc-number">6.</span> <span class="toc-text">非连续内存的分配-分段</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%9D%9E%E8%BF%9E%E7%BB%AD%E5%86%85%E5%AD%98%E7%9A%84%E5%88%86%E9%85%8D-%E5%88%86%E9%A1%B5"><span class="toc-number">7.</span> <span class="toc-text">非连续内存的分配-分页</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%9D%9E%E8%BF%9E%E7%BB%AD%E5%86%85%E5%AD%98%E7%9A%84%E5%88%86%E9%85%8D-%E9%A1%B5%E8%A1%A8%E6%A6%82%E8%BF%B0"><span class="toc-number">8.</span> <span class="toc-text">非连续内存的分配-页表概述</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%9D%9E%E8%BF%9E%E7%BB%AD%E5%86%85%E5%AD%98%E7%9A%84%E5%88%86%E9%85%8D-%E9%A1%B5%E8%A1%A8%EF%BC%8D%E4%BA%8C%E7%BA%A7%E5%A4%9A%E7%BA%A7%E9%A1%B5%E8%A1%A8"><span class="toc-number">9.</span> <span class="toc-text">非连续内存的分配-页表－二级多级页表</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%9D%9E%E8%BF%9E%E7%BB%AD%E5%86%85%E5%AD%98%E7%9A%84%E5%88%86%E9%85%8D-%E9%A1%B5%E8%A1%A8%E5%8F%8D%E5%90%91%E9%A1%B5%E8%A1%A8"><span class="toc-number">10.</span> <span class="toc-text">非连续内存的分配-页表反向页表</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98%E7%9A%84%E8%B5%B7%E5%9B%A0"><span class="toc-number">11.</span> <span class="toc-text">虚拟内存的起因</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%A6%86%E7%9B%96%E6%8A%80%E6%9C%AF"><span class="toc-number">12.</span> <span class="toc-text">覆盖技术</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BA%A4%E6%8D%A2%E6%8A%80%E6%9C%AF"><span class="toc-number">13.</span> <span class="toc-text">交换技术</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%A6%86%E7%9B%96%E5%92%8C%E4%BA%A4%E6%8D%A2%E6%8A%80%E6%9C%AF%E7%9A%84%E6%AF%94%E8%BE%83"><span class="toc-number">13.1.</span> <span class="toc-text">覆盖和交换技术的比较</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%99%9A%E6%8B%9F%E6%8A%80%E6%9C%AF-%E4%B8%8A"><span class="toc-number">14.</span> <span class="toc-text">虚拟技术(上)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%A1%B5%E9%9D%A2%E7%BD%AE%E6%8D%A2%E7%AE%97%E6%B3%95"><span class="toc-number">15.</span> <span class="toc-text">页面置换算法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9C%80%E4%BC%98%E9%A1%B5%E9%9D%A2%E7%BD%AE%E6%8D%A2%E7%AE%97%E6%B3%95"><span class="toc-number">16.</span> <span class="toc-text">最优页面置换算法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%85%88%E8%BF%9B%E5%85%88%E5%87%BA%E7%AE%97%E6%B3%95-FIFO"><span class="toc-number">17.</span> <span class="toc-text">先进先出算法(FIFO)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9C%80%E8%BF%91%E6%9C%80%E4%B9%85%E6%9C%AA%E4%BD%BF%E7%94%A8%E7%AE%97%E6%B3%95"><span class="toc-number">18.</span> <span class="toc-text">最近最久未使用算法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%97%B6%E9%92%9F%E9%A1%B5%E9%9D%A2%E7%BD%AE%E6%8D%A2%E7%AE%97%E6%B3%95"><span class="toc-number">19.</span> <span class="toc-text">时钟页面置换算法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BA%8C%E6%AC%A1-%E6%9C%BA%E4%BC%9A-%E8%BF%9B%E4%BD%8D%E6%B3%95"><span class="toc-number">20.</span> <span class="toc-text">二次(机会)进位法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9C%80%E4%B8%8D%E5%B8%B8%E7%94%A8%E6%B3%95-Least-Frequently-Used-LFU"><span class="toc-number">21.</span> <span class="toc-text">最不常用法(Least Frequently Used LFU)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Belady%E7%8E%B0%E8%B1%A1%EF%BC%8CLRU-FIFO"><span class="toc-number">22.</span> <span class="toc-text">Belady现象，LRU,FIFO</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%B1%80%E9%83%A8%E9%A1%B5%E6%9B%BF%E6%8D%A2%E7%AE%97%E6%B3%95%E7%9A%84%E9%97%AE%E9%A2%98"><span class="toc-number">23.</span> <span class="toc-text">局部页替换算法的问题</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%A4%E4%B8%AA%E5%85%A8%E5%B1%80%E7%BD%AE%E6%8D%A2%E7%AE%97%E6%B3%95"><span class="toc-number">24.</span> <span class="toc-text">两个全局置换算法</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%B7%A5%E4%BD%9C%E9%9B%86%E9%A1%B5%E7%BD%AE%E6%8D%A2%E7%AE%97%E6%B3%95"><span class="toc-number">24.1.</span> <span class="toc-text">工作集页置换算法</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E7%BC%BA%E9%A1%B5%E7%8E%87%E9%A1%B5%E9%9D%A2%E7%BD%AE%E6%8D%A2%E7%AE%97%E6%B3%95"><span class="toc-number">24.2.</span> <span class="toc-text">缺页率页面置换算法</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%8A%96%E5%8A%A8%E9%97%AE%E9%A2%98"><span class="toc-number">25.</span> <span class="toc-text">抖动问题</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%BF%9B%E7%A8%8B%E7%9A%84%E5%AE%9A%E4%B9%89"><span class="toc-number">26.</span> <span class="toc-text">进程的定义</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%BF%9B%E7%A8%8B%E7%9A%84%E7%BB%84%E6%88%90"><span class="toc-number">27.</span> <span class="toc-text">进程的组成</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%BF%9B%E7%A8%8B%E7%9A%84%E7%89%B9%E7%82%B9"><span class="toc-number">28.</span> <span class="toc-text">进程的特点</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%BF%9B%E7%A8%8B%E6%8E%A7%E5%88%B6%E7%BB%93%E6%9E%84"><span class="toc-number">29.</span> <span class="toc-text">进程控制结构</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%BF%9B%E7%A8%8B%E7%9A%84%E7%94%9F%E5%91%BD%E6%9C%9F%E5%8E%9F%E7%90%86"><span class="toc-number">30.</span> <span class="toc-text">进程的生命期原理</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%BF%9B%E7%A8%8B%E7%8A%B6%E6%80%81%E5%8F%98%E5%8C%96%E6%A8%A1%E5%9E%8B"><span class="toc-number">31.</span> <span class="toc-text">进程状态变化模型</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%BF%9B%E7%A8%8B%E6%8C%82%E8%B5%B7"><span class="toc-number">32.</span> <span class="toc-text">进程挂起</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BD%BF%E7%94%A8%E7%BA%BF%E7%A8%8B"><span class="toc-number">33.</span> <span class="toc-text">为什么使用线程</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E7%BA%BF%E7%A8%8B"><span class="toc-number">34.</span> <span class="toc-text">什么是线程</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%AE%9E%E7%8E%B0"><span class="toc-number">35.</span> <span class="toc-text">线程的实现</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%8A%E4%B8%8B%E6%96%87%E5%88%87%E6%8D%A2"><span class="toc-number">36.</span> <span class="toc-text">上下文切换</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%BF%9B%E7%A8%8B%E6%8E%A7%E5%88%B6-%E5%88%9B%E5%BB%BA%E8%BF%9B%E7%A8%8B"><span class="toc-number">37.</span> <span class="toc-text">进程控制-创建进程</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%BF%9B%E7%A8%8B%E6%8E%A7%E5%88%B6-%E5%8A%A0%E8%BD%BD%E5%92%8C%E6%89%A7%E8%A1%8C%E8%BF%9B%E7%A8%8B"><span class="toc-number">38.</span> <span class="toc-text">进程控制-加载和执行进程</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%BF%9B%E7%A8%8B%E6%8E%A7%E5%88%B6-%E7%AD%89%E5%BE%85%E5%92%8C%E7%BB%88%E6%AD%A2%E8%BF%9B%E7%A8%8B"><span class="toc-number">39.</span> <span class="toc-text">进程控制-等待和终止进程</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%83%8C%E6%99%AF"><span class="toc-number">40.</span> <span class="toc-text">背景</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%B0%83%E5%BA%A6%E5%8E%9F%E5%88%99"><span class="toc-number">41.</span> <span class="toc-text">调度原则</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%951"><span class="toc-number">42.</span> <span class="toc-text">调度算法1</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%952"><span class="toc-number">43.</span> <span class="toc-text">调度算法2</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%9E%E6%97%B6%E8%B0%83%E5%BA%A6"><span class="toc-number">44.</span> <span class="toc-text">实时调度</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%A4%9A%E5%A4%84%E7%90%86%E5%99%A8%E8%B0%83%E5%BA%A6%E4%B8%8E%E4%BC%98%E5%85%88%E7%BA%A7%E5%8F%8D%E8%BD%AC"><span class="toc-number">45.</span> <span class="toc-text">多处理器调度与优先级反转</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%83%8C%E6%99%AF%E7%9F%A5%E8%AF%86"><span class="toc-number">46.</span> <span class="toc-text">背景知识</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%B8%80%E4%BA%9B%E6%A6%82%E5%BF%B5part1"><span class="toc-number">46.1.</span> <span class="toc-text">一些概念part1</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%B8%80%E4%BA%9B%E6%A6%82%E5%BF%B5part2"><span class="toc-number">46.2.</span> <span class="toc-text">一些概念part2</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%B8%80%E4%BA%9B%E6%A6%82%E5%BF%B5part3"><span class="toc-number">46.3.</span> <span class="toc-text">一些概念part3</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%B4%E7%95%8C%E5%8C%BA"><span class="toc-number">47.</span> <span class="toc-text">临界区</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%96%B9%E6%B3%951-%E7%A6%81%E7%94%A8%E7%A1%AC%E4%BB%B6%E4%B8%AD%E6%96%AD"><span class="toc-number">47.1.</span> <span class="toc-text">方法1: 禁用硬件中断</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%96%B9%E6%B3%952-%E5%9F%BA%E4%BA%8E%E8%BD%AF%E4%BB%B6%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88"><span class="toc-number">47.2.</span> <span class="toc-text">方法2:　基于软件的解决方案</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%96%B9%E6%B3%953-%E6%9B%B4%E9%AB%98%E7%BA%A7%E7%9A%84%E6%8A%BD%E8%B1%A1%EF%BC%88%E5%9F%BA%E4%BA%8E%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C%E7%9A%84%E6%8C%87%E4%BB%A4%EF%BC%89"><span class="toc-number">47.3.</span> <span class="toc-text">方法3:　更高级的抽象（基于原子操作的指令）</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%83%8C%E6%99%AF%E7%9F%A5%E8%AF%86-1"><span class="toc-number">48.</span> <span class="toc-text">背景知识</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BF%A1%E5%8F%B7%E9%87%8F"><span class="toc-number">49.</span> <span class="toc-text">信号量</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%BF%A1%E5%8F%B7%E9%87%8F%E7%9A%84%E4%BD%BF%E7%94%A8"><span class="toc-number">49.1.</span> <span class="toc-text">信号量的使用</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%BF%A1%E5%8F%B7%E9%87%8F%E7%9A%84%E5%AE%9E%E7%8E%B0"><span class="toc-number">49.2.</span> <span class="toc-text">信号量的实现</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%AE%A1%E7%A8%8B"><span class="toc-number">50.</span> <span class="toc-text">管程</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%BB%8F%E5%85%B8%E5%90%8C%E6%AD%A5%E9%97%AE%E9%A2%98"><span class="toc-number">51.</span> <span class="toc-text">经典同步问题</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E7%BB%8F%E5%85%B8%E5%90%8C%E6%AD%A5%E9%97%AE%E9%A2%981"><span class="toc-number">51.1.</span> <span class="toc-text">经典同步问题1</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E7%BB%8F%E5%85%B8%E5%90%8C%E6%AD%A5%E9%97%AE%E9%A2%982"><span class="toc-number">51.2.</span> <span class="toc-text">经典同步问题2</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E7%BB%8F%E5%85%B8%E5%90%8C%E6%AD%A5%E9%97%AE%E9%A2%983"><span class="toc-number">51.3.</span> <span class="toc-text">经典同步问题3</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E7%BB%8F%E5%85%B8%E5%90%8C%E6%AD%A5%E9%97%AE%E9%A2%984"><span class="toc-number">51.4.</span> <span class="toc-text">经典同步问题4</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E7%BB%8F%E5%85%B8%E5%90%8C%E6%AD%A5%E9%97%AE%E9%A2%985"><span class="toc-number">51.5.</span> <span class="toc-text">经典同步问题5</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E7%BB%8F%E5%85%B8%E5%90%8C%E6%AD%A5%E9%97%AE%E9%A2%986"><span class="toc-number">51.6.</span> <span class="toc-text">经典同步问题6</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%AD%BB%E9%94%81%E9%97%AE%E9%A2%98"><span class="toc-number">52.</span> <span class="toc-text">死锁问题</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%B3%BB%E7%BB%9F%E6%A8%A1%E5%9E%8B"><span class="toc-number">53.</span> <span class="toc-text">系统模型</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%AD%BB%E9%94%81%E7%89%B9%E5%BE%81"><span class="toc-number">54.</span> <span class="toc-text">死锁特征</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%AD%BB%E9%94%81%E5%A4%84%E7%90%86%E5%8A%9E%E6%B3%95"><span class="toc-number">55.</span> <span class="toc-text">死锁处理办法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%AD%BB%E9%94%81%E9%A2%84%E9%98%B2%E5%92%8C%E6%AD%BB%E9%94%81%E9%81%BF%E5%85%8D"><span class="toc-number">56.</span> <span class="toc-text">死锁预防和死锁避免</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%93%B6%E8%A1%8C%E5%AE%B6%E7%AE%97%E6%B3%95"><span class="toc-number">57.</span> <span class="toc-text">银行家算法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%AD%BB%E9%94%81%E6%A3%80%E6%B5%8B%E5%92%8C%E6%AD%BB%E9%94%81%E6%81%A2%E5%A4%8D"><span class="toc-number">58.</span> <span class="toc-text">死锁检测和死锁恢复</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#IPC%E6%A6%82%E8%BF%B0"><span class="toc-number">59.</span> <span class="toc-text">IPC概述</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BF%A1%E5%8F%B7%E7%AE%A1%E9%81%93%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E5%92%8C%E5%85%B1%E4%BA%AB%E5%86%85%E5%AD%98"><span class="toc-number">60.</span> <span class="toc-text">信号管道消息队列和共享内存</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%BF%A1%E5%8F%B7-%E8%BD%BB%E9%87%8F%E6%9C%BA%E5%88%B6"><span class="toc-number">60.1.</span> <span class="toc-text">信号(轻量机制)</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E7%AE%A1%E9%81%93"><span class="toc-number">60.2.</span> <span class="toc-text">管道</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97"><span class="toc-number">60.3.</span> <span class="toc-text">消息队列</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%85%B1%E4%BA%AB%E5%86%85%E5%AD%98"><span class="toc-number">60.4.</span> <span class="toc-text">共享内存</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%BF%98%E6%9C%89%E4%B8%80%E7%A7%8D%E9%80%9A%E4%BF%A1%E6%9C%BA%E5%88%B6-socket"><span class="toc-number">60.5.</span> <span class="toc-text">还有一种通信机制 socket()</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%EF%BC%8E"><span class="toc-number">61.</span> <span class="toc-text">文件系统．</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5-%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%92%8C%E6%96%87%E4%BB%B6"><span class="toc-number">61.1.</span> <span class="toc-text">基本概念-文件系统和文件</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5-%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%8A%9F%E8%83%BD"><span class="toc-number">61.2.</span> <span class="toc-text">基本概念-文件系统的功能</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5-%E6%96%87%E4%BB%B6%E5%92%8C%E5%9D%97"><span class="toc-number">61.3.</span> <span class="toc-text">基本概念-文件和块</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5-%E6%96%87%E4%BB%B6%E6%8F%8F%E8%BF%B0%E7%AC%A6"><span class="toc-number">61.4.</span> <span class="toc-text">基本概念-文件描述符</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5-%E7%9B%AE%E5%BD%95"><span class="toc-number">61.5.</span> <span class="toc-text">基本概念-目录</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%9F%BA%E6%9C%AC%E7%9B%AE%E5%BD%95-%E6%96%87%E4%BB%B6%E5%88%AB%E5%90%8D"><span class="toc-number">61.6.</span> <span class="toc-text">基本目录-文件别名</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%9F%BA%E6%9C%AC%E7%9B%AE%E5%BD%95-%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%A7%8D%E7%B1%BB"><span class="toc-number">61.7.</span> <span class="toc-text">基本目录-文件系统种类</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%99%9A%E6%8B%9F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F"><span class="toc-number">61.8.</span> <span class="toc-text">虚拟文件系统</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E7%BC%93%E5%AD%98"><span class="toc-number">61.9.</span> <span class="toc-text">数据缓存</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%89%93%E5%BC%80%E6%96%87%E4%BB%B6%E7%9A%84%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84"><span class="toc-number">61.10.</span> <span class="toc-text">打开文件的数据结构</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%96%87%E4%BB%B6%E5%88%86%E9%85%8D"><span class="toc-number">61.11.</span> <span class="toc-text">文件分配</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E7%A9%BA%E9%97%B2%E7%A9%BA%E9%97%B4%E5%88%97%E8%A1%A8"><span class="toc-number">61.12.</span> <span class="toc-text">空闲空间列表</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%A4%9A%E7%A3%81%E7%9B%98%E7%AE%A1%E7%90%86-RAID"><span class="toc-number">61.13.</span> <span class="toc-text">多磁盘管理-RAID</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E7%A3%81%E7%9B%98%E8%B0%83%E5%BA%A6"><span class="toc-number">61.14.</span> <span class="toc-text">磁盘调度</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%9C%B0%E5%9D%80%E5%AE%89%E5%85%A8%E6%A3%80%E6%9F%A5"><span class="toc-number">61.15.</span> <span class="toc-text">地址安全检查</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%86%85%E5%AD%98%E5%88%86%E5%B1%82%E4%BD%93%E7%B3%BB"><span class="toc-number">61.16.</span> <span class="toc-text">内存分层体系</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%9C%A8%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E8%8C%83%E4%BE%8B"><span class="toc-number">61.17.</span> <span class="toc-text">在操作系统的内存管理范例</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link"><span class="toc-number">62.</span> <span class="toc-text"></span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#-1"><span class="toc-number">63.</span> <span class="toc-text"></span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#-2"><span class="toc-number">64.</span> <span class="toc-text"></span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#-3"><span class="toc-number">65.</span> <span class="toc-text"></span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86-%E5%88%86%E9%A1%B5%E5%92%8C%E5%88%86%E6%AE%B5%E7%9A%84%E5%8C%BA%E5%88%AB"><span class="toc-number"></span> <span class="toc-text">操作系统的内存管理, 分页和分段的区别</span></a></div></div></div><header class="post-bg" id="page-header" style="background-image: url(https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg)"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">陌上花开缓缓归</a></span><span id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> List</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/music/"><i class="fa-fw fas fa-music"></i><span> Music</span></a></li><li><a class="site-page" href="/movies/"><i class="fa-fw fas fa-video"></i><span> Movie</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/messageboard/"><i class="fa-fw fa fa-paper-plane"></i><span> message</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div><span class="close" id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></span></span></nav><div id="post-info"><div id="post-title"><div class="posttitle">linux_system</div></div><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2020-11-10T06:09:26.000Z" title="Created 2020-11-10 14:09:26">2020-11-10</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2020-11-27T15:37:51.201Z" title="Updated 2020-11-27 23:37:51">2020-11-27</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/linux/">linux</a></span></div><div class="meta-secondline"> <span class="post-meta-separator">|</span><span class="post-meta-pv-cv"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post View:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout_post" id="content-inner"><article id="post"><div class="post-content" id="article-container"><p>###　操作系统　<br>包括三部分:</p>
<ol>
<li>cpu</li>
<li>i/o</li>
<li>memory(内存)</li>
</ol>
<p>(硬盘)DISK : 存放OS,还有一个bootloader小程序也在上边<br>bootloader:主要功能用来加载OS的,能够让OS从硬盘加载到内存中去，然后让cpu执行操作系统．<br>BIOS : 基本I/O处理系统</p>
<h4 id="BIOS准备"><a href="#BIOS准备" class="headerlink" title="BIOS准备"></a>BIOS准备</h4><p>BOIS在内存中的分布</p>
<p>空闲内存<br>BOIS<br>空闲内存</p>
<p>BIOS会从一个确定的地址开始执行</p>
<ol>
<li>POST(加电自检)</li>
<li>寻找显卡和执行BIOS.</li>
</ol>
<h4 id="加载bootloader"><a href="#加载bootloader" class="headerlink" title="加载bootloader"></a>加载bootloader</h4><p>开启时　DISK(硬盘)包括 bootloader程序, os两部分.<br>bootloader程序一般为位于硬盘第一个主引导扇区．512个字节.<br>bootloader程序目的是为了把os放到内存中去．（OS为操作系统）</p>
<p>以X386为例:</p>
<p>BOIS:<br>    1. 将bootloader从磁盘的引导扇区(512字节)加载到0x7c00<br>    2. 跳转到　CS:IP = 0000:7c00 (这个地址是确定的)<br>bootloader:<br>    1. 将操作系统的代码和数据从鹰牌加载到内存中．<br>    2. 跳转到操作系统起始位置执行．（把操作系统的权限交给了OS）<br>到此硬件设备检测完毕,有操作系统来执行程序分配资源等操作.</p>
<h4 id="操作系统与设备和程序交互"><a href="#操作系统与设备和程序交互" class="headerlink" title="操作系统与设备和程序交互"></a>操作系统与设备和程序交互</h4><p>interface(接口):包括三部分<br>面向应用程序：</p>
<ol>
<li>系统调用: 应用程序主动向操作系统发出服务请求.</li>
<li>异常: 非法指令或者其他坏的处理状态(如:内存出错)(不良的应用程序产生的)</li>
</ol>
<p>面向硬件(外设):<br>3. 中断: 来自不同的硬件设备的计时器和网络中断.</p>
<p>为什么应用程序不能直接访问外设呢？</p>
<p>操作系统跟其他软件不同的地方在于，OS对操作系统有一定的控制权，能执行特权指令，是一个可信任的软件．<br>安全方面: 如果程序可以直接访问外设，可造成整个计算机系统的直接崩溃．<br>简单方面：操作系统为上层应用提供一个通用接口，可以是程序不用关注底层的运行，使得程序变得通用，可移植．</p>
<p>基于这两个方面设计了　system core, exception,interupt;</p>
<p>操作系统如何设计和实现中断，异常，和系统调用？</p>
<p>他们三者有什么区别和特点?<br>源头：</p>
<ol>
<li>中断： 外设</li>
<li>异常:　应用程序意想不到的行为</li>
<li>系统调用:　应用程序请求操作提供服务．<br>处理时间:　异步和同步指的是时间点.<ol>
<li>中断: 异步(事件),当这个中断产生的时候，应用程序并不知道会产生．</li>
<li>异常: 同步.（执行到某个指令或者别的一定会产生的事件）</li>
<li>系统调用: 异常或同步.<br>操作系统同步：就是发送一个请求，等待反馈（同步是可预测的）<br>操作系统异步：就是发送一个请求，就去做别的事情去了．返回一个消息这个事情做完了．（异步是不可预测的）<br>响应：<br>　　1. 中断: 持续，对用户应用程序是透明的．(应用程序感觉不到中断产生)</li>
<li>异常:杀死或者重新执行意想不到的应用程序指令.(严重的将杀死进程，其他的程序未响应等会重新执行．)</li>
<li>系统调用:等待和持续．(等待服务完成之后继续执行，不会重复执行产生系统调用的指令)．</li>
</ol>
</li>
</ol>
<h4 id="计算机体系结构-内存分层体系"><a href="#计算机体系结构-内存分层体系" class="headerlink" title="计算机体系结构/内存分层体系"></a>计算机体系结构/内存分层体系</h4><p>OS对操作系统首先控制的就是内存<br>操作系统如何管理物理内存:</p>
<h5 id="计算机体系结构"><a href="#计算机体系结构" class="headerlink" title="计算机体系结构"></a>计算机体系结构</h5><p>图：计算机体系结构<br>图: 内存的层次结构<br>缓存为cache包含l1和l2,<br>主存(物理内存)中放置：操作系统本身以及要运行的代码.掉电数据消失.<br>所以说需要永久保存的数据需要放在硬盘中．加电之后可以把数据从硬盘读到内存中来．</p>
<p>图: 操作系统对内存管理</p>
<ol>
<li>抽象:<br> 逻辑地址空间(底层提供的供程序用的连续的物理空间，不用考虑物理空间什么地方)</li>
<li>保护:<br> 独立地址空间(保护进程间的内存是独立的)</li>
<li>共享<br> 访问相同内存（进程间的交互）</li>
<li>虚拟化<br> 更多的地址空间（解决内存不够的情况，把最需要访问的数据放入内存，不太需要的放到硬盘上去）</li>
</ol>
<p>图中表示p1,p2,p3,p4四个应用程序续，p4可能处于等待状态，所以放入磁盘中，其他的在主存中排队.</p>
<h5 id="在操作系统中管理内存的不同方法"><a href="#在操作系统中管理内存的不同方法" class="headerlink" title="在操作系统中管理内存的不同方法"></a>在操作系统中管理内存的不同方法</h5><ol>
<li>程序重定位</li>
<li>分段</li>
<li>分页</li>
<li>虚拟内存</li>
<li>按需分页虚拟内存</li>
</ol>
<p>除了OS对内存管理还要对硬件管理,如下:</p>
<h5 id="实现高度依赖与硬件"><a href="#实现高度依赖与硬件" class="headerlink" title="实现高度依赖与硬件"></a>实现高度依赖与硬件</h5><ol>
<li>必须知道内存架构</li>
<li>MMU(内存管理单元):硬件组件负责处理CPU的内存访问请求.<h4 id="地址空间-amp-地址生成"><a href="#地址空间-amp-地址生成" class="headerlink" title="地址空间&amp;地址生成"></a>地址空间&amp;地址生成</h4>图:地址空间<br>物理地址空间:<br> 硬件支持的地址空间(主存和硬盘表示物理空间)<br> 主要靠硬件控制管理．<br>逻辑地址空间:<br> 一个运行的程序所拥有的内存范围</li>
</ol>
<p>逻辑地址空间是一个一维度的，它对应着一个物理空间（可能在主存也可能在硬盘），映射关系靠操作系统管理．</p>
<h5 id="逻辑地址生成"><a href="#逻辑地址生成" class="headerlink" title="逻辑地址生成"></a>逻辑地址生成</h5><p>图:逻辑地址生成<br>变量的名字就是一种逻辑地址．人为的实现的．<br>一个大程序可能有好多个小程序组成的，小程序组成的过程中，会使得不同程序间的地址相互访问，形成一个非常复杂的依赖关系？<br>通过link应用程序，把他们连在一起，构成一个统一的程序，比如图中的.exe file,他是一个可以在内存中执行，目前存在硬盘上的程序．不同的.io程序，在一个程序中访问的地址，有自己相关的定义．这个定义还不在内存中，还需要lowder应用程序硬盘中的程序，放到内存中执行．这样完成一个逻辑地址在内存中的分配，使程序可以正常的跑．看到这里基本不需要操作系统，只需要通过应用程序就可以完成这些操作．虽然放到了内存中但是他还是逻辑地址，不是物理地址，只是程序能看到这个地址．</p>
<h5 id="物理地址生成"><a href="#物理地址生成" class="headerlink" title="物理地址生成"></a>物理地址生成</h5><p>图: 物理地址生成</p>
<p>逻辑地址如何对应到对应的物理空间中去.</p>
<p>执行一条指令<br> cpu需要把指令从内存中取出来，cpu中有一个能查询逻辑地址和物理地址对应关系的MMU. MMU在内存中有一个相对应的位置，如图蓝色位置所示.查表可以知道逻辑地址对应物理地址在的位置，就可以让硬件把数据在物理内存中把数据取过来．</p>
<p>执行过程:</p>
<ol>
<li>当cpu执行某条指令的时候，他的ALU部件会需要这个指令的内容请求，带的参数是逻辑地址．</li>
<li>cpu中的MMU会查询这个逻辑地址的映射表，如果有ok，如果没有会产生一个处理过程，去内存中的map去找．如果找到了cpu的控制器会给主存发送一个请求我需要某一个物理地址的内容，（就是那条指令的内容）</li>
<li>主存会通过总线把内容传给CPU,cpu拿到这条指令后，cpu就开始对这条指令执行了．\</li>
</ol>
<p>操作系统起的作用：在完成这三步之前把这个映射关系建立好(逻辑地址到物理地址的映射关系)，这个关系可以放到内存中由cpu进行缓存，加快访问的过程，</p>
<h5 id="线程安全内存的约束"><a href="#线程安全内存的约束" class="headerlink" title="线程安全内存的约束"></a>线程安全内存的约束</h5><p>图:线程安全内存的约束<br>操作系统会保证每个程序有效访问的地址空间，主要包括起始地址,和长度.可以来确定在这块内存中程序访问是合理，一旦超出这个区域，访问变成不合法的访问，这个表也是操作系统建立和维护的，一旦cpu要执行某条指令的时候，他就会查这个map,来判断程序访问的逻辑地址是否满足该区域的限制，如果满足，就会根据映射关系把数据或者指令取回来，一旦不满足cpu就会产生一个memory异常，就是内存访问异常,从而让操作系统进一步处理．这就是地址的安全检查安全检测的过程，</p>
<h5 id="连续内存分配"><a href="#连续内存分配" class="headerlink" title="连续内存分配"></a>连续内存分配</h5><h6 id="内存碎片问题"><a href="#内存碎片问题" class="headerlink" title="内存碎片问题"></a>内存碎片问题</h6><p>图:内存碎片问题<br>内存空间不能被利用．<br>外部碎片:在分配单元间的未使用的内存<br>内部碎片:在分配单元中的为使用内存.</p>
<h6 id="分区的动态分配"><a href="#分区的动态分配" class="headerlink" title="分区的动态分配"></a>分区的动态分配</h6><p>图：分区的动态分配．<br>简单的内存管理方法:<br>    1. 当一个程序准许运行在内存中时，分配一个连续的分区．<br>    2. 分配一个连续的内存区间给运行的程序以访问数据．</p>
<p>分配策略:</p>
<ol>
<li>第一适配<br>图:第一匹配分配<br>为了分配n字节,使用第一个可用空闲块以致块的尺寸比n大．<br>简单实现:<br>需求:<ol>
<li>按地址排序的空闲块列表</li>
<li>分配需要一个合适的分区</li>
<li>重分配需要检查，看是否自由分区能合并于相邻的空闲分区．<br>优点:</li>
<li>简单</li>
<li>易于产生更大空闲块，向着地址空间的结尾．<br>劣势：</li>
<li>容易产生外碎片</li>
<li>不确定性</li>
</ol>
</li>
<li>最佳适配<br>图：最佳匹配分配<br>为了分配n字节,使用最小的可用空闲块，以致快的尺寸比n大．<br>基本原理＆实现<br>为了避免分割大空闲块.<br>为了最小化外部碎片产生的尺寸.<br>需求:<ol>
<li>按尺寸排列到空闲块列表</li>
<li>分配需要寻找一个合适的分区</li>
<li>重分配需要搜索及合并于相邻的空闲分区，若有<br>优势:<ol>
<li>当大部分分配是小尺寸时非常有效．</li>
<li>比较简单<br>劣势:</li>
<li>外部碎片</li>
<li>重分配慢</li>
<li>易产生很多没用的微笑碎片(不怎么好).</li>
</ol>
</li>
</ol>
</li>
<li>最差适配<br>图：最差匹配分配<br>为了分配n字节,使用最大可用空闲块,以致块的尺寸比n大.<br>基本原理&amp;实现<br>为了避免有太多微小的碎片<br>需求:<ol>
<li>按尺寸排列的空闲块列表</li>
<li>分配很快（获得最大的分区）</li>
<li>重分陪需要合并于相邻的空闲分区，若有，然后调整空闲块列表．<br>优势: 假如分配是中等尺寸效果最好<br>劣势: </li>
<li>重分配慢</li>
<li>外部碎片</li>
<li>易于破碎打的空闲块以致大分区无法被分配．</li>
</ol>
</li>
</ol>
<h6 id="压缩式碎片整理"><a href="#压缩式碎片整理" class="headerlink" title="压缩式碎片整理"></a>压缩式碎片整理</h6><p>紧致算法:</p>
<ol>
<li>重置程序以合并孔洞(就是把程序位置尽可能先上移动，然后省出够用的内存).</li>
<li>要求所有程序是动态可重置的<br>一提:<ol>
<li>何时重置?(程序运行是不能挪动)．</li>
<li>开销（内存拷贝用于挪动，考虑频繁挪动开销大不大问题）</li>
</ol>
</li>
</ol>
<p>交换式碎片整理<br>图:交换式碎片整理</p>
<ol>
<li>运行程序需要更多的内存</li>
<li>抢占等待的程序&amp;回收他们的内存<br>把硬盘当做内存的备份.<br>比如内存有p1,p2,p3,p4四个程序，p3在运行需要更大的内存，就会把p4这个程序换到硬盘中．不用了之后在缓存到内存中．<br>换入换出的大小为程序的大小，开销也是看的是程序的大小．内存开销问题就是改善的方向．或者改善的更为灵活（块变得小一些）．</li>
</ol>
<h4 id="非连续内存的分配-分段"><a href="#非连续内存的分配-分段" class="headerlink" title="非连续内存的分配-分段"></a>非连续内存的分配-分段</h4><p>连续内存分配的缺点就是非连续内存分配出现的缘由．<br>缺点:<br>    1. 分配给一个程序的物理内存是连续的<br>    2. 内存利用率较低<br>    3. 有外碎片,内碎片问题．</p>
<p>非连续分配的优点:<br>    1. 一个程序的物理地mZ动态链接.</p>
<p>非连续内存: 缺点<br>如何建立虚拟地址和物理地址之间的转换.</p>
<ol>
<li>软件方案</li>
<li>硬件方案<br>两种硬件方案:<ol>
<li>分段机制</li>
<li>分页机制<br>分段考虑两点:</li>
<li>程序的分段地址空间（如何分段）</li>
<li>分段寻址方案(如何寻址)．<br>分段机制的作用：就是为了根据程序的特点，把内存得到一个有效的分离和管理，<br>图:分散到多个物理地址空间（方便管理）<br>左边是连续的逻辑地址，右边是一个不连续的物理地址，这是就需要一个对应的关联.</li>
</ol>
</li>
</ol>
<p>图:分段的逻辑视图<br>逻辑地址映射到物理空间中，不一定是连续的大小也不一定一样．<br>这个映射如果是软件支持的话，就需要非常大的开销．<br>这时需要硬件的支持，</p>
<p>硬件支持寻址</p>
<ol>
<li>分段寻址方案<br>图:段访问机制<br>一个段:一个内存”块”<br>　一个逻辑地址空间<br>程序访问内存地址需要:<br> 一个2维的二元组(s,addr)<ol>
<li>s-段号</li>
<li>addr-段内偏移<br>X86是段寄存和地址寄存器分开的．<br>还有一种就是段和地址连在一起，不用分开的这种管理方式.就没有专门的段寄存器这样的概念.</li>
</ol>
</li>
</ol>
<p>图：硬件实现方案<br>运行程序，cpu执行命令，寻址，逻辑地址分成两部分,一部分是段号，另一部分是段内偏移，（这里有硬件机制称为段表）段表中存在映射关系，逻辑地址段号和物理地址段号对应关系，段表中还有储存一个段的长度的信息．（一共两个信息），所以说段号是一个段的索引．cpu会根据查询到的物理段，和限制大小比对，是否合法，如果不合法有一个中断异常机制.交给操作系统处理，如果有问题会Kill掉．如果合法，就把起始地址加上偏移量形成起始地址，<br>段表是操作系统在寻址前建立的.</p>
<h4 id="非连续内存的分配-分页"><a href="#非连续内存的分配-分页" class="headerlink" title="非连续内存的分配-分页"></a>非连续内存的分配-分页</h4><p>分页:<br>    1. 分页地址空间<br>    2. 页寻址方案<br>分段段的大小可变，分页页的大小不可变．</p>
<p>划分物理内存至固定大小的帧（物理页的大小）<br>大小是2的幂，512,4096,8192.</p>
<p>划分逻辑地址空间至相同大小的页，（逻辑页的大小）<br>大小是2的幂,512,4096,8192.</p>
<p>所以我们需要建立逻辑页和物理页之间的对应关系．</p>
<p>这些会涉及到<br>建立方案转逻辑地址为物理地址(pages to frames)</p>
<ol>
<li>页表</li>
<li>MMU/TLB(内存管理单元，cpu中的组成单元)．/（TBL快表完成对页表的缓存）</li>
</ol>
<p>帧(物理帧)<br>图: 物理帧<br>物理内存被分割为大小相等的帧．<br>一个内存物理地址是一个二元组(f,o)<br>f—-帧号(F位,共有2^F个帧)<br>o—-帧内偏移(S位,每帧有2^s字节)<br>物理地址 = 2^s*f + o;</p>
<p>地址计算的实例<br>16-bit的地址空间，9-bit(512 byte) 大小的页帧，</p>
<ol>
<li>物理地址 = (3, 6);</li>
<li>物理地址 = 1542<br>图:地址计算的实例</li>
</ol>
<p>逻辑的寻址方式(页)<br>一个程序的逻辑地址空间被划分为大小相等的页</p>
<ol>
<li>页内偏移的大小 = 帧内偏移的大小</li>
<li>叶号大小&lt;&gt;帧号大小.(可能不一样)<br>图:逻辑页<br>虚拟地址 = 2^s * p + o</li>
</ol>
<p>图：页寻址机制<br>页表保存了逻辑地址—物理地址之间的映射关系．<br>cpu通过页号和页表基址找到帧号，也表中的帧后边有一个offset,通过公式找到真实的物理地址．<br>page table 页表是操作系统在初始化的过程中就要建立好.(分页之前).</p>
<p>可以得到页的大小是固定的，在硬件管理方面也可以用更加简洁的方式来实现．不需要像分段那部分需要考虑段的大小不同的这样的问题．</p>
<p>图:页寻址机制<br>一般来说逻辑的空间大于物理的地址空间</p>
<ol>
<li>页映射到帧</li>
<li>页是连续的虚拟内存</li>
<li>帧是非连续的物理内存</li>
<li>不是所有的页都有对应的帧<br>页映射页帧，页帧是不连续的，这样减少了磁盘碎片．</li>
</ol>
<h4 id="非连续内存的分配-页表概述"><a href="#非连续内存的分配-页表概述" class="headerlink" title="非连续内存的分配-页表概述"></a>非连续内存的分配-页表概述</h4><p>页表（怎样实现）</p>
<ol>
<li>页表概述</li>
<li>页表后备缓冲区</li>
<li>二级/多级 页表　</li>
<li>反向页表</li>
</ol>
<p>图:页表结构<br>图:页表地址转换实例<br>(4, 0) 向从表的下往上数，第四位发现标记位(红色)为零，表示没有相关的物理内存映射，返回一个异常．<br>(3,1023)<br>向表的从下往上数，第三位发现标记位(红色)为零，表示有相关的物理内存映射，frame num是00100表示对应的物理页帧的号，物理页帧后边有一个偏移号o,进行计算找到对应的物理地址．</p>
<p>分页机制的性能问题<br>问题: 访问一个内存单元需要2次内存访问</p>
<ol>
<li>一次用于获取页表项</li>
<li>一次用于访问数据<br>在操作系统内需要实现考虑两个问题</li>
<li>内存占用越少越好</li>
<li>效率越高越好</li>
</ol>
<p>实例：页表可能非常大<br>64位机器如果每项1024字节,那么一个页表大大小会是多少?<br>(2^64)/(2^10) = 2^(54)这会导致页表也很大，就不能放到我们的cpu里面，这个开销很大</p>
<p>为了使应用程序的隔离，每个程序都有一份自己的页表，ｎ个程序ｎ份页表．<br>第一个问题页表可能导致占得空间很大．<br>第二个问题返回效率问题．<br>因为表很大，所以不能放到cpu中，页表得放到存中，页表放到内存中，需要在cpu和内存中两次寻址.(自己想的)<br>解决方法:<br>    1. 缓存(cache)<br>    2. 间接访问（比如多级索引）．</p>
<p>解决浪费时间问题：<br>图: TLB<br>cpu里边有一个MMU(内存管理单元),MMU里边有一个(TLB)(我们所说的cache缓冲)他缓冲的就是页表里边的内容．</p>
<p>TLB(Translation Look-aside Buffer)<br>缓存近期访问的页帧转换表项:<br>    1. TLB使用associative memory(关联内存)实现．具备快速访问性能．<br>    2. 如果TLB命中，物理页号可以很快被获取．<br>    3. 如果TLB未命中,对应的表项被更新到TLB中.<br>TBL内部有一个p和f值，Key和Value值最为列明对应的是p和f,这一对key和value构成了一个表项，是由相关的存储器实现的，速度很快可以并发的进行查找，但是他实现的代价和容量都是有限的，所以把经常用到的页表项把他放到我们的TLB中去，这样就能提升访问速度，就不需要查询页表了，当CPU的到逻辑地址，献给局p来查询TLB,如果有就很容易得到value值(f值)，有f之后直接加上offset直接得到物理地址对应的内容了．如果出现TLB访问不到的情况（TLB表项中不存在）就是TLB缺失(miss),cpu不得不查询页表．xB6系统中由于cpu的特性，硬件就完成了TLB缺失后查询存取的操作，会放到TLB表中．（有的系统需要os实现，就是软件来实现的）</p>
<p>TLB确实情况会不会很大呢?<br>32位系统里边，一个页是4k,一次访问，要访问4k次，才会引起TLB的缺失．</p>
<p>!!!!!! 疑问，一个TLB是不是占一个页的大小.<br>注意:TLB本身不是一种存储设备，是存储在存储设备中的一种数据结构．<br>在写程序的过程中</p>
<h4 id="非连续内存的分配-页表－二级多级页表"><a href="#非连续内存的分配-页表－二级多级页表" class="headerlink" title="非连续内存的分配-页表－二级多级页表"></a>非连续内存的分配-页表－二级多级页表</h4><p>为了让页表所占的空间足够小，就产生了二级或者多级页表来缓解这个问题．<br>以二级页表为例:<br>图:二级页表<br>就只是把page number 分成了两个,offset没有分开,把一个较大的page table,换成了两个较小的page table来进行寻址.<br>寻址过程:<br>    1. 把大的page number分成两部分，p1,p2.<br>    2. p1的起始地址cpu是知道的，把p1的起始地址作为index,查找p1中的页表项，p1中存的值是p2（二级页表的起始值）中的起始值，<br>    3. 找到p2的index,加上p1中存的起始地址，就找到了p2中的页表项．<br>    4. p2里边存的是frome number.(就是对应的f,然后招到逻辑和物理地址映射表，取出f,o进行公式运算得到物理地址.)</p>
<p>这样一来，多级页表都存到内存中，开销会很大，所以会把那些没有映射关系的页表项，就没必要占用内存了，<br>有一个驻存位来表示当前映射关系的可用与否，如果为零就说明可以把第二级页表移出内存．<br>图：多级页表<br>多级页表导致每次访问的时间越来越大，用时间换取了空间．时间可以通过TLB来缓解.</p>
<h4 id="非连续内存的分配-页表反向页表"><a href="#非连续内存的分配-页表反向页表" class="headerlink" title="非连续内存的分配-页表反向页表"></a>非连续内存的分配-页表反向页表</h4><p>非连续内存分配</p>
<ol>
<li>为什么需要非连续内存分配</li>
<li>分段</li>
<li>分页</li>
<li>页表:<ol>
<li>页表概览</li>
<li>快表(TLB)</li>
<li>二级/多级页表</li>
<li>反向页表</li>
</ol>
</li>
</ol>
<p>由于空间越大页表越多，从而想到有没有一种方法，是页表大小与逻辑地址空间大小没那么大的关系．和物理地址的大小建立对应关系．</p>
<p>大地址空间问题:<br>    有大地址空间(64-bit),前向映射页表变得繁琐．比如:5级页表<br>    不是让页表与逻辑地址空间的大小相对应，而是让页表与物理地址空间的大小相对应:<br>        1. 逻辑（虚拟地址空间增长速度快于物理地址空间）．</p>
<p>图:基于页寄存器的方案.<br>index 变了由逻辑页号变为了物理页号(页帧号)．根据物理页帧号查询他所对应的页号．反向查询.<br>这使得寄存器的容量只与物理地址的大小相关，与逻辑地址的大小无关．这样就限制了寄存器的数量．<br>还有一个很大的问题，就是我们根据page number来查找frome number的．这样一来怎么找到page　number所在的位置．我们的到的是以frame　number为index的数组.<br>难题：如何建立页号和页帧号的对应关系的建立?</p>
<p>解决方案 图:基于关联内存的方案（关联存储器）<br>这个问题可以解决，但是寄存器设计复杂，开销太大，由于复杂导致他的容量不可能做的太大．<br>key -&gt;页号<br>Value-&gt;页帧号<br>放到cpu里边，由于内存开销过大，没法避免．<br>如果放到cpu外边就会产生一个内存访问问题．<br>图：使用页寄存器.<br>有例题．</p>
<p>图：在反向页表中搜索一个页对应的帧号<br>如果帧数较少，页寄存器可以被放置在关联内存中．<br>在关联内存中查找逻辑页号</p>
<ol>
<li>成功: 帧号被提取</li>
<li>失败: 页错误异常(page fault)<br>限制因素:<br> 大量的关联内存非常昂贵:<pre><code> 1. 难以在单个时钟周期完成
 2. 耗电．</code></pre>
</li>
</ol>
<p>图:基于哈希查找的方案.<br>  输入page number 输出　frome number.(就一个底层的计算)<br>  可以用软件使用也可以用硬件加速.<br>  为了更快地效率，加一个PID(当前运行程序的ID),PID加上page number就可以很好通过哈希函数设计出对应的frame  number.很好的缓解了完成映射的开销．</p>
<p>把反向列表存到没存中去说白了内存的开销还是很大，还需要一个TLB的机制给他缓存起来，来降低访问列表的时间开销，（目前反向列表只有在高级的cpu中存在.<br>  再反向页表中通过哈希算法来搜索一个页对应的帧号．</p>
<ol>
<li>对页号做哈希计算，为了在”帧表”(每帧拥有一个表项)中获取对应的帧号．</li>
<li>页i被放置在表中f(i)位置，其中f是设定的哈希函数<br>　为了查找页i,执行下列操作:<ol>
<li>获取对应的页寄存器</li>
<li>检查寄存器标签是否包含i,如果包含，则代表成功，否则失败．</li>
</ol>
</li>
</ol>
<p>好处:不受限与逻辑内存大小的影响．只和我们物理的内存有关，<br>对于单级列表来说，每个程序都有一份自己的页表（page table)，对多级页表来说整个系统只要一个．因为他是用物理页帧号作为(index)来建立的表．需要高速的硬件计算，高速的处理函数．还需要一个解决冲突的机制，来保证高效的执行，</p>
<h4 id="虚拟内存的起因"><a href="#虚拟内存的起因" class="headerlink" title="虚拟内存的起因"></a>虚拟内存的起因</h4><p>起因:<br>虚拟内存之前用</p>
<ol>
<li>覆盖技术</li>
<li>交换技术<br>然后发展虚存技术</li>
<li>目标</li>
<li>程序局部性原理</li>
<li>基本概念</li>
<li>基本特征</li>
<li>虚拟页式内存管理</li>
</ol>
<p>理想中的存储器<br>更大，更快，更便宜的非易失性存储器．（就是断电能够保存数据）<br>图:os支持的存储器<br>基本实现了更大，更快，更便宜，但是非易失性基于现在的硬件设备没能实现，</p>
<p>通过操作系统的管理把不常用的数据放到硬盘上去，把常用的数据放入内存，这样让有限的内存放经常访问的数据，通过这种方式实现一种大内存的感觉，这种方式需要cpu,mmu硬件和操作系统内核协同在一起才能完成，</p>
<p>在早期遇到这种情况怎么办？</p>
<ol>
<li>如果是程序太大,超过了内存的容量，可以采用手动的覆盖技术，只把需要的指令和数据保存的内存中． </li>
<li>如果是程序太多，超过了内存的容量，可以采用自动的交换技术，把暂时不能执行的程序送到外存中．</li>
<li>如果想要在有限容量的内存中，以更小的页粒度为单位装入更多更大的程序，可以采用自动的虚拟存储技术．</li>
</ol>
<h4 id="覆盖技术"><a href="#覆盖技术" class="headerlink" title="覆盖技术"></a>覆盖技术</h4><p>目标:<br>    是在较小的可用内存中运行较大的程序．常用于多道程序系统，与分区存储管理配合使用．<br>原理:<br>把程序按照期自身逻辑结构，划分为若干个功能功能上相对独立的程序模块,那些不会同时执行的模块共享同一块内存区域，按时间先后来运行．</p>
<ol>
<li>必要部分(常用功能)的代码和数据常驻内存</li>
<li>可选部分(不常用功能)在其他程序模块中实现，平时存放在外存中，需要时才装如内存<br>3, 不存在调用关系的模块不必同时装入到内存，从而可以交互覆盖，即这些模块共用一个分区．<br>图:覆盖技术例子<br>程序A需要常驻内存，因为他要常驻内存，来调用BCDEF的执行．BC不会相互调用，DEF也不会相互调用，因此分成了两个共享区．（注意图中共享内存大小和原来程序的大小），在调用的过程中，比如A调用C,ｃ的内存会被调入都一个覆盖区，再调入之前需要把B的内容导回到硬盘中，注意代码是只读的不需要导只需要释放就可以了，把调入的内存和数据调用完，A就可以调用C了，<br>缺点:开销问题<ol>
<li>(设计开销)由程序来吧一个大的程序划分成为若干个小的功能块，并确定各个模块之间的覆盖关系，费时费力，增加了编程的复杂度．</li>
<li>(引入了时间开销)覆盖模块从外村装入内存，实际上是以时间延长来换区空间节省．</li>
</ol>
</li>
</ol>
<h4 id="交换技术"><a href="#交换技术" class="headerlink" title="交换技术"></a>交换技术</h4><p>目标:<br>    多道程序在内存中时，让正在运行的程序或需要运行的程序获得更多的内存资源．<br>方法:<br>    1. 可将暂时不能运行的程序送到外存，从而获得空闲内存空间，<br>    2. 操作系统把一个进程的整个地址空间的内容保存到外存中(换出swap out),而将外存中的某个进程的地址空间读入到内存中(换入swap in).换入换出内容的大小为整个程序的地址空间．<br>    换入换出这一部分是操作系统的一个重要部分，导入导出的粒度是一个程序，这跟程序的大小有关，如果程序比较大那么导入导出的开销就比较大，否则就比较小，相对来说粒度会大于一个页几十几百页，所以说导入导出的开销是比较大的．</p>
<p>图:交换技术</p>
<p>交换技术实现中的几个问题</p>
<ol>
<li>交换机的确定:何时需要发生交换?（如果频繁的交换会产生很大的开销）只当内存空间不够或又不够的危险时换出；（尽量减少换入换出的次数）</li>
<li>交换区的大小:必须足够大以存放所有用户进程的所有内存映像的拷贝；必须能够对这些内存映像进行直接存取；</li>
<li>程序换入时的重定位:换出后再换入的内存位置一定要在原来的位置上吗?最好才赢动态地址映射的方法．（换入换出的位置可能发生变化，寻址就会出现问题，怎么能让换入新地方的程序正常执行，值得思考．如果是换入位置是换出前的位置一样，那能正常执行，没问题，所以需要建立页表虚地址一样物理地址不一样，页表建立完成就可以了，也是动态地址映射的方法）</li>
</ol>
<h5 id="覆盖和交换技术的比较"><a href="#覆盖和交换技术的比较" class="headerlink" title="覆盖和交换技术的比较"></a>覆盖和交换技术的比较</h5><p>覆盖技术一个程序的模块，交换技术是一整个程序，所以说粒度有差别．</p>
<ol>
<li>覆盖只能发生在那些相互之间没有调度关系的程序模块之间，因此程序员必须给出程序内的各个模块之间的逻辑覆盖结构．</li>
<li>交换技术是以在内存中的程序大小为单位来进行的，他不需要程序员给出各个模块之间的逻辑覆盖结构．换言之，交换发生在内存中程序与管理程序或操作系统之间，而覆盖则发生在运行程序的内部（某个函数为覆盖对象，不好的地方是需要程序员手动的指定他们之间的逻辑关系，便于覆盖处理单元完成相应的功能）．</li>
</ol>
<h4 id="虚拟技术-上"><a href="#虚拟技术-上" class="headerlink" title="虚拟技术(上)"></a>虚拟技术(上)</h4><p>虚拟技术–目标<br>在内存不够用的情形下，可以采用覆盖技术和交换技术，但是:<br>    1. 覆盖技术:需要程序员自己把整个程序划分为若干个小的功能模块，并确定各个模块之间的覆盖关系，增加了程序员的负担；<br>    2. 交换技术:以进程作为交换单位，需要把进程的整个地址空间都换进换出，增加了处理器的开销．<br>更好的解决办法（四海之内的）解决之道:虚拟内存管理技术—虚拟技术</p>
<p>虚拟技术–目标</p>
<ol>
<li>像覆盖技术那样，不是把程序的所有内容都放在内存中，因而能够运行比当前的空闲内存空间还要大的程序．但做的更好，由操作系统自动来完成，无需程序员的干涉:</li>
<li>像交换技术那样，能够实现进程在内存和外村之间的交换，因而获得更多的空闲空间，但做的更好，只对进程的部分内容在内存和外存之间进行交换．（不用交换整个程序或者程序块，只需要动态调用所需要用到的页就好了，没有运行到的就放到外村就可以了）由操作系统和MMU合作完成的．</li>
</ol>
<p>由于这个过程是自动做的，就会要求程序有一定的局部性.<br>虚拟技术—程序的局部性原理<br>程序的局部性原理:指程序在执行过程中的一个较短时期，所执行的指令地址和指令的操作数地址，分别局限于一定区域．这可以表现为:<br>    1. 时间局部性:一条指令的一次执行和下次执行，一个数据的一次访问和下次访问都集中在一个较短时期内；<br>    2. 空间局部性:当前指令和邻近的几条指令，当前访问的数据和邻近的几个数据都集中在一个较小区域内．<br>    程序的局部性原理表明，从理论上来说，虚拟存储技术是能够实现的，而且在实现了以后应该是能够取得一个满意的效果的．<br>图:虚拟技术–程序的局部性原理 例题<br>图:虚拟技术–程序的局部性原理2 题解<br>缺页中断，就是4k的物理内存，每次能存1024字节(图中的消息得出)，如果访问没有数据了，就会产生缺页中断．<br>第二中就不具备两种局部性．注意32位系统下一个整形占4比特，1024*4 = 4k.</p>
<p>根据时间局部性来判断需要把哪些内容放到内存中去．</p>
<p>图:虚存技术–基本概念<br>可以在页式或段式内存管理的基础上实现．</p>
<ol>
<li>在装入程序时，不必将其全部装入内存，而是需将当前需要执行的部分页面或段装入到内存，就可以让程序开始执行；</li>
<li>在程序执行过程中，如果需执行的指令或访问的数据尚未在内容（称为缺页或缺段）,则由处理器通知操作系统将相应的页面或段调入到内存，然后继续执行程序．</li>
<li>另一方面，操作系统将内存中暂时不使用的页面或段调出保存在外存上，从而腾出更多空闲空间存放将要装入的程序以及将要调入的页面或段．</li>
</ol>
<p>虚存技术-基本特征</p>
<ol>
<li>大的用户空间:通过把物理内存与外存相结合，提供给用户的虚拟内存空间通常大于实际的物理内存，即实现了这两者的分离．如32位的虚拟地址理论上可以访问4GB,而可能计算机上仅有256M的物理内存,但硬盘容量大于4GB.</li>
<li>部分交换: 与交换技术相比较，虚拟存储的调入和调出是对部分虚拟地址空间进行的．</li>
<li>不连续性: 物理内存分配的不连续，虚拟地址空间使用的不连续．（某些代码换出去，导致不连续）</li>
</ol>
<p>虚拟内存 = 物理内存 + 硬盘</p>
<p>虚拟内存的实现．<br>图：虚拟技术-虚拟页式内存管理<br>虚拟技术-虚拟页式内存管理　<br>大部分虚拟存储系统都采用虚拟页式存储管理技术，即在页式存储管理的基础上，增加请求调页和页面置换功能．<br>基本思路:<br>    1. 当一个用户程序要调入内存运行时,不是将该程序的所有页面都装入内存，而是只装入部分的页面，就可以启动程序运行．<br>    2. 在运行过程中，如果发现要运行的程序或要访问数据不在内存，则向系统发出缺页中断请求，系统在处理这个中断时，将外存中相应的页面调入内存，使得该程序能够继续运行．<br>    换入换出过程中有效的置换算法，起着关键因素．</p>
<p>图:虚拟技术-虚拟页式内存管理–页表项<br>页表项中有4个bity比较重要．<br>逻辑页号—访问位-修改位-保护位-驻留位-物理页帧号</p>
<ol>
<li>驻留位:表示该页是在内存还是在外存．如果该位等于1,表示该页位于内存当中，即该页表项是有效的，可以使用；如果该位等于0,表示该页当前还在外存当中，如果访问该页表项，将导致缺页中断；</li>
<li>保护位: 表示允许对该页坐何种类型的访问，如只读，可读写，可执行等．</li>
<li>修改位: 表明此页在内存中是否被修改过．当系统回收该物理页面是，根据此位来决定是否把它的内存写回外存；（如果数据没有被修改，就不需写回，直接释放即可，有数据更新则就写回）．</li>
<li>访问位: 如果该页面被访问过,(包括读操作或写操作),则设置此位用于页面置换算法．</li>
</ol>
<p>图:虚拟技术–虚拟页式内存管理bity图</p>
<p>如果是X就说明驻留位为零，否则就是一个数字表示驻留位为1，表示该位是有效的。</p>
<p>如果把虚拟的零地址赋值给一个寄存器，命令如MOV REG, 0</p>
<p>查询0的页号对应的是2，代表驻留位为1，对应关系是有效的，页帧号为2，一个页的大小为4k，表示4096，用4096*2 = 8192，实际访问的物理地址就是8192.操作正常没有问题。</p>
<p>现在要把   MOV REG, 32780</p>
<p>就是要把虚拟得知32780读到寄存器中去，页表项就是第八个，32k-36k区间，驻留位的设置为零，没有所对应的页帧号，就会产生缺页异常（缺页中断）。</p>
<p>图：虚拟技术–虚拟页式内存管理-缺页中断</p>
<p>一旦缺页，程序就会把控制权交给操作系统，然后执行图中流程。</p>
<p>后备存储</p>
<p>在何处保存未被映射的页？</p>
<ol>
<li><p>能够简单的识别在二级存储器中的页</p>
</li>
<li><p>交换空间（磁盘或者文件）:特殊格式，用于存储未被映射的页面。</p>
</li>
</ol>
<p>概念后备存储</p>
<ol>
<li>一个虚拟地址空间的页面可以被映射到一个文件（在二级存储中）中的某个位置</li>
</ol>
<p>例如：访问一个数组，他是一个大的数据可能是一个数据文件，方在了我们的硬盘上，当需要访问到某个地方的时候呢，如果内存中没有就需要从数据文件中读取出来，（这是一种后援存储 ）</p>
<ol start="2">
<li>代码段:映射到可执行二进制文件   </li>
</ol>
<p>操作系统在执行代码过程中，会执行每一条指令，这个指令也是一种数据，这个数据放到我们的执行程序里边.放在我们的硬盘中，我们的硬盘存了好多执行程序。会把这些代码当做数据，放到内存中去。然后让我们cpu去执行一条条指令，如果遇到某条指令不存在的情况，会进一步从执行程序中，把信息读取到内存中来进一步执行，这属于代码的一种后备存储。</p>
<ol start="3">
<li>动态加载的共享库程序段:映射到动态调用的库文件</li>
</ol>
<p>软件运行需要很多库，这些库也是放到硬盘中的，需要的时候才会把库的代码和数据从硬盘中读进内存中。</p>
<ol start="4">
<li>其他段:可能被映射到交换文件（swap file）</li>
</ol>
<p>程序在运行的过程中，会产生很多的数据，这些数据没有对应到具体文件（数据文件，执行文件，库文件等），这些数据可能占了很大空间，需要被换出到硬盘上去，操作系统会在硬盘开辟一个区（swap换入换出分区）放置那些没有与文件直接对应的那些内容。</p>
<p>这四部分构成了我们说的后备存储或者二级存储，充分保证空间的有效性。</p>
<p>图:虚拟内存性能</p>
<p>p:代表残缺的概率</p>
<p>q:代表对页进行写操作的概率</p>
<p>5000，000表示ms到ns的换算</p>
<p>（1+q）写完后需要换出操作，写入硬盘，也需要5ms的时间。</p>
<p>p足够小使得公式后边的数最小，这样接近10ns</p>
<p>我们有办法保证p的最小就是程序的局部性特点，就是缺页的概率很小，</p>
<h4 id="页面置换算法"><a href="#页面置换算法" class="headerlink" title="页面置换算法"></a>页面置换算法</h4><p>功能与目标</p>
<ol>
<li>功能:当缺页中断发生，需要调入新的页面而内存已满时，选择内存当中那个物理页面被置换</li>
<li>目标:尽可能地减少页面的换进换出次数(即缺页中断的次数).具体来说，把未来不再使用或短期内较少使用的页面换出，通常只能在局部性原理指导下依据过去的统计数据来进行预测:</li>
<li>页面锁定:用于描述必须常驻内存的操作系统的关键部分或时间关键的应用程序．实现的方法是：在页表中添加锁定标志位（lock bit）,使得这些页不在页面处理算法之内．确保操作系统随时能正常工作．<br>实验设置与评估方法<br>局部页面置换算法</li>
<li>最优页面置换算大(opt)</li>
<li>先进先出算法(FIFO)</li>
<li>最久未使用算法(LRU)</li>
<li>时钟页面置换算法(clock)</li>
<li>最不常用算法(LFU)</li>
<li>Belady现象</li>
<li>LRU,FIFO和Clock的比较．<br>全局页面置换算法</li>
<li>工作集模型</li>
<li>工作集页置换算法</li>
<li>缺页率置换算法</li>
</ol>
<h4 id="最优页面置换算法"><a href="#最优页面置换算法" class="headerlink" title="最优页面置换算法"></a>最优页面置换算法</h4><p>图:1最优页面置换算法–性能分析<br>(3,0) (1, 9)表示页号和偏移(f, o);<br>只有页不存在的情况，才会产生缺页中断，所以只看页就可以了，offset忽略掉就可以．<br>更少的缺失，更好的性能．</p>
<p>基本思路:当一个缺页中断发生时，对于保存在内存当中的每一个逻辑页面，计算在它的下一次访问之前，还需等待多久时间，从中选择等待时间最长的那个，作为被置换的页面．</p>
<p>这是一种理想情况，在实际系统中是无法实现的，因为操作系统无从知道每一个页面要等待多久时间以后才会再次被访问．<br>这个算法涉及到了未来，所以无法实现，这个算法只是作为一个评价算法好坏的标准．</p>
<p>可以作其他算法的性能评价的依据(在一个模拟器上运行某个程序，并记录每一次的页面访问情况，在第二次运行时即可使用最优算法．</p>
<p>图:置换页面算法的例题<br>前a,b,c,d四个页已经存到了物理页里．所以说前四个不弄页面置换，后边才涉及到页面转换，换出的时间最长不用的．<br>第四步中<br>步数为a = 7, b = 6, c = 9, d = 10,需要把d替换出去，e替换进来．</p>
<h4 id="先进先出算法-FIFO"><a href="#先进先出算法-FIFO" class="headerlink" title="先进先出算法(FIFO)"></a>先进先出算法(FIFO)</h4><p>基本思路:选择在内存中驻留时间最长的页面并淘汰之，具体来说，系统维护着一个链表，记录了所有位于内存当中的逻辑页面．从链表的排列顺序来看，链首页面的驻留时间最长，链表页面的驻留时间最短．当发生一个缺页中断时，把链首页面淘汰出局，并把新的页面添加到链表的末尾．</p>
<p>性能较差，调出的页面有可能是经常要访问的页面，并且有Belady现象．<br>FIFO算法很少单独使用．<br>图:FIFO</p>
<h4 id="最近最久未使用算法"><a href="#最近最久未使用算法" class="headerlink" title="最近最久未使用算法"></a>最近最久未使用算法</h4><p>图:最久未使用算法.<br>图:页面置换算法应用<br>图:LRU算法数据维护</p>
<ol>
<li>头插链表，头部为最近时期用的，尾部没用的</li>
<li>用栈维护，栈顶为最近用的，栈尾为最久未用的．<br>图LRU算法基于栈的样例<br>lRU算法，系统开销过于大．不利于你系统和程序的运行平衡．</li>
</ol>
<h4 id="时钟页面置换算法"><a href="#时钟页面置换算法" class="headerlink" title="时钟页面置换算法"></a>时钟页面置换算法</h4><p>图:时钟页面置换算法(由cpu访问页，就会把xsexbit(时钟位)位置一，此过程不需要软件参与，由硬件完成)<br>这个算法依据的就是x-sexbit位.<br>图:时钟置换算法原理<br>page 7,4,0,3,1五个虚拟页放在物理内存中的<br>第一位表示页的存在位，页的存在1,不存在0.(resident bit)<br>第二位表示x-sexbit（access bit）<br>第三位表示页帧号(frame number)<br>通俗来说当前位如果为1,就替换成0,指针下移动一位，找到零就会把虚拟页为6(举例子)的内容存到物理页为5的页中，然后置为1.</p>
<p>图:时钟置换原理算法题<br>最下边一行每一列表示一个环形列表．</p>
<p>在实际过程中clock和LRU置换算法的置换页面次数相近（产生缺页中断的次数），因为clock只用了一个bit为来表示置换的信息，达不到LRU那么精确.达不到最好的效果，但是接近，</p>
<h4 id="二次-机会-进位法"><a href="#二次-机会-进位法" class="headerlink" title="二次(机会)进位法"></a>二次(机会)进位法</h4><p>clock算法用了页表项的access bit位，标记了访问信息，但是访问信息是读和写，两种都是访问，并没有区分．页表项中还有一个叫dity bit脏位标记，如果进行了写操作，dity bit 会置为1,如果只是读操作没有写，dity bit 置位为零．（有硬件完成的）</p>
<p>如果把页内容从硬盘中读入内存，如果只有读操作，那么把该页替换出去的话，就不会把该页重新写回到硬盘中去，只把该页内容释放掉就好了，因为他们的内容是一样的．如果程序在访问这一页的过程中对该页进行了写操作．这个页如果被替换出去的话，就需要把页重新写回到硬盘中去．通过dity bit 这一位就可以改善clock这个算法的执行效率，就更名为”二次进位法”</p>
<p>图：二次进位法<br>查看图的　从左往右数，第二位(used)access bit, 第三位dity bit.<br>　　　　　　　　　　　　　　　　　　after clock sweep<br>used bit　　　　　dity bit 　　　　used bit　　　dity bit　　　　<br>0　　　　　　　　　0　　　　　　　　replace page<br>0　　　　　　　　　1　　　　　　　　0　　　　　　0<br>1　　　　　　　　　0　　　　　　　　0　　　　　　0<br>1　　　　　　　　　1　　　　　　　　0　　　　　　1<br>二次机会由来是因为两个标记位都是1,就要就行指针两次循环指，才能把该页换出去．从而使被写过的页被换出去的概率减少．由于dit bit位进行了修改，所以要标记一下是否进行了写操作．比如图中a^w ｗ标记为写过．<br>图:二次进位法例题</p>
<h4 id="最不常用法-Least-Frequently-Used-LFU"><a href="#最不常用法-Least-Frequently-Used-LFU" class="headerlink" title="最不常用法(Least Frequently Used LFU)"></a>最不常用法(Least Frequently Used LFU)</h4><p>基本思路: 当一个缺页中断发生时，选择访问次数最少的那个页，并淘汰之．<br>实现方法: 对每个页面设置一个访问计数器，每当一个页面被访问时，该页面的访问计数器加1,在发生缺页中断时，淘汰计数值最小的那个页．（用计数器来存，很明显硬件开销很大，如果也很大，链表查找时间按也必然很长）</p>
<p>LRU和LFU区别:LRU考察的是多久未访问，时间越短越好；而LFU考察的是访问次数和频度，访问次数越多越好．</p>
<p>问题：一个页面在进程开始使用得很多，但以后就不使用了．实现也费时费力．<br>解决方法: 定期把次数寄存器右移一位．</p>
<h4 id="Belady现象，LRU-FIFO"><a href="#Belady现象，LRU-FIFO" class="headerlink" title="Belady现象，LRU,FIFO"></a>Belady现象，LRU,FIFO</h4><p>Belady现象:在采用FIFO算法时,有时会出现分配的物理页面增加,缺页率反而提高的异常现象;注意Belady是科学家名字．<br>Relady现象的原因:FIFO算法的置换特征与进程访问内存的动态特征是矛盾的，与置换算法的目标是不一致的(即替换较少使用的页面),因此，被置换出去的页面并不一定是进程不会访问的．<br>图:Belady-FIFO（分三个物理页的情况）<br>最后一行X表示产生缺页中断，带框的就是不产生缺页中断．<br>图:Belady-FIFO-page-4(分四个物理页的情况)<br>给三行物理页缺页次数为9,给四行物理页缺页次数变为10.期望的是少结果变多了．<br>图中不是最坏的，最坏情况就是每次都会产生缺页中断．</p>
<p>图: Belady-LRU实例<br>Belay-FIFO ：物理页为3缺页中断次数为10</p>
<p>LRU: 物理页为4缺页中断次数为8,更符合我们的理想情况，</p>
<p>时钟/第二次机会页面置换是怎样的?</p>
<p>为什么LRU页面置换算法没有Belay的现象？（再此鼓励查找Belady现象的论文查找读）<br>LRU算法符合一类栈算法的特点，符合这一特点就有一种属性，给的物理页越多产生的缺页次数越少．FIFO不满足栈算法这一特点．</p>
<p>LRU,FIFO和Clock的比较(如果程序没有良好的局部性这些区别也就不会很大，都会成为最差的算法)<br>LRU算法和FIFO本质上都是先进先出的思路，只不过LRU是针对页面的最近访问时间来进行排序，所以需要在每一次页面访问的时候动态调整各个页面的先后顺序（有一个页面的最近访问时间变了）；而FIFO是针对页面进入内存的时间来进行排序，这个时间是固定不变的，所以各页面之间的先后顺序是固定的，．如果一个页面在进入内存后没有被访问，那么它的最近访问时间就是进入内存的时间．换句话说，如果内存当中的所有页面都未曾访问过，那么LRU算法就退化为FIFO算法．</p>
<p>例如进程分配3个物理页面，逻辑页面的访问顺序为1,2,3,4,5,6,1,2,3…</p>
<p>如果程序有更好的局部特点，LRU更能适应，也能产生更能好的效果．<br>所以说如果程序没有很好的局部性，LRU和FIFO算法就会有一样的不太好的效果．<br>clock算法是对LRU算法的一种类似，只是clock用access bit和dity bit两个位进行了标记（硬件标记）,不能精确的表示使用的频率信息，最差效果也是FIFO算法．开销比LRU算法小的很多.因为LUR在某种情况下会退化为FIFO,所以clock在最坏的情况下也会退化为FIFO算法．</p>
<p>LRU算法性能较好，但系统开销较大；FIFO算法系统开销较小，但可能会发生Belady现象，因此，折中的办法就是Clock算法，每一次页面访问时，它不必去动态调用该页面在链表中的顺序，而仅仅是做一个标记，然后等到发生却也中的时候，再把它移动到链表末尾．对于内存当中那些未被访问的页面，Clock算法的表现和LRU算法一样好；而对于那些曾经被访问过得页面，它不能像LRU算法那样，记住他们的精准位置，</p>
<h4 id="局部页替换算法的问题"><a href="#局部页替换算法的问题" class="headerlink" title="局部页替换算法的问题"></a>局部页替换算法的问题</h4><p>以上算法针对的是一个进程或者是一个程序来写的．如果操作系统只是采取固定的局部的页面置换算法，其实会带来一些问题，这就是全局置换算法产生的原因．<br>图:FIFO页面置换算法不同物理页区别</p>
<p>可以看出物理页数的不同会影响到不同页面置换算法的效果．（效果评判看置换页面的多少，少的为优），如果分配一个固定的页帧，和一个固定的算法没给一个程序，其实在某种程度上就限制了程序产生缺页的特点．因为程序在运行过程中他有一个阶段性特点．可能开始需要内存多中间少最后内存多，此时程序对物理页的需求是动态变换的过程．操作系统可同时跑多个程序，如果这时分配固定的物理页帧，就限制了物理灵活性．所以可不可以动态调整不同时期对程序分配的物理页帧，这是全局页面置换算法要考虑的问题．</p>
<p>实现全局置换算法的前提(工作集模型)<br>前面介绍的各种页面置换算法，都是基于一个前提．<br>即程序的局部性原理，但是此原理是否成立?</p>
<ol>
<li>如果局部性原理不成立，那么各种页面置换算法就没有什么区别，也没有什么意义．例如;假设进程对逻辑页面的访问顺序是1,2,3,4,5,6,7,8,9…,即单调递增，那么在物理页面数有限的前提下你，不管采用何种置换算法，每次的页面访问必然导致缺页中断．</li>
<li>如果局部性原理是成立的（时间和空间访问的局部性），那么如何来证明他的存在，如何来对它进行定量的分析?这就是工作集模型．</li>
</ol>
<p>工作集定义:<br>工作集: 一个进程当前正在使用的逻辑页面集合．（当前正在使用表示一个时间段，起始时间，时间长度）（逻辑页面的集合这是一个集合）<br>可以用一个二元函数W(t,△ )来表示:<br>t :是当前的执行时刻；<br>△ : 称为工作集窗口(working-set window),即一个定长的页面访问的时间窗口；（t + △ 形成的时间段）<br>W(t, △ ) = 在当前时刻t之前的△ 时间窗口当中的所有页面所组成的集合（随着t的变化，该集合也在不断的变化）;（t在变△ 不变，移动定长窗口）<br>| W(t, △ )|指定工作集的大小，即页面数目．（在der ta（△ ）时间内访问到的页面的集合）</p>
<p>图：工作集实例</p>
<p>△ :当前和过去的大小．（注意是过去）<br>分析：t1中7出现了四次，但是t2中多个数多次出现，从工作集中看出，t1比t2的程序局限性比差．</p>
<p>图：工作集大小的变化图<br>可以看出工作集动态变化的特征．</p>
<p>另一个概念：常驻集<br>常驻集是指在当前时刻，进程实际驻留在内存当中的页面集合．<br>图:常驻集（笔记中符号有缺陷可看图）<br>对比解释：</p>
<ol>
<li>工作集是进程在运行过程中固有的性质，而常驻集取决于系统分配给进程的物理页面的数目，以及所采用的页面置换算法；（常驻集就是当前程序需要访问的页哪些在内存中，工作集是在运行过程中需要访问的页是那些，也得有一个上限，不是越多越好，超出一定限制，程序会把多余的页分给其他程序，使得所有程序总的缺页次数比较小）</li>
<li>如果一个进程的整个工作集都在内存中，即常驻（－）工作集，那么进程将很顺利的运行，而不会造成太多的缺页中断(直到工作集发生剧烈变动，从而过渡到另一状态);<br>当进程常驻集的大小达到某个数目之后，再给它分配更多的物理页面，</li>
</ol>
<h4 id="两个全局置换算法"><a href="#两个全局置换算法" class="headerlink" title="两个全局置换算法"></a>两个全局置换算法</h4><h5 id="工作集页置换算法"><a href="#工作集页置换算法" class="headerlink" title="工作集页置换算法"></a>工作集页置换算法</h5><p>工作集页置换算法的思想:<br>随着工作窗口的移动，页不属于工作集窗口或者缺页了都会进行替换（或者说丢掉）．<br>性质：每次窗口中都有一定的物理页，来进行页面的替换或者丢弃（来确保整个系统的缺页置换次数降低）</p>
<p>图：工作集页置换算法实例.<br>图片讲解：开始分配了五个物理页帧其中ade三个窗口被访问了．剩下两个页是空页还可以再用．<br>第几次访问等同于第几个时刻访问．<br>第一次访问: 工作集a,c,d,e（缺页中断大红点）<br>第二次访问: 工作集a,c,d（e不属于工作集窗口的元素，如果只读直接free,如果可写就得写回硬盘）<br>第三次访问: 工作集a,c,d（工作集不变）<br>第四次访问: 工作集b,c,d,(把a换出去，把b换进来产生缺页中断，为什么换a,因为a的t= 0,超出了工作级窗口．)<br>第五次访问: 工作集b,c,d(工作集不变)<br>第六次访问: 工作集b,c,d,e（工作集加入e）<br>第七次访问: 工作集b,c,e(工作集由于ｄ的时间到了剔除，别的不变)<br>第八次访问: 工作集c,e(b到时间了，可以看出即使没有中断由于工作集往前走，所以也会把到时见的页踢出工作集)</p>
<p>根据窗口从不变到改变得到了以下的算法．</p>
<h5 id="缺页率页面置换算法"><a href="#缺页率页面置换算法" class="headerlink" title="缺页率页面置换算法"></a>缺页率页面置换算法</h5><p>可变分配策略: 常驻集大小可变．例如: 每个进程在刚开始运行的时候，先根据程序大小给它分配一定数目的物理页面，然后在进程运行过程中，在动态的调整常驻集的大小．</p>
<ol>
<li>可采用页面置换的方式，法身一个缺页中断时，被置换的页面可以是在其他进程当中，各个并发进程竞争地使用物理页面．</li>
<li>优缺点:性能较好，但增加了系统开销．</li>
<li>具体实现: 可以使用缺页率算法(PFF, page fualt frequenvy)来动态调整常驻集的大小．</li>
</ol>
<p>缺页率：<br>缺页率表示＂缺页次数/内存访问次数＂(比率)或＂缺页的平均时间间隔的倒数＂.影响缺页率的因素:</p>
<ol>
<li>页面置换算法</li>
<li>分配给进程的物理页面数目（一般情况下物理页越多产生的缺页次数越少）</li>
<li>页面本身的大小（页面越大差生的缺页次数也会减少）</li>
<li>程序的编写方法（程序是否拥有局部性）</li>
</ol>
<p>图:缺页率算法<br>若运行程序的缺页率过高，则通过增加工作集来分配更多的物理页面；若运行的程序的缺页率过低，则通过减少工作集来减少他的物理页面数．力图使运行的每个程序的缺页率保持在一个合理的范围内．</p>
<p>一个交替的工作集计算明确的试图最小化页缺失</p>
<ol>
<li>当缺页率高的时候-增加工作集</li>
<li>当缺页率低的时候-减少工作集</li>
</ol>
<p>图:缺页率页面置换算法<br>算法:<br>注意T 为一个时间阈值．<br>保持追踪缺失发生概率:<br>    当缺失发生时,从上次页缺失起计算这个时间记录这个时间，t(last)是上次的页缺失的时间．<br>    如果发生页缺失之间的时间是”大”的，之后减少工作集如果．<br>    如果t(current) - t(last) &gt; T,之后从内存中移除所有在[t(last), t(current)]时间内没有被引用的页．<br>    没有被引用的页．<br>    如果这个发生页缺失的时间是”小”的，之后增加工作集．<br>    如果t(current) - t(last) &lt;= T，之后增加缺失页到工作集中． </p>
<p>图:页面置换算法实例</p>
<p>前三个不用管，因为就产生一次中断，到第二次页面中断才能应用该算法，<br>第四个时刻；4 - 1 &gt; 2,page(e)就是第五个页不在工作集内，被清理出去，缩小窗口．a在该时间段内没有被访问也被剔除．b添加进来．工作集变为（b,c,d）.<br>第五个时刻:没有变化<br>第六个时刻:有缺页变化, 6-4 &lt;= 2,符合算法的第二点，直接把e重新加入到工作集中来．新工作集（b,c,d,e）.<br>第七,八时刻: 没有变化<br>第九时刻: 有缺页中断，9 - 6 = 3 &gt; 2, b, d 没有被访问，剔除，a,c,e放在里边<br>第十时刻: 10 - 9 = 1,直接把缺的页面放到工作集中就行了．<br>工作集需要在每一个时刻调整工作集中的内容，而缺页率置换算法，只是在中断发生时，才会产生工作集调整．<br>这两个算法根据工作集和工作频度的大小来动态调整内存页的放入踢出情况．使得一些经常访问的页驻留在内存中．就全局运行的程序而言．全局置换算法优于局部页置换算法．</p>
<h4 id="抖动问题"><a href="#抖动问题" class="headerlink" title="抖动问题"></a>抖动问题</h4><p>其实就是对工作集和常驻集进行进一步讲解<br>工作集：程序在执行过程中对内存访问的固有属性，<br>常驻集: 指的是要把我们当前运行的程序要访问的那些页面放到内存里边来．</p>
<p>如果分配给一个进程的物理页面太少，不能包含整个的工作集，即常驻集是工作集的子集，那么进程将会造成很多的缺页中断，需要频繁地在内存与外存之间替换页面，从而使进程的运行速度变得很慢，我们把这种状态称为”抖动”<br>抖动产生的原因: 随着驻留内存的进程数目增加，分配给每个进程的物理页面数不断减小，缺页率不断上升．所以OS要选择一个适当的进程数目和进程需要的帧数，以便在并发水平和缺页率之间达到一个平衡．</p>
<p>如何量化页面抖动现象:<br>抖动问题可能会被本地的页面置换改善<br>更好的规则为加载控制:调整MPL所以:Better criteria for load cintrol:<br>Adjust MPL sot that :</p>
<ol>
<li>平均页缺失时间mean time between page faults(MTBF) = 缺页服务时间 page fault service time(PFST)</li>
<li>M(右旋转45度累加)WSi = 内存大小．<br>图：抖动问题的改动</li>
</ol>
<p>图横轴表示程序的多少，纵轴表示CPU的利用率．紫线图．<br>(MTBF)/(PFST) 蓝色表示，当蓝色线为1的点，就是最佳的时候．（尽可能改善了内存抖动现象）</p>
<p>如果一个程序耗费了很大的内存，也可能产生内存抖动现象．<br>内存抖动的主要原因就是需要的内存在硬盘，需要频繁的产生缺页中断，从而使得整个系统处于一个利用率很低的状态．<br>所以说系统需要全局页面置换算法的实现，来有效的缓解内存不够这种现象．同时来缓解内存不够这种现象．这是设计高效置换算法的原因．<br>实际过程中使用的算法更为复杂，这些只是一些简单的置换思路．<br>能力要求：　学完之后看到别的算法，能看出底层和置换顺序，给出一定的评价（评估，置换次数少者一般是优越的）</p>
<h4 id="进程的定义"><a href="#进程的定义" class="headerlink" title="进程的定义"></a>进程的定义</h4><p>进程的组成<br>一个进程应该包括:<br>    程序的代码:<br>    程序处理的数据；<br>    程序计数器数器中的值，指示下一条将运行的指令；<br>    一组通用的寄存器的当前值，堆栈；<br>    一组系统资源(如打开的文件)<br>总之，进程包含了正在运行的一个程序的所有状态信息．</p>
<p>进程和程序的联系（多对多的映射关系）<br>1, 程序是产生进程的基础<br>2. 程序的每次运行构成不同的进程（资源数据不同，所得到的结果也是不同的）<br>3. 进程是程序功能的体现<br>4. 通过多次执行，一个程序可对应多个进程；通过调用关系，一个进程可包括多个程序．（后半句是如果多个程序合在一起完成一个更大功能体现）</p>
<p>进程与程序的区别</p>
<ol>
<li><p>进程是动态的，程序是静态的；程序是有序代码的集合；进程是程序的执行，进程有核心态/用户态．（读取文件信息，操作系统代表地进程在内核中执行就是处于核心态）</p>
</li>
<li><p>进程是暂时的，程序是永久的；进程是一个状态变化的过程，程序可长久保存．</p>
</li>
<li><p>进程与程序的组成不同:　进程的组成包括程序，数据和进程控制块（即进程状态信息）（进程使用了程序的代码段，数据段，但是数据的处理不同比如输入和输出，以及为了管理进程信息建立的进程控制块等等．）<br>总的来说进程包括程序的部分也有自己独有的部分</p>
</li>
</ol>
<p>进程和程序的联系:类比<br>科学家做蛋糕问题<br>食谱= 程序,科学家 = CPU, 原料 =数据, 做蛋糕 = 进程.<br>科学家做蛋糕的过程就叫进程．<br>在坐蛋糕的过过程中会按照食谱（一条一条指令去做），蛋糕做完之后程序和进程都结束了，这就是程序和进程的对应关系．<br>做蛋糕途中儿子被狗咬了，给儿子处理伤口后，再回到做蛋糕．<br>体现了cpu的动态这一特性，也是第二件事优先级高于第一件事．（这是进程和程序没有的特性）</p>
<p>进程的特点</p>
<ol>
<li><p>动态性: 可动态的创建,结束进程;</p>
</li>
<li><p>并发性: 进程可以被独立调度并占用处理机运行；并发并行:</p>
<ol>
<li>并发: 指的是一段时间内有多进程在执行．如果时间很短，感觉是在一起执行一样．</li>
<li>并行:一个时刻多个进程能过同时执行．（所以说一个cpu只能执行一个进程，不能实现并发）．<br>如果需要执行别的进程就需要进行切换，所以说一个CPU在一段时内只能实现并发.<br>现在的机器存在多核（多个cpu）就能实现并行．</li>
</ol>
</li>
<li><p>独立性:不同进程的工作不相互影响．两个层面来看</p>
<ol>
<li>同过CPU调度，可能会受到第一个线程的影响，但是安全性（正确性）不受影响．就是一个进程的数据不会受到其他进程所破坏．怎么实现独立性呢？<br>这里提到了前边的页表，可以使不同的程序访问不同的地址空间，不可能越过这个地址空间，如果越过就会产生缺页异常（页错误）所以说页表是保证进程独立性的重要机制．cpu通过给不同的进程分配不同的页表，达到进程的独立性，这需要操作系统在内存管理上有一定的支持．</li>
</ol>
</li>
<li><p>制约性:因访问共享内存数据/资源或进程同步而产生制约．<br>　　进程进不可能完全独立，有可能还会有交互，或者说一个进程等另一个进程执行到一定阶段后才能执行另一个进程，两个进程间有一个时序的关系．这样进程间就会产生制约．也需要操作系统根据进程的特点来协调这些过程．那个时间执行进程ａ，那些时候执行进程ｂ，这涉及到进程间同步互斥的特点．</p>
</li>
</ol>
<p>图：进程的特点<br>ａ图：进程间的相互切换(动态性)<br>ｂ图: 地址空间相互独立<br>ｃ图: 不同时间的调度关系．需要操作系统去调度．执行那个进程．</p>
<p>问题:如果你要设计一个OS,怎么样来实现其中的进程管理机制?(思考！！！！！)</p>
<p>程序 =　算法　+ 数据结构<br>描述进程的数据结构:进程控制块(Process Control Block,PCB).<br>操作系统为每个进程都维护了一个PCB,用来保存与该进程有关的各种状态信息．</p>
<h4 id="进程的组成"><a href="#进程的组成" class="headerlink" title="进程的组成"></a>进程的组成</h4><h4 id="进程的特点"><a href="#进程的特点" class="headerlink" title="进程的特点"></a>进程的特点</h4><h4 id="进程控制结构"><a href="#进程控制结构" class="headerlink" title="进程控制结构"></a>进程控制结构</h4><p>如果进程存在PCB存在，如果进程消失PCB消失．（PCB是唯一的东西，是进程存在的唯一标识）．<br>进程控制块: 操作系统管理控制进程运行所用的信息集合．<br>操作系统用PCB来描述进程的基本情况以及运行变化的过程，PCB是进程存在的唯一标志．</p>
<p>使用进程控制块<br>进程的创建: 为该进程生成一个PCB;<br>进程的终止: 回收它的PCB;<br>进程的组织管理: 通过对PCB的组织管理来实现;</p>
<p>PCB具体包含什么信息?如何组织的?进程的状态转换….?</p>
<p>PCB包含以下三大类信息:<br>进程标识信息．如本进程的标识，本进程的产生者标识(父进程标识)；用户标识．<br>处理机状态信息保护区．保护进程的运行现场信息:<br>    1. 用户可见寄存器，用户程序可以使用的数据，地址等寄存器．<br>    2. 控制和状态寄存器，如程序寄存器(PC),程序状态字(PSW).<br>    3. 栈指针，过程调用/系统调用/中断处理和返回时需要用到它．</p>
<p>进程控制信息</p>
<ol>
<li>调度和状态信息，用于操作系统调度进程并占用处理机使用．(描绘出进程当前执行现状)</li>
<li>进程间通信信息，为支持进程间的与通信相关的各种标识，信号，信件等．这些信息存在接收方的进程控制块中．</li>
<li>存储管理信息，包含有指向本进程映像存储空间的数据结构．</li>
<li>进程所用资源，说明由进程打开，使用的系统资源，如打开的文件等．</li>
<li>有关数据结构连接信息，进程可以连接到一个进程队列中，或连接到相关的其他进程的PCB.</li>
</ol>
<p>PCB的组织方式<br>链表: 同一状态的进程其PCB成一链表，多个状态对应多个不同的链表．<br>　　　个状态的进程形成不同的链表:就绪链表，阻塞链表．</p>
<p>用链表的主要原因，因为进程的创建和删除是一个动态的过程，一会创建，一会删除，在组织里可以动态加入，动态删除的．</p>
<p>索引表: 同一状态的进程归入一个index表(由index指向PCB),多个状态对应多个不同的index表<br>      各状态的进行形成不同的索引表: 就绪索引表，阻塞索引表<br>      索引如果是数组的话动态的加入删除开销会大很多．所以更多来说大多数系统使用链表．如果进程确定，没有过多的删除生成操作，索引也不失为一种更快捷的方法．</p>
<p>进程状态．</p>
<ol>
<li>进程的生命期管理</li>
<li>进程状态变化模型</li>
<li>进程挂起模型</li>
</ol>
<h4 id="进程的生命期原理"><a href="#进程的生命期原理" class="headerlink" title="进程的生命期原理"></a>进程的生命期原理</h4><ol>
<li>进程创建</li>
<li>进程运行</li>
<li>进程等待</li>
<li>进程唤醒</li>
<li>进程结束</li>
</ol>
<p>进程创建<br>引起进程创建的三个主要事件:<br>    1. 系统初始化时；(init进程)<br>    2. 用户请求创建一个新进程:(init 来创建别的进程)<br>    3. 正在运行的进程执行了创建进程的系统调用；</p>
<p>进程运行<br>内核选择一个就绪的进程，让它占用处理机并执行<br>(下边两个问题涉及系统调度的问题)</p>
<ol>
<li>为何选择?</li>
<li>如何选择?</li>
</ol>
<p>进程等待<br>在以下情况下，进程等待(阻塞):<br>    1. 请求并等待系统服务，无法马上完成<br>    2. 启动某种操作，无法马上完成<br>    3. 需要的数据没有到达．</p>
<pre><code>进程只能自己阻塞自己，因为只有进程自身才能知道何时需要等待某种事件的发生．</code></pre>
<p>进程唤醒　<br>进程唤醒的原因:<br>    1. 被阻塞进程需要的资源可被满足<br>    2. 被阻塞进程等待的事件到达<br>    3. 将该进程的PCB插入到就绪队列．</p>
<pre><code>进程只能被别的进程或操作系统唤醒．</code></pre>
<p>进程结束<br>在以下四种情形下，进程结束:<br>    1. 正常退出(自愿的)<br>    2. 错误退出(自愿的)<br>    3. 致命错误(强制性的)(抢占了其他进程的空间死的形式3/4两种方式)<br>    4. 被其他进程所杀(强制性的)</p>
<p>图:进程的运行过程.</p>
<h4 id="进程状态变化模型"><a href="#进程状态变化模型" class="headerlink" title="进程状态变化模型"></a>进程状态变化模型</h4><p>进程的三种基本状态:<br>    进程在生命结束前处于且仅处于三种基本状态之一不同系统设置的进程状态数目不同．<br>    1. 运行状态(Running): 当一个进程正在处理机上运行时．<br>    2. 就绪状态(Ready):一个进程获得了除处理机之外的一切所需资源，一旦得到处理机即可运行．<br>    3. 等待状态(又称为阻塞状态Blocked):一个进程正在等待某一事件而暂停运行时．如等待某资源，等待输入/输出完成．</p>
<p>图：进程运行状态模型</p>
<p>进程其他的进程状态:<br>    1. 创建状态(new):一个进程正在被创建，还没被转到就绪状态之前的状态．<br>    2. 一个进程正在从系统中消失时的状态，这是因为进程结束或由于其他原因所导致．</p>
<p>图:进程五状态图<br>为什么运行的好好地就从运行态转变成就绪态?<br>由于每个就绪进程，操作系统都希望他得到执行，所以会给每个进程分配一个时间片(小的时间段)，然后CPU会执行，等到时间片运行完之后，就会变回到就绪态．让其他处于就绪态的进程能被执行．可以使的每个就绪态的进程可以公平的获得CPU的资源去执行．</p>
<p>可能的状态变化如下:<br>    NULL-&gt;new: 一个新进程被产生出来执行一个程序．(创建PCB,进行PCB的初始化（数据结构的定义）初始化为零)<br>    new-&gt;Ready: 当进程被创建完成并初始化后，一切就绪准备运行时，变为就绪状态．是否会持续很久?（PCB的初始化，所需资源准备完毕，就是初始化完毕）（初始化为一定的数据）．<br>    他不会持续很久，因为只是一个初始化，而且初始化会很快．<br>    以下两个步骤取决于时间调度算法．<br>　　Read-&gt;Running: 处于就绪状态的进程被进程调度程序选中后，就分配到处理机上来运行.<br>　　Running-&gt;Exit:当进程表示它已经完成或者因出错，当前运行进程会由操作系统作结束处理．<br>　　Running-&gt;Ready:处于运行状态的程序在其运行过程中，由于分配给他的处理机时间片用完而让出处理机.谁完成?<br>　　(因为同时存在多个就绪态进程，都得执行，所以划分时间片，所以会出现运行态到就绪态)<br>　　这里是操作系统来完成的，应用进程不是说能让出来就能让出来的．因为操作系统有会管理一个时钟．<br>　　Running-&gt;Block:　当进程请求某样东西且必须等待时.例如?<br>　　等待定时器，或者读写文件就比较慢．就会到阻塞态．<br>    Blocked-&gt;Ready:　当进程要等待某事件到来时，他从阻塞状态变到就绪状态，例如?<br>    当这个事件阻塞到某一件事件上边，当这个事件到来，就会从阻塞态变到就绪态．有操作系统完成．</p>
<h4 id="进程挂起"><a href="#进程挂起" class="headerlink" title="进程挂起"></a>进程挂起</h4><p>Why? 合理且充分的利用系统资源．<br>进程在挂起状态时，意味着进程没有占用内存空间．处在挂起状态的进程映像在磁盘上．这个时候进程是挂起的进程．<br>进程挂起：通俗来说进程没有占用内存空间，就是进程挂起．<br>前边说进程在内存中运行，怎么能不占用内存呢?<br>虚拟内存部分说到了，会把运行的一部分不用的空间，移到外存中去．腾出更多的空间给需要的进程去使用（以前说的运行的程序就叫进程）．<br>图：进程挂起</p>
<p>挂起状态两种</p>
<ol>
<li>阻塞挂起状态(Block-suspend): 进程在外存并等待某事件的出现，</li>
<li>就绪挂起状态(Ready-suspend):　进程在外存，但只要进入内存，即可运行．</li>
</ol>
<p>与挂起相关的状态转换<br>挂起: 把一个进程从内存转到外存:可能有一下几种情况:<br>    1. 阻塞到阻塞挂起: 没有进程处于就绪状态或就绪进程要求更多内存资源时，会进行这种装换，以提交新进程或运行就绪进程；<br>    2. 就绪到就绪挂起:当有优先级阻塞(系统一位会有很快就绪的)进程和低优先级先就绪进程时，系统会选择挂起低优先级就绪进程；<br>    3. 运行到就绪挂起: 对抢先式分时系统，当有高优先级阻塞挂进程因事件出现而进入就绪挂起时，系统可能会把运行进程转到就绪挂起状态．<br>    4. 阻塞挂起到就绪挂起（在外存中的状况）:当有阻塞挂起进程因相关事件出现时，系统会把阻塞挂起进程转换为就绪挂起进程．（但是进程所需要的资源，还是都存储在硬盘中的）．</p>
<p>与挂起相关的状态转换（续）<br>解挂/激活(Activate):把一个进程从外存转到内存；可能有一下几种情况：</p>
<ol>
<li>就绪挂起到就绪: 没有就绪进程或挂起就绪进程优先级高于就绪进程时，会进行这种转换．</li>
<li>阻塞挂起到阻塞: 当一个进程释放足够内存时，系统会把一个高优先级阻塞挂起（系统认为会很快出现所等待的事件）进程转换为阻塞进程；</li>
</ol>
<p>OS怎么通过PCB和定义的进程状态来管理PCB,帮助完成进程的调度过程?</p>
<p>用进程的观点来看待OS:用户进程，磁盘管理进程，中断进程…….<br>以进程为基本结构的OS:<br>    最底层为CPU调度程序(包括中断处理等)；<br>    上面一层为一组各式各样的进程；</p>
<p>状态队列</p>
<ol>
<li>由操作系统来维护一组队列，用来表示系统当中所有进程的当前状态；</li>
<li>不同的状态分别用不同的队列来表示(就绪队列，各种类型的阻塞队列)；</li>
<li>每个进程的PCB都根据它的状态加入相对应的队列当中，当一个进程的状态发生变化时，它的PCB从一个状态队列中脱离出来，加入到另外一个队列．</li>
</ol>
<p>图；状态表示方法</p>
<p>小结:<br>　　进程描述<br>    1. 进程定义<br>    2. 进程的定义和组成<br>    3. 进程控制结构</p>
<pre><code>进程状态
1. 进程的生命期管理
2. 进程状态变化模型
3. 进程挂起模型</code></pre>
<h4 id="为什么使用线程"><a href="#为什么使用线程" class="headerlink" title="为什么使用线程"></a>为什么使用线程</h4><p>线程管理<br>自提出进程概念以来，在操作系统中一直都是以进程为独立运行的基本单位，直到，<br>人们又提出了更小的能独立运行的基本单位—-线程．</p>
<ol>
<li><p>为什么使用线程?<br>案例　编写一个MP3播放软件．<br>核心功能模块有三个:</p>
<ol>
<li><p>从MP3音频文件中读取数据;</p>
</li>
<li><p>对数据进行解压缩;</p>
</li>
<li><p>把解压缩后的音频数据播放出来.<br>图:单进程的实现方法while循环实现三个函数．<br>问题来了:<br> 播放出来的声音是否连贯?<br> 各个函数之间不是并发执行，影响资源的使用效率;</p>
<p>图:多进程的实现方法<br>　　每个函数都写一个进程．形成三者之间有序的执行，像流水一样．（行云流水）实现高效的音频播放．<br>　　问题来了:<br>进程之间如何通信，共享数据?另外，维护进程的系统开销较大；创建进程时，分配资源，建立PCB;撤销进程时，回收资源，撤销PCB;进程切换时，保存当前进程的状态信息．</p>
<p>怎么来解决这些问题?<br>提出一种新的实体,满足以下特征:（这种实体不是进程，就是我们所说的线程）</p>
<ol>
<li>实体之间可以并发的执行；</li>
<li>实体之间共享相同的地址空间；</li>
</ol>
</li>
</ol>
</li>
</ol>
<ol start="2">
<li>什么是线程？<br>Thread: 进程当中的一条执行流程．<br>从两个方面重新理解进程前边是整合在一起的现在进程拆分成两部分．前边讲的进程中线程只有一个.<br>　　1. 从资源组合的角度;进程把一组相关的资源组合起来，构成了一个资源平台(环境），包括地址空间(代码段，数据段)，打开的文件等各种资源；<br>　　2. 从运行的角度:代码段在这个资源平台上的一条执行流程(线程)<br>线程共享该进程的资源，可以直接访问该进程提供的代码数据内存等等．<br>（TCB为线程控制块，不是进程控制块）只负责管理跟时间相关的一系列的流程信息，包含pc(程序计数器)sp(堆栈)一些不同的寄存器的信息，因为他有不同的执行流控制流，控制流需要一些列的寄存器来表示执行状态．堆代码段数据段是所有线程所共享的．有各自独立的部分和共同拥有的部分．</li>
</ol>
<p>线程　＝　进程　－　共享资源<br>线程的优点:</p>
<ol>
<li>一个进程中可以同时存在多个线程．</li>
<li>各个线程之间可以并发的执行．</li>
<li>各个线程之间可以共享地址空间和文件等资源．<br>线程的缺点:一个进程在处理资源时出现错误，就会导致别的线程的资源也会出现错误．（安全可靠性没有保障）<br>一个线程崩溃，会导致其所属进程所有线程崩溃．整个进程也就结束了．</li>
</ol>
<p>应用场景:<br>比如高性能计算，水利天气预报计算，这里用的是线程．不容易出现错误，<br>另一方面像intnet 的服务，比如打开一个网页就可以用一个线程去实现很快，一个线程崩溃之后，就会导致所有页面崩溃，就会导致这个浏览器崩溃．（早期浏览器采用线程机制实现，现在浏览器采用进程机制实现）<br>性能不是瓶颈安全性成为瓶颈，在这种情况下采用进程方式实现，例子chrome浏览器，就是一个进程打开一个网页，意味这一个网页崩溃后不会影响到其他进程访问的网页，（这就是进程和线程的区别他们各自有各自的特点，依据特点选取所需）</p>
<p>图：不同操作系统对线程的支持<br>早期的MS-DOS 就是单进程单线程的模式，<br>早期的Unix是多进程单线程的模式．<br>现在的Windows_NT, linux 等就是支持一个进程以及一个进程里边多线程的模式．</p>
<p>图:线程所需的资源(续) (重要)（线程区别进程，就是两种资源一种独占的一种共享的，所有独占的资源都跟他的控制执行相关的．需要把这些信息单独的保护起来，避免线程之间状态的破坏）<br>基于几个进程（小框是进程的资源）（寄存器和堆栈是每个线程独有的）共享的是数据段代码段文件网络资源等<br>左图为单线程流<br>右图为多线程流</p>
<p>进程和线程的比较:</p>
<ol>
<li><p>进程是资源(内存，文件，网络)分配的单位，线程是CPU调度单位（cpu执行控制流相关的信息）;</p>
</li>
<li><p>进程拥有一个完整的资源平台，而线程只独享必不可少的资源，<br>　　如寄存器和栈；</p>
</li>
<li><p>线程同样具有就绪，阻塞和执行三种基本状态，同样具有状态之间的转换关系．（和进程是一样的）</p>
</li>
<li><p>线程能减少并发执行的时间和空间开销；<br>　　1. 线程的创建时间币进程短；（进位进程在创建进程时还要去创建一些其他的信息去管理，比如内存的管理，大的文件怎么去管理，线程直接重用了进程创建好的资源．）<br>　　2. 线程的终止时间比进程短；（同理他不需要考虑那些资源的释放问题，终止的时间也会短）<br>　　3. 同一进城内的线程切换时间比进程短；(在同一进程中的线程，切换也会很快，同一个进程的线程拥有一样的页表，早切换过程中不需要切换内存管理所需要的页表，而进程切换需要把页表也要进行切换掉，切换页表的开销很大，因为涉及到他们访问也表的物理地址空间是不一样的，很多catch和TLB 那些信息都会无效，需要重新加载，这里的开销很大，线程由于共享一个页表信息可以重用，不需要切换页表)<br>　　4. 由于同一进程的各线程间共享内存和文件资源，可直接进行不通过内核的通信．（不通过内核，直接物理地址读取，效率会很高．）<br>综上说是，线程实行的时间效率空间开销比进程要高．</p>
</li>
<li><p>线程的实现．</p>
</li>
<li><p>多线程编程接口举例．</p>
</li>
</ol>
<h4 id="什么是线程"><a href="#什么是线程" class="headerlink" title="什么是线程"></a>什么是线程</h4><h4 id="线程的实现"><a href="#线程的实现" class="headerlink" title="线程的实现"></a>线程的实现</h4><h4 id="上下文切换"><a href="#上下文切换" class="headerlink" title="上下文切换"></a>上下文切换</h4><p>各个进程之间是共享cpu资源的，在不同时候，进行cpu切换，让不同的进程占用cpu执行．切换的过程称为进程的上下文切换．<br>停止当前运行进程(从运行状态改变成其他状态)并且调度其他进程(转变成运行状态)（各种信息存放在进程控制块中，在切换过程中，需要把要换的进程的控制块中的信息，恢复到cpu中执行．）<br>图:进程切换图(这部分的信息，主要是硬件完成的，这部分代码有的是汇编语言)</p>
<ol>
<li>必须在切换之前存储许多部分的进程上下文</li>
<li>必须能够在之后恢复他们，所以进程不能显示它曾经被暂停过．</li>
<li>必须快速(上下文切换时非常频繁的)．</li>
</ol>
<p>需要存储什么上下文?</p>
<ol>
<li>寄存器(PC,SP,…),cpu状态,…</li>
<li>一些时候可能会费时，所以我们应该尽可能避免．</li>
</ol>
<p>上下文切换的开销越小越好，这样我们就能让进程有更多的时间做必须要做的事情去了．</p>
<p>操作系统为活跃进程准备了进程控制块(PCB)<br>操作系统将进程控制块(PCB)放置在一个合适的队列里．</p>
<ol>
<li>就绪队列</li>
<li>等待i/o队列(每个设备的队列)</li>
<li>僵尸队列</li>
</ol>
<p>图:操作系统控制块队列</p>
<h4 id="进程控制-创建进程"><a href="#进程控制-创建进程" class="headerlink" title="进程控制-创建进程"></a>进程控制-创建进程</h4><p>和上一个重复了</p>
<h4 id="进程控制-加载和执行进程"><a href="#进程控制-加载和执行进程" class="headerlink" title="进程控制-加载和执行进程"></a>进程控制-加载和执行进程</h4><p>系统调用exec()加载程序取代当前运行的进程．<br>图:系统调用exex()加载程序取代当前运行的进程<br>pid 三种情况 </p>
<ol>
<li>pid== 0　代表子进程</li>
<li>pid&gt;0　</li>
<li>pid&lt;0 失败的进程调用</li>
</ol>
<p>图:exrc()复制过程<br>执行fork()代码和数据都复制了一份,执行完exec()的时候，pid 有了变化，用户态的进程空间中的代码段被新的程序所替换和执行的数据都变了．整个程序的控制流都发生了变化．<br>图:exec在内存中的布局图.</p>
<ol>
<li>Exec()调用允许一个进程”加载”一个不同的程序并且在main开始执行(事实上_start)</li>
<li>它允许一个进程指定参数的数量(argc)和它字符串参数数组(argv).</li>
<li>如果调用成功<br>　　1. 他是相同的进程…<br>　　2. 但是它运行了一个不同的程序!!</li>
<li>代码,stack(栈)&amp;heap(堆)重写.</li>
</ol>
<p>fork()的简单实现;</p>
<ol>
<li>对子进程分配内存</li>
<li>复制父进程的内存和CPU寄存器到子进程里</li>
<li>开销昂贵</li>
</ol>
<p>在99%的情况里，我们在调用fork()之后调用exec()</p>
<ol>
<li>在fork()操作中内存复制是没有作用的 </li>
<li>子进程将可能关闭打开的文件和连接</li>
<li>开销因此是高的</li>
<li>为什么不能结合他们在一个调用中(os/2, windows)?<br>由于fork(),重复拷贝了一个空间，exec()进行了数据可代码的初始化所以内存空间进行了fork()时是一个无用的copy操作．如何优化呢.<br>Uxix系统中的优化手段，vfork()创建一个虚拟空间．</li>
</ol>
<p>vfork();(早起Unix系统改进手段)</p>
<ol>
<li>一个创建进程的系统调用，不需要创建一个同样的内存映像．</li>
<li>一些时候称为轻量级fork()</li>
<li>子进程应该几乎立即调用exex()</li>
<li>现在不再使用如果我们使用Copy on Write (cow)技术．<br>cow技术: 写的时候进行复制．<br>运用cow技术：只复制父进程的源数据，页表，指向的是同一块地址空间，当父进程或者子进程进行写操作的时候，会触发异常，无论是父进程还是子进程，把触发异常那个页制为两份，这样使得父进程和子进程用于两个不同的地址了．可以实现不同情况按需写的情况的复制，如果都是读数据确实没必要复制，因为指向的同一块内存，只有在进行写的时候才需要复制．<br>这样的话不管有没有exec(),执行fork()都产生一个子进程，而且这样效率还很块，因为他只复制了源数据页表等等．然后根据是否进行写操作，来决定是否需要复制，这就是cow技术．是进程和内存之间相互支撑的一种技术．</li>
</ol>
<p>问题：<br>有没有什么方法，只用一个fork()系统调用，不用考虑exec(）执行还是不执行．<br>结合之前的内存管理考虑，操作系统各个子系统是相互支持相互帮助的，通过虚存管理就能实现一个高效的fork()机制．</p>
<h4 id="进程控制-等待和终止进程"><a href="#进程控制-等待和终止进程" class="headerlink" title="进程控制-等待和终止进程"></a>进程控制-等待和终止进程</h4><p>wait()系统调用是被父进程用来等待子进程的结束</p>
<ol>
<li>一个子进程向父进程返回一个值，所以父进程必须接受这个值来处理</li>
<li>wait()系统调用担任这个要求<br>　　1. 他使父进程去休眠来等待子进程的结果<ol start="2">
<li>当一个子进程调用exit()的时候，操作系统解锁父进程，并且将通过exit()传递得到的返回值作为wait调用的一个结果（连同子进程的pid一起）如果这里没有子进程存活，wait()立刻返回.</li>
<li>当然，如果这里有为父进程的僵尸等待，wait()立即返回其中一个值(并解除僵尸状态)．</li>
</ol>
</li>
</ol>
<p>问题直接让子进程结束exit()就可以了，为什么还要父进程来等待呢（为什么要有wait()）？<br>一个进程exit()，结束之后，进程的资源会不会被系统回收掉，缺失操作系统会把当前进程所占用的资源打开的文件进行关闭和释放．这确实可以做完，但是有一个很难去掉，比如操作系统内代表进程存在那个东西，就是进程控制块，进程控制块是代表进程存在的唯一标识．释放了这些空间后，只能说明这个进程回不到用户空间继续执行了．但是操作系统内核里边还在帮你完成回收操作，在这个时刻，把所有资源释放后，虽然用户空间不能执行了，但是内核态还有进程的相关资源．比如说PCB它本身回收就比较困难，就好像自己把自己拎起来一样．自身完成不了的事情，就让父进程来帮忙完成．所以子进程在执行完成后，会返回，通过操作系统通知父进程，如果父进程正在执行一个wait()操作的话，就会知道子进程执行了exit()这个操作，子进程退出了系统调用，父进程还收到了子进程执行完毕的信号，wait会有一个返回值，这时父进程就可以帮助子进程完成最后一步帮助子进程把它在内存中的资源释放掉．主要即使我们所说的子进程的PCB,这个就是靠父进程的wait()完成．<br>wait()和exit()两个一起完成子进程的所有资源的回收．<br>wait(pid),参数等待的进程．</p>
<p>进程结束之后，它调用exit()<br>这个系统调用:</p>
<ol>
<li>将整个程序的”结果”作为一个参数</li>
<li>关闭所有打开的文件，连接等</li>
<li>释放内容</li>
<li>释放大部分支持进程的操作系统结构</li>
<li>检查是否父进程是否存活着的；<br>　　1. 如果是的话，他保留结果的值直到父进程需要它；在这种情况里，进程没有真正死亡，但是他进入了僵尸状态．<br>　　2. 如果没有，他释放所有数据结构，这个进程死亡．</li>
<li>清理所有等待僵尸进程　<br>进程终止是最终的垃圾收集(资源回收)</li>
</ol>
<p>在子进程执行完exit()后，父进程还没执行网wait(),这是他不属于任何状态(就绪态等状态．因为他已经没法回到用户态执行了)这个就是僵尸状态．要死没死的状态叫僵尸状态．</p>
<p>问题来了：如果父进程先于子进程死了，是不是没法回收资源了,PCB一直留在内存中?<br>如果是这样的操作系统中处于僵尸态的进程越来越多，操作系统的设计思路: 进程都有父子关系，第一个进程称为祖宗进程(root进程)，他会定期的扫描进程控制块的链表，是否有进程处于僵尸状态，如果有进程处于僵尸状态，他会代替父进程完成资源回收过程（wait操作），这样就会使得操作系统中不会以后更多的僵尸进程存在．这也是让操作系统更好的管理系统采取的更有效的办法．</p>
<p>图:加上僵尸进程的六状态图<br>注意running 后边的两个状态，资源不够blocked态，资源程序条件都到位了就执行exit()函数.</p>
<h4 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h4><p>上下文切换</p>
<ol>
<li>切换CPU当前任务,从一个进程/线程到另一个</li>
<li>保存当前进程/线程在PCB/TCP中的执行上下文(CPL状态)</li>
<li>读取下一个进程/线程的上下文<br>CPU调度</li>
<li>从就绪队列中挑选一个进程/线程作为CPU将要运行的下一个进程/线程</li>
<li>调度程序:挑选进程/线程的内核函数(通过一些调度策略)</li>
<li>是么时候进行调度?<br>在进程/线程的生命周期中的什么时候进行调度?<br>状态转变的时候，尤其是就绪态到运行态，从运行态到等待状态，或者是从运行态到结束态等．这些状态这是就应该考虑是否让新的进程让CPU执行，或者让当前进程从CPU撤下来，这就是调度的时机或者是调度点，涉及调度，就要考虑调度的这些位置．<br>对应用程序而言它是以用户态的应用程序存在的两种情况（对应下边的可抢占和不可抢占）</li>
<li>　不可抢占 一个程序启动后，从开始到结束不允许被打断（早期操作系统实行的非抢占式的调度策略）这种策略确保了这个进程一旦启动别的进程不能打断它了．这就不得不让下一个进程等着这个进程执行完毕才能执行，<br>如果有急需使用的进程还得等第一个进程结束，所以效率不高．</li>
<li>可抢占<br>操作系统来根据需求进行进程的切换，会根据操作系统来觉定该时刻是否要进行进程的换入换出．</li>
</ol>
<p>内核里存在一个状态是否可以抢占？<br>分析两种1.用户态是否能抢占 2.内核态是否能抢占<br>当一个用户进程，执行系统调用，如果这个系统调用在内核中不会导致这个进程处于等待状态，就是他还是处于运行状态的时候，当这个进程在正常返回的时候，他一定返回到发起这个进程的进程继续执行．也就意味着内核中不会出现抢占现象．（不会在内核中发生切换，切换到另一个进程去执行了．）只要从系统调用到内核态，自身不会出现从运行态到阻塞态的变化，操作系统就可以确保，回去之后一定是发起进程的那个进程去执行．（这就是内核的不可抢占）</p>
<p>如果在内核当中也允许去抢占，在内核中执行系统调用，由一个进程发起的，由一种特殊事件的产生，需要当前内核进行切换，切到另一个优先级更高的进程，一旦进程返回的时候，就可能返回到另一个程序，这样的就是抢占式内核．</p>
<p>内核运行调度程序的条件(满足一条即可)</p>
<ol>
<li>一个进程从运行转台切换到等待状态</li>
<li>一个进程被终结了</li>
</ol>
<p>不可抢占<br>调度程序必须等待事件结束</p>
<p>可以抢占</p>
<ol>
<li>调度程序在中断被响应后执行</li>
<li>当前的进程从运行切换到就绪，或者一个进程从等待切换到就绪</li>
<li>当前运行的进程可以被换出．</li>
</ol>
<h4 id="调度原则"><a href="#调度原则" class="headerlink" title="调度原则"></a>调度原则</h4><p>原则是: 基于什么去选择合适的进程去执行</p>
<ol>
<li>调度策略</li>
<li>程序执行模型<br>执行模型:程序在CPU突变和I/O中交替<br> 图:执行模型:程序在CPU突变和io交替(突增的原因，可能进程在读文件，io较多，读完io就自然降低了)<br>　　1. 每个调度决定都是关于下一个CPU突变将哪个工作交给CPU<br>　　2. 在时间分片机制下，线程可能在结束当前CPU突发前被迫放弃CPU.<br>CPU繁忙或者IO繁忙，如何协调进程才能更充分的利用CPU.</li>
<li>比较调度算法的准则<br>设计算法的指标　<br>　　1. CPU利用率吧:<br>　　　　CPU处于忙状态所占时间的百分比<br>　　2. 吞吐量:<br>　　　　在单位时间内完成的进程数量<br>　　3. 周转时间:等待时间越少越好<br>　　　　包括两部分：等待时间和运行时间<br>　　　　启动之后要等待一段时间才能被CPU执行称为等待时间<br>　　　　服务时间：进程执行程序的时间<br>　　　　一个进程从初始化到结束，包括所有等待时间所花费的时间　　<br>　　4. 等待时间:和上边的不一样．<br>　　　　进程在就绪队列中的总时间　<br>　　5. 响应时间:<br>　　　　从一个请求被提交到产生第一次相应所花费的总时间．</li>
</ol>
<p>人们通常都需要”更快”的服务<br>什么是更快：响应时间快<br>　　1. 传输文件是的高宽带<br>　　2. 玩游戏时的低延迟<br>　　3. 这两个因素都是独立的<br>和水管类比；响应时间快和时间吞吐量大都是对快的一种体现．<br>　　1. 低延迟:喝水的时候想要一打开水龙头水就流出来<br>　　2. 高宽带:给游泳池冲水时希望从水龙头里同时流出大量的水，并且不介意是否存在延迟<br>所以说对快的不同需求，就会对快有不同的指标．</p>
<p>我们的目标<br>　　1. 减少响应时间<br>　　　及时处理用户的输出并且尽快将输出提供给用户<br>　　2. 减少平均相应时间的波动<br>　　　在交互系统中，可预测性比高差异低平均更重要　　　<br>　　3. 增加吞吐量－两个方面（这两个指标是有矛盾的，在实际中只能实现其中一个）<br>　　　减少开销(操作系统开销，上下文切换)<br>　　4. 减少等待时间<br>　　　减少每个进程的等待时间<br>　　<br>根据不同需求设计不同算法：<br>低延迟调度增加了交互式表现<br>　　如果移动鼠标，但是屏幕中的光标却没动，我可能重启计算机<br>但是操作系统需要保证吞吐量不受影响<br>    我想结束长时间的编程，多以操作系统必须不时进行调度，即使存在许多交互任务<br>吞吐量是操作系统的计算带宽<br>响应时间是操作系统的计算延迟．</p>
<ol start="4">
<li>吞吐量vs延迟</li>
<li>公平的目标<br>公平的定义<br>举例</li>
<li>保证每个进程占用相同的CPU时间</li>
<li>这公平么?如果一个用户比其他用户运行更多的进程怎么办．</li>
</ol>
<p>举例<br>保证每个进程都等待相同的时间</p>
<p>公平通常会增加平均响应时间</p>
<h4 id="调度算法1"><a href="#调度算法1" class="headerlink" title="调度算法1"></a>调度算法1</h4><p>三部分入手</p>
<ol>
<li>最基本(一般的)的调度算法<br>　1. FCPS(先来先服务)<br>　　　图：FIFO队列的规定(注：average response time 是平均响应时间，而不是周转时间)<br>　　　图中1,2对比，如果第一个进来的进程时间特别长后边的进程时间越来越短，会造成平均相响应时间变长，图二进行一下调整短的在前长的在后，是的平均响应时间变短，响应更快．（后边的短进程优先的调度算法）<br>　　　优点:<br> 　　简单<br> 　缺点:<br>　　　　1. 平均等待时间波动较大<br>　　　　2. 花费时间少的任务可能排在花费时间唱的任务后面<br>　　　　3. 可能导致i/o和CPU之间的叠加处理.(没有考虑抢占)<br>　　　　　　CPU密集型进程会导致I/O设备闲置时，i/O密集型进程也在等待．<br>　　　　<br>　2. SPN(SJF) SRT(短进程优先（短作业优先）短剩余时间优先)<br>　　　　图:短任务优先<br>　　　　总的来说执行时间决定了它的优先级，执行时间越短，优先级越高．<br>　　　　问题来了：在Running运行过程中，wait()中来了一个比running运行的进程优先级更高，怎么办．两种策略.<br>　　　　1. 放到就绪队列最前边，我还执行原来的进程，不会被打断．（非抢占方式）（SJF,SPN）<br>　　　　2. 比如图中的pw,时间片是9,在完成一个时间片后变成8,这时候来了一个pa,执行时间为5,比较一下，pa执行时间更小，这是就要完成抢占，当前运行的进程，从运行态到就绪态，重新挂回到就绪队列里边去，让新来的pa占用cpu执行．（最短调度时间优先的策略Shortest-Remaining-Time(SRT)）最短剩余时间<br>第二种是第一个的变种，只是考虑了抢占．</li>
</ol>
<p>　　优点：最优平均等待时间（和前一个算法比较标准）<br>　　　图:最优平均等待时间　<br>　　　图：中SJF是有序的　XYZ是无序的时时间对比<br>　　　c[i]表示进程执行时间(两个R中间的时间)．<br>　　问题:<br>    　　可导致饥饿<br>    　　　　1. 连续的短任务流会使长任务饥饿<br>　　　　　　2. 短任务可用时的任何任务的CPU时间都会增加平均等待时间．<br>　　　　需要预知未来（无法知道进程的结束时间）<br>　　　　　　1. 怎么预估下一个CPU突发的持续时间<br>　　　　　　　2. 简单解决办法:询问用户<br>　　　　　　3. 如何用户欺骗就杀死进程<br>　　　　　　4. 如果用户不知道怎么办．<br>　　　　无法预估进程的结束时间，解决办法．<br>　　　　根据这个进程的历史情况，来预估接下来的执行．比如上一分钟这个进程执行了10秒，上上一分钟执行了2秒这样的历史．通过公式来预估下一个时间段执行的时长．<br>　　　　图:未来预算公式 τ：这次的预算，ｔ这次的时间，ａ一个概率维护这个准确性．黄框中的局部推导，下边是展开．<br>　　　　图:估计情况<br>　　　<br>　　　<br>　3. HRRN(最高相应比优先)<br>最短任务优先考虑了执行时间，没有考虑进程的等待时间，如果等待时间考虑进去就会的到新的算法，依据是下边的R公式．Ｒ越大意味着等待时间越长，就优先调度R.(就是最高响应比的意思)就可以设计一种交互性响应性更好的一种调度算法．目前不考虑抢占，我们完全可以设计一种可以抢占的算法！！！！！和SPN一样，进程的结束时间很难预估，只能去预估．这是它存在的两个问题．<br>对于前面两个算法充分考虑的进程的等待时间．前边的饥饿现象得到了有效的缓解．<br>　　1. 在SPN调度的基础上改进<br>　　2. 不可抢占<br>　　3. 关注进程等待了多长时间<br>　　4. 防止无限期推迟<br>　　　　R = (W + S)/S　　W：waiting time 等待时间，S:service time 执行时间<br>　　　　选择R值最高的进程，
　　
　　</p>
<p>　4. Round Robin(轮循)<br>　　轮循算法让各个进程轮流占用cpu去执行．这是他的特点．<br>　　图轮循图<br>　　图：轮循算法例子<br>　　时间片设置为20 ，超过20的执行完换出，不够20的实行进程所需时间换出．<br>　　甘特图就是　时间片执行不同线程的例子．体现的特点是公平，<br>　　衡量算法重要的指标:<br>    1. 等待时间，图中以p1等待时间为例，第一次没等待，到执行完成一共的等待时间，<br>    2. 平均等待时间，总的时间除以进程数量是每个进程的等待时间，他是很大的．<br>    该算法总结:<br>        时间片的大小设置很重要．设置的太大，就会退化成FIFO先来先服务．设置时间片是一个很讲究的事情，一般根据经验，比如linux早起unix设置为1%秒．随着性能提高，现在的linux设置为千分一秒，实现片很小才能让进程得到充分的调度．这是他的一个特点．总体而言我们想要做好一个ＲＲ调度算法，我们尽可能把上下文切换尽量控制在一个小的范围之内．1%以内这是可以接受的范围,99%的时间用在执行上，这个开销还是值得的．<br>        1. RR花销:额外的上下文切换(对比FIFO算法)<br>        2. 时间量子太大:<br>            1. 等待时间过长<br>            2. 极限情况退化成FCFS<br>        3. 时间量子太小:<br>            1. 反应迅速，但是…<br>            2. 吞吐量由于大量的上下文切换开销受到影响<br>        4. 目标:<br>            1. 选择一个合适的时间量子<br>            2. 经验规则:维持上下文切换开销处于1%以内．<br>　　　图RR的不同窗口实例<br>　　　　从图中可以看出有的时候FIFO比RR的新能还好，只要是因为FIFO没有上下文切换的消耗．但是FIFO不能像RR算法那样对每个进程得到及时的响应．公平性上有一定的代价，牺牲了公平性，如果把时间长的服务放到前边，平均等待时间更长了．所以说FIFO更大的去取决于任务的顺序，如果是短任务先来就类似短任务优先的算法，</p>
<p>有没有兼顾前面这些的算法呢？多级队列．<br>　5. Multilevel Feedback Queues (多级反馈队列)<br>　　由于一开始就会把进程优先级划好，但是执行过程中会导致优先级变化（比如该阶段会要求交互性比较高，后一个阶段会要求做大量的计算处理，所以说在不同阶段他的特点是不一样的，）有没有一种可以动态调整不同队里中的进程优先级的算法．就是我们所说的多级反馈队列．<br>　　1. 就绪队列被划分成独立的队列<br>　　　　E.g 前台(交互)，后台(批处理)<br>　　2. 每个队列拥有自己的调度策略<br>　　　　E.g 前台,—RR后台–FCFS<br>　　3. 调度必须在队列间进行<br>　　　　固定优先级<br>　　　　　1. 先处理前台，然后处理后台<br>　　　　　2. 可能导致饥饿．<br>　　　　时间切片<br>　　　　　1. 每个队列都得得到一个确定的能够调度其进程的CPU总时间<br>　　　　　2. E.g 80%给使用RR的前台，20%给使用FCFS的后台．</p>
<p>　　图：一个进程可以在不同的队列中移动（重点必看）<br>　执行时间越长优先级越低．特征是:在进程执行过程中，动态调整进程的优先级．从而使得io密集型的任务，可以很快得到执行．CPU密集型优先级逐渐逐渐的降低，这样符合通常我们在计算机系统中执行程序的特点．我们希望交互性好的进程，优先得到执行，特别消耗计算机资源的程序，优先级低，跑的慢一些没有关系．可以让它在交互性任务执行完毕的情况下，执行消耗资源的任务．</p>
<p>前边的算法或多或少的考虑到了公平的问题．<br>下边的算法重点强调了公平　<br>　　<br>　6. Fair Share Schediling(公平共享调度)<br>每个用户拥有的进程资源是不同的怎么在用户这个层面实现一个进程的公平．（公平共享算法需要重点考虑的内容）最新的linux采取的公平调度策略，设计上也是考虑到了不同级别设计上实现公平调度的机制（CFS调度）<br>图:三种评测方法.<br>最后加到真实的计算机中进行检测（细节可能被忽略在前边三种测评方法中）也受到计算机硬件本身的影响．<br>　<br>2. 嵌入式实时的调度算法<br>3. 多核处理器的调度算法</p>
<p>总结:<br>    1. FCFS先来先服务：不公平，平均等待时间较差<br>    2. SPN/SRT短进程优先:<br>        1. 不公平，但是平均等待时间最小<br>        2. 需要精确预测计算时间<br>        3. 可能导致饥饿<br>    3. HRRN最高响应比优先: 等待时间考虑进去<br>        1. 基于SPN调度改进<br>        2. 不可抢占<br>    4. Round Robin 轮循:<br>        公平但是平均等待时间较差（上下文切换多度）<br>    5. MLFQ多级反馈队列:（可以进程的优先级动态调用，操作系统可以根据这个特点动态调度）<br>        和SPN类似<br>    6. Fair-share Schediling 公平共享调度:　更多考虑用户的请求在不同级别(用户级别，进程级别，还是用户主的级别等)公平的占用CPU的调度．<br>        公平是第一要素</p>
<h4 id="调度算法2"><a href="#调度算法2" class="headerlink" title="调度算法2"></a>调度算法2</h4><h4 id="实时调度"><a href="#实时调度" class="headerlink" title="实时调度"></a>实时调度</h4><p>实时调度系统主要用: 火车，机床或者是嵌入式的工厂的控制环境，他需要确保某些任务在规定时间完成．规定时间指的是在未来的某段时间必须完成某个事情．这个就是如约态，时间是确定的，在操作系统中某个任务或事物在以进程的形式在执行过程中，能够满足实时的特征，确定性和可预测性是实时系统最大的特点，</p>
<p>实时系统分为两类:<br>    1. 硬实时(强实时系统):如果某个任务在规定时间不完成会引起灾难性后果<br>        需要在保证的时间内完成重要的任务，必须完成<br>        比如控制水坝，如果不能在规定时间内把水放掉，水就会把水坝淹过去了，产生灾难性后果．<br>    2. 软实时(弱实时系统):尽量完成，比如看视频，规定每秒60帧，如果不能完成可能会掉帧．可鞥你会引起观看者不太满意的后果．但是不会产生严重的后果．<br>        要求重要的进程的优先级更高，尽量完成，并非必须．</p>
<p>定义:<br>    正确依赖于其时间和功能两方面的一种操作系统．<br>性能指标:<br>    1. 时间约束的及时性<br>    2. 速度和平均性能相对不重要<br>主要特性:<br>    时间约束的可预测性．</p>
<p>如何衡量一个进程是否完成实时的需求？<br>图:进程衡量<br>Released:发起一个任务．对应进程的就绪．就绪之后不能马上执行，等一段时间之后才能执行．<br>图中的蓝色部分表示执行任务部分．<br>结束时间就是蓝色条结束位置．<br>最后一部分还有一个deadline,就是期限．执行时间不能超过这个期限，超过了实时性就不能得到满足．<br>relative deadline 相对的期限．<br>absolute deadline　绝对期限．</p>
<p>图:一系列相似的任务<br>执行时间为　蓝色区域，执行周期为5.<br>执行时间e,在(0,p),不能超过P.<br>利用率用:e/p表示．<br>对应前边的事情产生的:<br>    1. 硬时限:<br>        1. 如果错过了最后期限，可能会发生灾难性或非常严重的后果．<br>        2. 必须验证: 在最坏的情况下也能够满足时限吗?<br>        3. 保证正确性．<br>    2. 软时限:<br>        1. 理想情况下，时限应该被最大满足．如果有时限没有被满足，那么就相应地降低要求．<br>        2. 尽最大努力去保证．</p>
<p>基于硬时限和软时限的算法设计时限:<br>    表示一个实时系统是否能够满足deadline要求<br>    1. 决定实时任务执行的顺序,以下为两种不同的实时系统调度算法．（对应前边的FCFS静态调度算法，RR动态调度算法）.<br>    2. 静态优先级调度:<br>        在执行前就得把优先级确定．根据优先级来选择任务在规定时间完成．<br>    3. 动态优先级调度:<br>        任务的优先级会根据任务的动态变化，这就会影响任务在不同时刻他的优先级有所区别，所以会优先调度，也可能会延迟调度．</p>
<pre><code>图:两种实时调度算法.(了解)</code></pre>
<h4 id="多处理器调度与优先级反转"><a href="#多处理器调度与优先级反转" class="headerlink" title="多处理器调度与优先级反转"></a>多处理器调度与优先级反转</h4><p>如何确保把处理器均匀的分配给每个任务．不会存在一个特别忙别的特别闲这种情况，这样就浪费了我们计算机系统资源．这是就需要追求一种负载平衡．<br>多核处理器调度考虑的两个问题:<br>    1. 放到哪个CPU上去．<br>    2. 如何让整个系统处于负载平衡的状态．<br>    其实在一个CPU内跟前边的调度是一样的，只是调度算法本身还需要动态的探测其他CPU忙和闲的情况．来完成负载均衡这种情况，这是多处理器调度需要考虑的问题．</p>
<p>多处理器的CPU调度更加复杂:<br>    1. 多个相同的单处理器组成一个多处理器<br>    2. 优点: 负载共享<br>对称多处理器(SMP):<br>    1. 每个处理器运行自己的调度程序<br>    2. 需要在调度程序中同步．</p>
<p>优先级反转问题:<br>    1. 可以发生在任何基于优先级的可抢占的调度机制中．<br>    2, 当系统内的环境强制使高优先级任务等待低优先级任务时，发生．</p>
<pre><code>图:NASA火星车重启问题
简化的；当前火星车上有三个进程执行，T1,T2,T3三个进程．T1优先级最高，T2优先级居中，T3优先级最低．正长情况下通过操作系统调度，执行就完成了．但是如果T1不能按时完成，他就会重启这个系统，一般不会出现这种情况，那么为什么出现这种情况，分析图:
    横轴是时间轴，纵轴是三个进程．
    先是T3开始执行t1-t2,到t2会访问一个共享资源，执行到t3时候，T1出现了，说T1准备好了可以执行了，因为T1的执行优先级比T3高．所以就开始执行T1中的第一个块，执行完灰块（涉及到那块共享资源前），就返回到T3那块已经被T3占有的共享资源，因为共享资源被T3占用，T1没办法访问，就会切换到T3.T3 继续从t4开始执行到t5,这个时候T2来了，T2优先级比T3更高．执行T2,T2抢占cpu执行．执行时间长短取决于T2的任务长短，这个时候会出现，T1的优先级高，但是得等待T2的执行．因为T2抢占了T3的CPU去执行，T1等待T3,导致T3的执行时间被T2的执行延长了．使得不能使T1不能在规定时间完成任务，使系统觉得系统处于不稳定状态．会导致系统重启．这就出现了低优先级任务影响高优先级任务．

    基于上述问题提出的解决办法:
    其一:
    低优先级任务继承高优先级任务的优先级依赖于他们共享的资源．
        由于T3在访问一个共享内存，等到T1准备就绪执行，这时共享资源还没被T3用完，所以动态的把T3的优先级提升到和T2一样，这时T2就不能抢占T3了，T3就能尽快把占用共享资源的操作尽快执行完毕．从而可以使得T1继续执行．
    图:低优先级继承高优先级
    其二:运行开始就会进行一下共享资源的统计，给共享资源确定一个优先级，资源的优先级等于最高进程的优先级，当一个进程占用共享资源去执行，一旦执行之后我的优先级就会和共享资源的优先级一样（或者说提升），这样就能确保他的优先级很高，在执行过程中，除非他的优先级超过共享资源的优先级才只能继续执行，否则就要进行等待．这一部分我们就能保证一旦访问了共享资源，就能保证能完成对这个共享资源的操作．然后离开，不会让别的进程等待更多的时间．
        1. 优先级天花板: &quot;资源&quot;的优先级和&quot;所有可以锁定该资源的任务中优先级最高的那个任务&quot;的优先级相同．
        2. 除非优先级高于系统中所有被锁定的资源的优先级上限，否则任务尝试执行临界区的时候会被阻塞．
        3. 持有最高优先级上限信号量锁的任务，会继承被该锁所阻塞的任务的优先级．</code></pre>
<h4 id="背景知识"><a href="#背景知识" class="headerlink" title="背景知识"></a>背景知识</h4><p>到目前为止:<br>    还没讲到的多个进程的交互，交互会引起他们对共享资源的访问，如果这些资源处理不当的话，就会出现我们意想不到的情况．比如饥饿死锁等一些列的问题．为什么出现这些问题，还跟我们上节课说的调度相关，如果进程独立（1.没有访问共享资源，没有去使用同一个资源 2.他们之间不需要交互（通知你干什么事情，或者给你发某些数据））．<br>    1. 多道程序(multi-programming):现代化系统的重要特性．<br>    2. 并行很有用(为什么?)提示:多个并发实体:CPU(s),I/O,…,用户,…<br>    3. 进程/线程:操作系统抽象出来用于支持多道程序设计<br>    4. CPU调度:实现多道程序设计的机制<br>    5. 调度算法-不同的策略<br>本周和下周:<br>    协同多道程序设计和并发问题．</p>
<p>独立的线程:<br>    1. 不和其他线程共享资源和状态<br>    2. 确定性-&gt;输入状态决定结果<br>    3. 可重现-&gt;能够重现起始条件,I/O<br>    4. 调度顺序不重要．(调用顺序是不确定的)<br>合作线程:<br>    1. 在多个线程中共享状态<br>    2. 不确定性<br>    3. 不可重现<br>不确定性和不可重现意味着bug可能是间歇性发作的．</p>
<p>进程间的合作有这么多风险，我们还需要合作吗？合作也是必须要做到的，因为首先资源是共享的，有可能多进程访问一块内存，访问同一个文件，这跟我们日常生活中一样，很多人在一个银行里边存钱取钱，也是一个道理，第二个可以通过系统的并行或并发的操作，可以提高系统的效率，实现更有效的资源的利用，前边讲过，把一个大的任务拆分成若干小的任务，通过流水或者并行的执行来提升整个系统的性能，提高系统的效率．第三可以把大的工作设置成小的工作，这样具有一定的模块化，这个是软件工程设计过程中必须要考虑的问题，模块化后，不同的模块之间需要完成相应的共享的，交互的，这点使得这种现象在别的地方也是经常存在的．所以说合作的进程是普遍存在的．既然有不可确定很难重现的问题，就有办法来避免这些问题．</p>
<p>进程/线程，计算机/设备需要合作<br>优点1: 共享资源:<br>    1. 一台电脑，多个用户<br>    2. 一个银行存款余额，多台ATM机<br>    3. 嵌入式系统(机器人控制:手臂和手的协调)<br>优点2: 加速:<br>    1. I/O操作和计算可以重叠<br>    2. 多处理器–将程序分成多个部分并行执行．</p>
<p>优点3: 模块化:<br>    1. 将大程序分解成小程序<br>    　　以编译为例，gcc会调用cpp, cc1, cc2, as, 1d.</p>
<pre><code>2. 使系统易于扩展</code></pre>
<p>有这么多不确定的现象吗？来个例子:<br>  程序可以调用函数fork()来创建一个新的进程:<br>      1. 操作系统需要分配一个新的并且唯一的进程ID<br>      2. 因此在内核中，这个系统调用会运行<br>      操作系统维护了一个全局变量，等有新的进程把这个值付给进程就ｏｋ了．<br>     　　new_pid = next_pid++; 共享全局变量，原子操作?<br>      3. 翻译成机器指令:<br>          1. LOAD next_pid Reg1  把new_pid赋值给寄存器1<br>          2. STORE Reg1 new_pid  把寄存器1的值加载（存）到new_pid中去．<br>          3. INC Reg1　寄存器进行加1操作.<br>          4. STORE Reg1 next_pid 把值赋值给next_pid<br>    假设两个进程并发执行:<br>        1. 如果next_pid等于100,那么其中一个进程得到的ID应该是100,另一个进程的ID应该是101,next_pid应该增加到102.</p>
<pre><code>    图:多进程并行
    图中执行完两句汇编语句后，就进行了上下文切换，进程从进程1到进程2的切换．进程2执行完他所需要的四句汇编指令后，再完成一次调度，从进程2切换到进程1,完成剩下部分语句的执行．两个进程中得到的PID都是100, next_pid 变为101.
    总的流程来看:先把new_pid赋值给寄存器1,把寄存器1的值赋值给new_pid,new_pid这时是100,进入进程2中的操作，会把new_pid赋值为100,next_pid变为101,到这里没有异常，一旦从进程2切换到进程1,需要注意进程1,会给寄存器1进行加1操作，这个时候寄存器1还是等于100,按道理说进程2的pid被赋值为100,进程1 会变成101了，可是他却是100,为什么呢?? 更奇怪的现象，next_pid都变成了101了.并没有变成102.因为寄存的值依然保存着100,因为切换会进程1,寄存器的值保存了进程2中的值，使得new_pid不可改变．这是一种典型的异常现象．调度点可以在四条语句中任何一部分切换，产生不同的结果．
    综上我们希望线程1得到pid 为100，线程2等到pid 为101;最后的next_pid是102.这是理想情况．
    无论多个线程的指令程序怎样交替执行，程序都必须正常工作:
        1. 多线程程序具有不确定性和不可重新的特点
        2. 不经过专门设计，调度难度很高．
    不确定性要求并行程序的正确性:
        1. 先考虑清楚问题，把程序的行为设计清楚
        2. 切忌急于着手编写代码，碰到问题再调试．</code></pre>
<p>为了解决这些不确定性原因，引入了同步和互斥．<br>上边的现象我们称为(竞态条件)</p>
<p>系统缺陷: 结果依赖于并发执行或者事件的顺序/时间:<br>    1. 不确定性<br>    2. 不可重现</p>
<p>怎样避免竞态?<br>让指令不被打断．</p>
<p>原子操作(对于刚才那个例子就是四条汇编指令执行完不被打断，就是原子性,不可被打断就是排除不确定性因素的方法，但是在实际的操作系统中，那四条指令是可以被打断的，必须通过某种软硬件结合的方式，使得这四条指令按照一种原子操作的方式来执行，而不是说随时可以被打断的方式来执行)<br>图:A和B两个线程相互竞争小栗子<br>如果说ｃ语言一条语句就确定为一个原子操作，不会像上边那样，一个ｃ指令变为四个汇编指令．是不是就可以避免掉了？这个例子说明即使在c语言保证了原子操作，也不能避免出现别的情况．<br>图中谁赢呢? 如果先调度a,就a赢，调度b,就b赢．还有可能两种结果都不能输出来．这种奇怪的现象如何产生的呢？就是比如在线程A做到i = i + 1的过程，产生线程切换B线程执行的是i = i - 1，这样就相当于i的值没有变化，就有可能线程A和线程B都在while循环里边出不来.都无法取得最后的胜利，取决于调度的序列，在某一种调度算法下就可能出现这种情况．</p>
<p>下边介绍相应的同步互斥方法:<br>    1. （Critical section）临界区:  临界区是进程中的一段需要访问共享资源并且当另一个进程处于相应代码区域时便不会被执行的代码区域（相当于前边说的进程A和进程B共同访问的共同资源是全局变量i，访问共享资源的代码被称为临界区）．<br>    2. (Mutual exclusion)互斥:当多个进程同时访问一个临界区的时候就会产生不确定性的结果．<br>         当一个进程处于临界区并访问共享资源时，没有其他进程会处于临界区并且访问任何相同的共享资源．<br>　　3. (Dead lock) 死锁:(两个进程拥有自己的资源，同时还需要其他资源的时候，比如进程A等待进程B的资源，进程B等待进程A的资源，就会出现相互等待，这样锁在一起了，称为死锁，谁也执行不了．)<br>    两个或以上的进程，在相互等待完成特定任务，而最终没法将自身任务进行下去.<br>    4. (Strvation)饥饿:<br>        一个可执行的进程，被调度器持续忽略，以至于虽然处于可执行状态却不被执行．</p>
<p>原子操作是指一次不存在任何中断或者失败的执行:<br>    1. 该执行成功结束<br>    2. 或者根本没有执行<br>    3. 并且不应该发现任何部分执行的状态．</p>
<p>实际上操作往往不是原子的:<br>    1. 有些看上去是原子操作，实际上不是<br>    2. 连x++这样的简单语句，实际上是由三条指令构成的．<br>    3. 有时候甚至连单条机器指令都不是原子的:<br>        Pipeline, super-scalar,out-of-order, page fault.</p>
<p>引入了同步和互斥重要的原因就是解决不确定性．</p>
<h5 id="一些概念part1"><a href="#一些概念part1" class="headerlink" title="一些概念part1"></a>一些概念part1</h5><p>操作系统中的问题和显示生活中的问题的类比:<br>    1. 更好的帮助你理解现实生活的问题<br>    2. 但是,计算机比人更蠢．</p>
<p>例如: 人需要协调:<br>栗子:两个人一起住，共享一个面包，两个人相当于两个进程．<br>图:买面包的栗子<br>不同人不同时刻做了同样的事情，导致面包买多了．</p>
<p>什么是”面包太多”问题的正确性质?以下两个问题如何解决?<br>　1. 最多有一个人去买面包<br>　2. 如果需要，有人回去买面包．<br>　<br>例如,在冰箱上设置一个锁和钥匙:<br>    1. 去买面包之前锁住冰箱并且拿走钥匙<br>    2. 修复了”太多”的问题: 要是有人想要果汁怎么办?<br>    3. 可以改变”锁(lock)”的含义.<br>    4. “锁(lock)”包含”等待(waiting)”</p>
<p>lock(锁): 在们，抽屉等物体上加上保护性装置，使得外人无法访问物体内的东西，只能等待解锁后才能访问．<br>Unlock(解锁):打开保护性装置，使得可以访问之前被锁保护的物体类的东西．<br>Deadlock(死锁):</p>
<p>如果把冰箱全都锁住锁的粒度太大．因为整个冰箱还有其他的东西，这就需要一种轻量级的锁．轻量锁的诞生．</p>
<p>使用便签来避免购买太多面包:<br>    1. 购买之前留下一张便签(一种”锁(lock)”);<br>    2. 买完后移除该便签(一种”解锁”);<br>    3. 如果存在便签就不要购买面包(在便签被移除之前一直等待).</p>
<p>仔细思考，如果两个进程同时执行这一条逻辑的话，还是会出现多买面包的情况．进程之间会发生上下文切换，也就意味着进程A正在执行，就可能被调度切换到另一个进程去执行．这种情况下是不是存在某种调度策略，调度两个进程出现奇怪的现象．</p>
<p>图: 某种进程调度:<br>    1. 判断没面包<br>    2. 判断标签<br>    3. 上下文切换到进程2,判断没面包，<br>    4. 判断没标签.<br>    5. 上下文切换到进程1,去买面包放标签.<br>    6. 切换到进程2,然后进程2去买面包，方标签<br>这样产生了一个不太友好的结果，就是又买了两份面包.<br>并没有满足只让一个人(进程)去买面包的操作.就让控制逻辑失效了.<br>下一次再被调度时，可能不按这个顺序调度了</p>
<p>结果:<br>    1. 偶尔情况下还是会购买太多面包!<br>    2. 线程可以得到检查面包和标签之后，购买面包之前切换的上下文．</p>
<p>该解决方案由于间歇性的失败，使得问题更糟了:<br>    1. 使问题更加难以调试<br>    2. 必须做调度器所做的事情．</p>
<p>简单来说采用note的机制不能满足要求.</p>
<p>修改标签行数，快速修复:将便签(note)放在第一位<br>图: 将留便签放在第一位<br>进程1,先贴标签，然后进程上下文切换到进程2,再进行贴标签，然后两个进程都能判断有标签，所以都不会往下边执行．<br>会发生:不会有人买面包.<br>也不是我们想产生的．</p>
<h5 id="一些概念part2"><a href="#一些概念part2" class="headerlink" title="一些概念part2"></a>一些概念part2</h5><p>上一部分是part2.</p>
<h5 id="一些概念part3"><a href="#一些概念part3" class="headerlink" title="一些概念part3"></a>一些概念part3</h5><p>是不是因为note没有一个标识，标明是哪个进程的标签．<br>标签细化看谁标记的标签．<br>图:为便标签增加标签<br>考虑能否满足要求:<br>    1. 需要买面包一定能买到?<br>    2. 不会出现买到多余面包这种情况.</p>
<p>还是不行，进程1，贴上标签1，进程上下文切换，切换到进程2然后再贴上标签2，都无法满足两个进程中的if()中的判断，最后使得两个进程都无法执行的情况．</p>
<p>可能导致没有线程去买面包:<br>    错误时间的上下文切换可能会导致每个线程都认为另外一个线程会去买面包</p>
<p>最难处理的:<br>    1. 极其不可能发生的事情也会发生在糟糕的时间<br>    2. 就像UNIX中的一些事情.</p>
<p>这种锁定状态叫做”饥饿”．</p>
<p>进程1就是循环判断标签2是否存在,如果存在，进程1就会进入忙等状态，进程2就是判断标签1的存在与否，如果存在就会把标签2去掉,<br>if 换成了while语句实现mZ两种逻辑.<br>图:更加复杂的两种便签方案<br>可以解决我们的两个问题:<br>    1. 需要买面包一定能买.<br>    2. 不会出现买到多余面包这种情况.<br>可以看出进程A能购买面包的概率会大一些，或者说进程A和进程B同时贴标签，共同竞争资源时，A获胜的概率大一些.<br>产生的问题:<br>    1. 这只是两种进程，多个进程如何应用．<br>    2. 从我们的调度，或者从我们进程的设计来说，我们希望设计一种方法让他们是均等的，让A和B均等获取买面包的事情.刚才设计让A获得概率更大一些，B获得的概率更小一些．这种不对称性，不是我们所期待的．我们期待的是同等概率，同等竞争.</p>
<p>解决方案3为每个线程保护了一段”临界区”<br>代码 :<br>    if(nobread){<br>        buy bread;<br>    }<br>Critical section(临界区<br>    只能一个进程执行，如果一个进程在执行时，其他的进程只能等待．不能同时进来．<br>临界区是指进程中的一段需要访问共享资源并且当另一个进程处于相应代码区域时便不会被执行的代码区域.</p>
<p>Mutual exclusion(互斥)<br>    确保一个进程在临界区，就成为互斥．这样就会出现不确定性那种情况．<br>当一个进程处于临界区并访问共享资源时，没有其他进程会处于临界区并且访问任何相同的共享资源.</p>
<p>总的来说：为了让代码在临界区互斥的进行.</p>
<p>抽象来说:<br>  1.即使在买面包前后加上，进入临界区，和退出临界区代码．<br>图: 临界区代码<br>退出临界区后，就会把等待队列的进程唤醒执行．<br>这个时候就需要我们设计一个进入和退出临界区的时限.</p>
<p>接下来设置进入和退出临界区的时限.</p>
<h4 id="临界区"><a href="#临界区" class="headerlink" title="临界区"></a>临界区</h4><p>临界区特征:</p>
<ol>
<li>互斥:同一时间临界区中最多存在一个线程. </li>
<li>Progress: 如果一个线程想要进入临界区，那么他最终会成功．</li>
<li>有限等待:　如果一个线程i处于入口区，那么在i的请求被接受之前,其他进程进入临界区的时间是有限制的．（如果是无线的等待就是饥饿现象．）对第二条的补充．</li>
<li>无忙等待(可选): 如果一个进程在等待进入临界区，那么在它可以进入之前会被挂起．（如果能确保临界区能很快相应，就进行忙等，如果不能确保临界区及时相应(或执行之间比较长)，忙等效率会很低，导致系统利用率不够．以前就是while死循环忙等）.</li>
</ol>
<p>下边是三种方法，对临界区代码的一种保护．</p>
<h5 id="方法1-禁用硬件中断"><a href="#方法1-禁用硬件中断" class="headerlink" title="方法1: 禁用硬件中断"></a>方法1: 禁用硬件中断</h5><p>进入和离开临界区的代码:</p>
<ol>
<li>ENTER_CRITICAL_SECTION</li>
<li>EXIT_CRITICAL_SECTION</li>
</ol>
<p>基本的机制:</p>
<ol>
<li>禁用中断</li>
<li>软件方法(例如, Peterson算法)</li>
<li>更高级的抽象</li>
</ol>
<p>比较不同的机制<br>  性能: 并发级别</p>
<p>第一种方法开始讲解:<br>当进程进行调度的时候，很重要一个中断就是时钟中断，有了这个中断，即使这个进程正在被执行，也能被打断，切换到我们操作系统来，操作系统可以完成一个调度切换到其他进程去执行,这个中断让我们操作系统有了强制打断进程正常执行完成进程切换的能力，这个能力本来用在操作系统做进程调度很重要的一个机制，但是这也是导致前面不确定结果的很重要的一个原因，因为他随时可以切换，如果执行临界区的一段代码，执行的过程中不予许它切换，就没有问题了，这段代码就会得到一个确定的结果．所以说我们在进入临界区之前把这个中断屏蔽了，退出临界区后再重新恢复这个中断．<br>禁止硬件中断,这些中断都是响应外设或者是网络包磁盘块读写等的内容来的，如果屏蔽了中断系统对这些事件没有办法及时的响应，第二个呢，临界区整个的执行长短是不确定的如果很长就会对系统的影响很大，所以说用屏蔽中断的方法有一定的局限性，仅限于临界区非常小的这种情况是有效的．还要注意一点，如果两个线程由两个cpu并行的执行的话，中断机制只屏蔽其中一个cpu的中断机制是不行的．所以说中断机制对多cpu的情况是有限制的．如过只有一个cou屏蔽了中断，另一个cou继续相应中断，就没有办法解决这个互斥问题．</p>
<p>一旦中断被禁用,线程(进程)就无法被停止:</p>
<ol>
<li>整个系统都会为你停下来 </li>
<li>可能导致其他线程处于饥饿状态．</li>
</ol>
<p>要是临界区可以任意长怎么办:</p>
<ol>
<li>无法限制响应中断所需的时间(可能存在硬件影响)<br>要小心使用.</li>
</ol>
<p>没有中断，没有上下文切换，因此没有并发</p>
<ol>
<li>硬件将中断处理延迟到中断被启用之后． </li>
<li>大多数现代计算机体系结构都提供指令来完成．<br>进入临界区:</li>
<li>禁止中断.</li>
</ol>
<p>离开临界区:</p>
<ol>
<li>开启中断</li>
</ol>
<h5 id="方法2-基于软件的解决方案"><a href="#方法2-基于软件的解决方案" class="headerlink" title="方法2:　基于软件的解决方案"></a>方法2:　基于软件的解决方案</h5><p>图:两个线程的代码逻辑<br>设计思想: 如果满足有进程想进入临界区就能让该线程在一定的时间内进入临界区，满足这些特性就说明这个设计是可行的．</p>
<p>图:皮特森算法:<br>进程进入临界区有一定的顺序，根据次序来确谁进入临界去，比如有两个进程，图中turn 就能取值0和1.<br>能满足互斥但是有时不满足progress.<br>举个例子:比如进程0,在进入临界区之后，就干其他事去了．他就不再访问临界区了，进程1在完成一次临界区操作后，想再次进入临界区，这时候发现，他在离开临界区的时候，turn就被复制成0,导致它再次执行while 循环，turn不为1,就会一直循环.而进程0就不想在进入临界区，就不会执行那段临界区代码了，使得我们进程1无法继续前进．看一看满足的性质满足互斥，但是不满足（一定可以往前走属性）原因就是我们上边所说的，0进程撤出做别的事情，1进程无法进行再次执行临界区的资源.完成这两个属性就必须让两个线程交替执行，每一个都不能离开，一旦一个离开另一个也不能执行了．这是一种不很理想的情况．</p>
<p>改进思路: 用一个flag[i] = 1表示进程i是否准备好进入临界区别.</p>
<p>图:临界区改进不可前进部分<br>如果flag[j] = 0的话，就会跳出while循环，表示j进程不想进入临界区，就把当前i进程赋值为1进行执行．执行完成后flag就会赋值为0,表示进程1<br>不需要进入临界区了，就把临界区资源让给别的进程．退出临界区．这里考虑一下是否满足临界区的属性．<br>满足不了互斥的条件．因为在刚开始每个flag[] 都被初始化0,只有在执行到第二步的时候，才会被赋值为1,也就意味着当两个进程同时执行，都会跳过while循环,被赋值为1,(f[0]不为1，就去执行f[1],否则同理)，就会使得两个进程同时得到执行，就会同时执行临界区代码,不存在互斥，都会出现都买面包的问题，这样就无法保证互斥．如果flag[i] 的赋值语句和while(flag[j])互换顺序，会产生什么问题,由于刚开始就被赋值了1,所以产生互斥的问题解决了，但是可能会出现两个进程都在while循环里边谁都进不去的情况（死锁情况），实例是第一个进程被被赋值为1,之后然后调度到进程2，导致这两个进程都变为了1，所以都不会进入下边来执行．谁都跳不出while循环,这样就变成了死锁.所以说简单的代码换位置来实现并不可行．软件实现并不是想象中的那么容易．<br>正确解法皮特森的解法:把刚才的几种方法综合起来解决问题.<br>图:皮特森解法<br>加入了turn 指示谁该进入临界区<br>boolean flag[] 指示进程是否准备好进入临界区</p>
<p>进入临界区，flag[i] = TRUE, turn = j(另一个进程)(这里边如果i = 0, j就是1,否则反过来), while(flag[j] &amp;&amp; turn == j)表示轮到j进入临界区也该到j进入临界区.只能让给j去执行.只要一种不满足就会跳出循环，退出临界区flagp[i] = false就可以了（表示我不需要进入临界区了）<br>图: 皮特森算法代码<br>反证法证明　互斥，有限等待和前进三个属性，</p>
<p>戴克斯算法也能解决:<br>图: 戴克斯算法(了解)</p>
<p>皮特森算法以上研究的是针对两个进程，下一步进行算法扩展,能对n个进程.<br>思路:对于进程i而言，他前边有进程要进入临界区或等待进入临界区，i就会等待，i进程后边的进程也需要等待i进程执行完成后，才能进入临界区，前提是i想进入临界区,实现n个进程循环进入临界区的大致的思路.</p>
<p>第二个 Bakery算法<br>图:Bakery算法<br>比如去银行取钱，首先拿一个票号，然后根据票的大小来安排取钱的顺序，如果有两个发票号的地方，如果不同人领到相同的票号，就会比较身份正好安排先后顺序.<br>拿号进临界区.先比较拿到的号，如果拿到的号一样就比较进程号的大小．</p>
<p>图:临界区部分总结</p>
<h5 id="方法3-更高级的抽象（基于原子操作的指令）"><a href="#方法3-更高级的抽象（基于原子操作的指令）" class="headerlink" title="方法3:　更高级的抽象（基于原子操作的指令）"></a>方法3:　更高级的抽象（基于原子操作的指令）</h5><p>大多数现代体系结构都提供特殊的原子操作指令:<br>    1. 通过特殊的内存访问电路<br>    2. 针对单处理器和多处理器</p>
<p>Test-and-Set 测试和置位:(第一个特殊指令)<br>    1. 从内存中读取值<br>    2. 测试该值是否为1（然后返回真或假）<br>    3. 内存值设置为1.</p>
<p>交换:(第二个特殊指令)<br>    1. 交换内存中的两个值.<br>这两个特殊指令实现了，就很容易实现临界区的进入和退出操作．</p>
<p>图:两个命令的实现<br>既然封装成命令了，也就意味着执行这三条指令时不可以被打断.就是所说的原子操作.(三条指令之间不会产生中断或者上下文切换，只有执行完毕后才可以)<br>设计步骤:<br>    图:test-and-set代码<br>    1. 把内存单元设置为一个lock中的Value．初始值为零代表谁还没用这个lock.<br>    2. 接下来某一个进程想进入临界区，就先获得这个lock,Lock::Acquire().做完test-and-set(Value)之后，返回值为零跳出while循环,从而进入临界区执行，如果Value被赋值为1,那么返回也是1,就会在while里边等待(忙等)<br>    3. 对于退出临界区而言就是lock的release()操作,就简单的把value的内存单元赋值为0就ok了．<br>    4. Value为零，就会跳出Acquire()中的while 循环了.下一个就会执行.从这里可以看出了，除了可以支持两个进程之外还可以支持多个进程的互斥操作.进入临界区和退出临界区很简洁.<br>当一个进程在进行忙等状态时，就可以让他进入睡眠,把忙等的进程，挂到等待队列中去，让他进行睡眠，如果为0,就会退出临界区，然后唤醒wait队列里的进程．</p>
<p>图:无忙等待.<br>如果临界区很短的时候，我们更喜欢忙等待（因为他不需要像刚才那种方式那样完成上下文切换，因为上下文切换会是一种开销比较大的操作，如果临界区很长，远远大于上下文切换的开销，我们更希望基于上下文切换非忙等的方式，来实现同步互斥的机制，针对某种应用来选择用合适的方式来实现．）<br>以上部分都是基于 test-and-set()实现的，我们还讲了echange指令，我们能不能实现这种功能呢?<br>也是可以的<br>while(test-and-set(Value))如果临界区过长，忙等消耗的cpu比较多，用什么办法让他不忙等呢?思考!!!<br>使用忙等待的锁:<br>    1. 就像上面使用test-and-set实现的锁一样.<br>    2. 线程在等待的时候消耗cpu周期.</p>
<p>echange 完成进入临界区和退出临界区的概念:<br>    有一个lock和key的两个值,初始化key为1, 当k为1,就会执行exchange(),把lock和key进行转换,key 变成0了，一旦Key为零了就会跳出第一个while循环,就会进入临界区去执行了，进入临界区lock值就会从0变成1,当另一个进程进入临界区的时候lock是1,Key也是1,就不会跳出循环，进入不了临界，直到处于临界区的进程完成后，把lock赋值为0,下一个进程才可以去执行（处于忙等状态的进程，第一个执行exchange的进程就能得到进入临界区的机会）．</p>
<pre><code>优点:
    1. 适用于单处理器或者共享主存的多处理器中任意数量的进程.
    2. 简单并且容易证明.
    3. 可以用于支持多临界区.</code></pre>
<p>　　缺点:<br>    　　1. 忙等待消耗处理器时间<br>    　　2. 当进程离开临界区并且多个进程在等待的时候可能导致饥饿(多进程抢占Block,可能存在多个进程抢不到的情况)<br>    　　3. 死锁:<br>        　　如果一个低优先级的进程拥有临界区并且一个高优先级进程也需求，那么高优先级进程会获得处理器并等待临界区.(如果高优先级进程获得处理器，低优先级进程就没有机会拿到处理器去释放锁)．（这里就可以通过前边讲到的优先级反转的方法，解决死锁的问题）.</p>
<p>锁是更高级的编程抽象:<br>    1. 互斥可以使用锁来实现<br>    2. 通常需要一定等级的硬件支持<br>常用的三种实现方法:<br>    1. 禁用中断(仅限于单处理器)<br>    2. 软件方法(复杂)<br>    3. 原子操作指令(单处理器或多处理器均可)<br>可选的实现内容:<br>    1. 有忙等待<br>    2. 无忙等待</p>
<h4 id="背景知识-1"><a href="#背景知识-1" class="headerlink" title="背景知识"></a>背景知识</h4><p>知识回顾总结:<br>    1. 并发问题:竞争条件(镜态条件):<br>        1. 多程序并发存在大的问题<br>    2. 同步:<br>        1. 多进程共享公共数据的协调执行<br>        2. 包括互斥与条件同步<br>        3. 互斥:在同一时间只有一个线程可以执行临界区<br>    3. 确保同步正确很难?:<br>        1. 需要高层次的编程抽象(如:锁)<br>        2. 从底层硬件支持编译.</p>
<p>图:临界区概念模型.</p>
<h4 id="信号量"><a href="#信号量" class="headerlink" title="信号量"></a>信号量</h4><p>进入临界区后并不只是进行写操作，在进行读操作的时候就没有必要限制一个进程或者线程的必要了，这个时候就需要更高级的手段来应对这种情况．可以通过信号来实现这种机制.</p>
<p>抽象数据类型:<br>    1. 一个整形(sem),两个原子操作.sem就是信号量,下是对信号量的操作.通常所说的P,V操作.<br>    2. p():sem减1, 如果sem &lt; 0, 等待，　否则继续.<br>    3. v():sem减1, 如果sem &lt;= 0,唤醒一个等待的P.</p>
<p>图:信号量(sem)和PV操作<br>举例子：图下的小火车.<br>信号量为2,就是两个线程(资源)，一个进程来进行p()操作，两个线程占用，执行完一个调用一次V()操作，一个线程的小火车就走了，唤醒另一个小火车，再执行P()操作，小火车进来．</p>
<p>图：信号量PV的含义(ｐｖ来自荷兰语，加减的意思).</p>
<h5 id="信号量的使用"><a href="#信号量的使用" class="headerlink" title="信号量的使用"></a>信号量的使用</h5><p>信号量是整数<br>信号量是被保护的变量:<br>    1. 初始化完成后,唯一改变一个信号量的值的办法是通过P()和V()<br>    2. 操作必须是原子<br>P()能够阻塞,V()不会阻塞(因为P()操作需要进行减操作，减少为零后，就得等待(就是阻塞))<br>我们假定信号量是”公平的”:<br>    1. 没有线程被阻塞在P()仍然堵塞如果V()被无线频繁调用(在同一个信号量)<br>    2. 在实践中，FIFO经常被使用.(后来的放到尾部，从头部开始取)</p>
<p>锁有没有先等先被唤醒的机制呢?思考!!!</p>
<p>两种类型信号量:<br>    1. 二进制信号量: 可以使0或1(模拟clock为0或者1)<br>    2. 一般/计数信号量:可取任何非负值．(如果是正整数就可以让多个执行p操作的进程，进入后续操作)主要体现在lock中只有一个进程执行，而在信号量中允许多个进程执行．所以说信号量除了可以用在互斥同步中还能用在条件同步的情况．<br>    3. 两者相互表现(给定一个可以实现另一个)<br>信号量可以用在2个方面:<br>    1. 互斥<br>    2. 条件同步(调度约束—-一个线程等待另一个线程的事情发生).</p>
<p>用二进制信号量实现的互斥:<br>    模拟lock的话，就要把初始值设置为1, 在临界区前设置P操作，在临界区之后设置V操作.(这是二进制信号量的常用法完全可以代替前边的lock用法．)<br>    除了完成互斥操作，还需要完成同步的操作．这个时候就得把初值设置为0.<br>    举例子:现在有两个线程A 和B,线程A要等到线程B执行到某个语句之后才能执行,怎么确定这一点，我们可以用信号量来完成,在线程A的前边加上p()操作，使信号量变成-1,线程挂起，然后等到B线程执行到V()操作，使得信号量变为0,才能唤醒进程A来执行.总的来说想先执行的代码写再V()的前边．<br>    互斥操作: 目标进程进入临界区时seg = 1 -1 = 0,如果其他进程进入临界区是，seg = 0 - 1 = -1,需要等待.</p>
<p>一个线程等待另一个线程处理事情:<br>    1. 比如生产东西或消费东西．<br>    2. 互斥(锁机制)是不够的．</p>
<p>例如:有界缓冲区的生产者—消费者问题:<br>    1. 一个或多个生产者产生数据将数据放在一个缓冲区<br>    2. 单个消费者每次从缓冲区取出数据<br>    3. 在任何一个时间只能一个生产者或消费之可以访问该缓冲区.</p>
<p>例子: 有一个Buffer,要有生产者和消费者，生产者要向里边写数据，消费者要读数据，生产者写数据的时候，消费者不能做相应的操作，但是可以多个生产者都往里边写数据，这里跟我们的clock是不一样的，clock只能是一个生产者或者一个消费者在做操作．但是这个不一样，我们有多个生产者往里边写东西．也可以有多个消费者从里边读数据.到底有几个主要是设置信号量的初值来完成.这里还有同步的地方,Buffer为空的时候，消费者再从里边读取数据就不行了，只能进行睡眠，只能等有一个生产者往里边写了数据之后，才会唤醒睡眠的进程，同理buffer满了，就会生产者等待消费者了．</p>
<p>正确性要求:<br>    1. 在任何一个时间只能一个线程操作该缓冲区(互斥)<br>    2. 当缓冲区为空，消费者必须等待生产者(调度/同步约束)<br>    3. 当缓存区满，生产者必须等待消费者(调度/同步约束)</p>
<p>每个约束用一个单独的信号量:<br>    1. 二进制信号量互斥<br>    2. 一般信号量fullBuffers<br>    3. 一般信号量emptyBuffers</p>
<p>那么多对buffer的影响,我们可以用信号量来完成对添加或者取出这样的互斥的保障.<br>如果Buffer还有空间,就需要唤醒等待消费者,还需要唤醒生产者让他产生更多的数据,需要两个信号量完成同步的操作.<br>就是上边的1, 2, 3,表示的,<br>图:互斥量完成图<br>mutex 互斥信号量<br>fullBuffers 初值是0,<br>emptyBuffers 设置为Buffer的大小n,<br>Deposit(c) 生产者函数(中添加队列不为空的条件,互斥量,添加信息完,互斥量更新,emptyBuffers加1通知缓冲区有数据了)<br>Remove(c) 消费者从缓冲区移除(消费者和生产者刚好相反.开始fullBuffer值为零,进入睡眠,然后等待fullBuffers-&gt;V操作后,就变为1了,才能继续执行,如果生产者一下把buffer塞满了,就需要消费者进行emptyBuffer-&gt;V操作完成后,通知其才可继续运行)<br>如何保证生产者和消费者的互斥,想一想如何保证?<br>就想用信号量的P()和V()操作来完成.在写入数据和读出数据代码前后都加上P()和V()操作,保证只有一个进程或线程在一个时间内进行内存的读取操作.</p>
<p>问题来了,P()和V()操作能不能换顺序??<br>基于生产者:<br>V()对信号量加1,然后把等待进程进行唤醒.v()操作交换顺序没有影响,没有阻塞部分.但是交换P()紧紧是生产值,就是如果Buffer快速慢了,再进入函数后,首先执行的mutex-&gt;P()操作,得到锁,这时emptyBuffers-&gt;p()为-1,进行睡眠,换到消费者模式, fullBuffers被初始化为n,可以进入,但是mutex被生产者所占有,得不到锁,执行不到emptyBuffers-V没办法唤醒生产者睡眠的进程.由于p()操作能产生阻塞,所以一旦交换顺序就可能产生死锁更严重的同时进入临界区等等.</p>
<h5 id="信号量的实现"><a href="#信号量的实现" class="headerlink" title="信号量的实现"></a>信号量的实现</h5><p>信号量怎么来做,首先我们来确定信号量是一个整形,我们需要一个整形来记录P(),V()对信号量加和减具体的值.做P()操作会有进程等待,这里的等待是如何实现的.可以把信号量看做虚拟的资源,类似进程的sleep,所以说在这个值变为-1或者小于0,在这种情况下我们会让进程睡在信号量这个资源上,我们需要一个等待队列,要记录这个被执行v()操作之后需要被唤醒的进程,(等待队列最适合用FIFO来实现.)选择把等待时间最久的进程唤醒,然后p()中的Block就可以继续往下执行.<br>图:信号量的实现</p>
<p>信号量的基本实现原理还是比较容易理解的,但是在使用中除了要用在互斥操作,还可以用在同步操作中,和lock的区别<br>lock两种机制:1. 忙等. 2.等待队列(可以做sleep操作)(lock用在p()的实现过程中),如果P()的操作的顺序安排问题,如果安排的不合适就会产生各种问题.所以如何改进呢?(跳转管程)<br>虽然比较复杂但是生活中我们大量应用来解决同步互斥问题.<br>信号量的双用途:<br>    1. 互斥和条件同步<br>    2. 但等待条件是独立的互斥<br>读/开发代码比较困难:<br>    1. 程序员必须非常精通信号量<br>容易出错:<br>    1. 使用的信号量已经被另一个线程占用<br>    2. 忘记释放信号量<br>不能够处理死锁问题:</p>
<h4 id="管程"><a href="#管程" class="headerlink" title="管程"></a>管程</h4><p>抽象程度比信号量还要高.抽象程度越高,相对更加容易的完成同步互斥的一些问题<br>信号量的提出:就是为了同步互斥机制的实现.<br>管程提出的时候:是用在语言这个level,不是用在操作系统中的,而是用在了编程语言(java等),这些语言通过管程机制简化语言来完成同步互斥的操作.并不是一开始就用在操作系统中的设计里面的,管程的整个机制实现,很大程度上根据语言的并发机制来完成的,<br>目的: 分离互斥和条件同步的关注<br>什么是管程:包含了一系列的共享变量,以及针对这些变量的函数的一个组合.<br>    1. 一个锁:指定临界区(访问管程管理的区域只能有一个线程,所以有一个lock机制来确保互斥性)<br>    2. 0或者多个条件变量:等待/通知信号量用于管理并发访问共享数据.(如果访问条件(得不到资源)不足了,这个时候就得把进程(线程)挂起这时候就需要把进程或者线程挂起,挂到条件变量中去.)根据条件的个数,来确定你需要多少个条件变量,<br>    通过这两个机制组合就能实现管程.!!</p>
<p>一般方法:<br>    1. 收集在对象/模块中的相关贡献数据<br>    2. 定义方法来访问共享数据</p>
<p>图: 管城操作顺序图<br>进入管程时要加入进入队列(entry Queues),先获得一个锁(就是conditions)进入临界区,进入lock管理的管程之后,就可以执行管程维护的一系列的函数(操作或者是函数)就是图中间那一段(operation),在函数中可能有很多共享变量操作,有可能针对某一种共享变量对资源的操作得不到满足了,就需要等待,因为他是互斥的占用了这个管程,他需要把自身挂到某个地方去,然后把lock释放掉,才可以让其他的等待这个lock的线程去执行,等到什么地方,就是条件变量上边,图中x,y就是两个条件变量他有两个队列就是等待队列,这里边挂着所有需要等待的线程,条件变量有两个一个signal 和wait操作,wait就是挂载条件变量里边,signal就是把挂起的线程唤醒,去执行,</p>
<p>lock:以下两个函数确保执行的函数是互斥的,可以把这两个操作放到函数里边也可以通过语言优先级的保障,不写也行语言能帮你嵌入到函数里边.<br>    1. lock()::Acquire() - 等待知道锁可用,然后抢占锁<br>    2. lock()::Release() - 释放锁,唤醒等待者如果有.<br>conditions variable:<br>    1. 允许等待状态进入临界区:<br>        1. 允许处于等待(睡眠)的线程进入临界区<br>        2. 某个时刻原子释放锁进入睡眠<br>    2. Wait() operation:<br>        释放锁,睡眠,重新获得返回后,</p>
<pre><code>3. signal() operation(or broadcast() operation):
    唤醒等待者(或者所有等待者),如果有</code></pre>
<p>条件变量的实现:图:管城条件变量的实现<br>    1. 需要维护每一个条件队列<br>    2. 线程等待的条件等待signal()<br>    wait():<br>        num Waiting ++ 表明我要去睡眠了,多了一个要睡的线程,<br>        线程挂到等待队列里边去<br>        还没Acquire lock就要Released lock这里比较特别为什么?<br>        schedule()选择下一个线程去执行.本来的线程处于睡眠状态了,<br>        再做require(lock),这里又是为什么?<br>    signal():和wait()操作相反:<br>        如果大于零就说明有线程在等待.<br>        把等待队列中的线程取出来,FIFO(来等待这个线程)<br>        取出来之后就要唤醒这个线程,(把sleep线程置成ready状态).再次被调用后,处于运行态就可以继续往下走了.<br>        num–;<br>        如果等待队列没有等待的操作,说明这个啥也不做,这里和信号量的整形变量和这里的num wait他们的含义是很不一样的,num wait表示当前等待的数量,signalfull代表信号量的个数,在处理上也不一样,在signal中的实现,一定要执行PV操作(加减操作),着这里wait中有加操作,但是这里的signal中不一定做减操作,</p>
<p>图: 管程实现消费生产值<br>管程来解决生产者和消费者问题如何解决?<br>就是类似于其那边信号量的定义,来实现管程操作,实现一个锁lock和满和不满的两个条件变量.<br>count记录了当前buffer的空闲情况,count 为零为空,为n为满的.<br>生产者用Deposit(),消费者Remove()两个函数实现.跟前边不一样的就是count++ 和count–操作,和ingal不一样的,sigal是紧紧地放在加入buffer前后的,但是我们这里实现的是放在函数开头结尾,不用紧挨着Buffer.!!这是由我们的管程的定义决定的,就是只能由一个线程能进入管程,才能执行管城所管理的所有的函数,这两个是属于管程所管理的两个函数,访问共享变量的函数,所以得有互斥性,和唯一性,所以要确保一旦进入这个函数就必须是互斥的,所以lock放到了头尾部分,还缺少同步的通知机制buffer空了就得让消费者去睡眠,Buffer满了生产者去睡眠,(while notfull.wait())操作,注意notfull是条件变量不是信号量,不需要有初始值.<br>条件变量中wait(在实现Acquir之前先实现了一个rlease(clock)操作),就是为了让当前生产者释放当前锁,这使得其他的线程才有机会进入管程去执行,因为当前线程要睡眠了,所以要把当前的锁释放.这是因为执行这个函数之前有个lock-Acquire!!!,他获得了这个锁,所以在wait操作里边一定要把锁释放掉,<br>有了notfull.wait就一定会有他的唤醒机制,放在了消费者末尾lock-&gt;Released(),Buffer不满了,notfull里边有等待生产者的线程就会被唤醒,<br>当Buffer空的时候也可以有一个while操作,再消费者这边会判断,count是不是为零,如果等于零,这时候已经空了,会做一一个notemoty的一个wait,直到生产者有一个noemoty.signal之后才会被唤醒继续执行,这几个结合在一起就完成了生产者和消费者问题的实现,<br>总的看来实现的总体是一样的但是实现的细节是不一样的.</p>
<p>还需要注意一点是: 当线程在管程里边执行的时候,如果某个线程要执行某个条件变量的signal操作(唤醒操作),当执行完这个操作后,去执行等待在这个条件变量上的线程呢还是说让发出唤醒操作这个线程执行完毕之后再去让那个等待的线程去执行这两者是不一样的,因为一旦发出signal操作也就意味这当前管城里边有两个线程都可以执行,一个是发出可执行操作的线程,signal之后就意味着要把等待的线程唤醒,唤醒的线程本身他也应该执行,这样就有两个线程执行,到底选那个线程先执行这是一个问题,<br>图: 两种解决办法<br>两种解决办法:<br>    1. hansen:实现起来容易,在很多操作系统(语言)里都是这样来实现的.<br>        提出另一种方法,当他发出signal操作之后呢,并不意味者我要马上放弃cpu,马上把控制权交给等待的线程,而是等我正在执行的线程执行完release操作之后,才把控制权交给wait中所唤醒的线程,让他去执行,</p>
<pre><code>2. hoare:实现起来难,需要很复杂的机制保证hoare的有效性,
    一旦发出signal操作之后,就应该让等待的线程继续执行,他自身去睡眠,比较急切的让等待线程去执行,等待的线程relaese之后这个线程才能继续执行,</code></pre>
<p>这两种方式在我们管程中的使用也会产生一定的影响,</p>
<p>图:两种实现方式不同</p>
<p>在hoare中Deposit中可以用while中换成if语句主要是由于唤醒机制实现不同造成的.他做完signal操作之后,并没有马上的让那个被唤醒的等待的进程执行,他必须要继续往下执行,知道执行relase才能释放,这种情况下,有可能多个等在条件变量上的线程,也被唤醒,就有可能存在多个被唤醒的进程,大家都可能回去抢共同执行的那个acquire(),cpu只有一个,也就是只有一个抢中,所以说那些被唤醒的那些线程,当他能够被选中占用cpu去执行的时候,count已经不为n了,所以说必须用while来做一下确认,是否count=n,这是hansen实现方式造成的一种结果,<br>但是用hoare这种机制来实现,就相对来说简单一点,只有一个等待线程被唤醒,不会有多个,signal操作条件是count &lt; n,而又只有一个线程,不发生抢占,条件满足,依然认为count &lt; n,继续执行,导致我们设置函数的时候也会有所不一样,</p>
<p>图: 临界区管城总结</p>
<p>总结一下:<br>    信号量和管程(Monitor)引入,比lock更进一步,层次高了一层,<br>    不足:<br>        1. 开发/调试并行程序很难:<br>            1. 非确定性的交叉指令<br>        2. 同步结构:<br>            1. 锁:互斥<br>            2. 条件变量:有条件的同步<br>            3. 其他原语:信号量</p>
<pre><code>    3. 怎样有效的使用这些结构:
        制定并遵循严格的程序设计风格/策略</code></pre>
<h4 id="经典同步问题"><a href="#经典同步问题" class="headerlink" title="经典同步问题"></a>经典同步问题</h4><h5 id="经典同步问题1"><a href="#经典同步问题1" class="headerlink" title="经典同步问题1"></a>经典同步问题1</h5><p>读者-写者问题:<br>动机:<br>    1.<br>两类类型使用者:<br>    读者: 不需要修改数据<br>    写着: 读数据和修改数据<br>问题的约束:<br>    1. 允许同一时间有多个读者,但在任何时候只有一个写着.<br>    2. 当没有写者是读者才能访问数据<br>    3. 当没有读者和写者时写者才能访问数据<br>    4. 在任何时候只能有一个线程可以操作共享变量.</p>
<p>多个并发进程的数据集共享:<br>    1. 读者-只读数据集;他们不执行任何更新.<br>    2. 写着-可以读取和写入.</p>
<p>共享数据:<br>    1. 数据集<br>    2. 信号量 CountMutex初始化为1.<br>    3. 信号量 WriteMutex初始化为1.<br>    4. 整数 Rcount 初始化为0.</p>
<p>有一个细节,读者优先,一开始有读者对这个数据开始读了,这时候来了一个写着,他一看有数据就必须进行等待,之后又来了一个读者,读者会跳过这个写者进行数据的读取操作,并没有按照时间顺序谁先来谁就进去,因为读操作对数据不做更改,所以读数据就会跳过写者完成对数据的操作,这就是读者优先的一个特征.</p>
<p>了解特性,那么该如何去设计呢?</p>
<p>首先一个共享变量data,我们会对这个共享变量,进行读取和写入的操作,我们需要知道有几个读者rcount,写者只有一个没什么好说多,我们对Rcount有一个修改,这里的修改的时候需要一个信号量来进行互斥操作,这里用CountMutex来实现的互斥操作,写也需要互斥,因为写者本身也需要互斥,只能有一个写者进入临界区去执行,进入到数据集里边进行相应的写操作,我们还需要一个WriteMutex完成对写者的互斥保护,设置完信号量和共享变量之后就能完成相应的读者和写着的操作流程.</p>
<p>看一看如何完成:<br>    可以有n个读者线程或者有n个写者线程,<br>    writer 和reader.对共享数据进行操作.<br>    先看writer这一部分:<br>    有一个write操作,<br>    为保持互斥操作,在write操作前后加上锁,只允许一个写者进入临界区执行.sem_wait(WriteMutex) 相当于p()操作,对WriteMutex进行一个P()操作,sem_post(WriteMutex)是对于WriteMutex的V()操作.为二级信号量这种方式更加简洁一点,包起来之后就能保证只能有一个写者的线程对数据进行写操作,就是写方面只能保证一个线程访问临界区资源,完成的是只要有一个写着写了,就能保证读者都不能进去只能在外边等.一旦有读者读这个数据,写着也一样在外边等着,但是没有体现允许多个读者进去,下面介绍如何完成这一步:<br>    什么情况下才允许有多个读者进去,首先前边有一个Rcount变量,来记录读者的数量,如果Rcount等于0,就表示现在没有一个读者,先执行一下WriteMutex,可能没有读者有写着,所以要执行一下writeMutex,p()操作,来确定在对这个临界区操作的时候没有写操作存在, 因为Rcount为0了,就没有读者了,这是第一个读者,只要确保没有写者就能继续执行,如果这个时候Rcount不等于0,意味着当前已经有读者线程读数据,也就意味着当前的操作写者一定进不来了的,然后Rcount++进行读操作,进行–操作,如果为0的话,表示已经读完了,当Rcount为0就表示当前没有读者了我是最后一个读者,所以得等待锁者,就需要sem_post(WriteMutex)操作,来使得等待进程的锁者被唤醒,Rcount是一个共享变量,要确保当多个读者来进行操作的时候他有一个互斥性,所以说在对Rcount进行加或者减操作的时候,要把它包起来,就需要使用sem_wait(CountMutex) 和sem_post(CountMutex)把if和_++Rcount包起来起来,对Rcount进行了互斥的保护,不会存在多个读者线程对这个rcount进行同时的操作,保证数据的互斥性,这里就是读者优先的读者写者问题,<br>图:读者优先的读者写者问题</p>
<p>基于读者优先策略的方法,只要有一个读者处于活动状态,后来的读者都会被接纳,如果读者源源不断的出现的话,那么写着就始终处于阻塞状态,<br>基于写者优先策略的方法: 一旦写者就绪,那么写者尽可能快地执行写操作.如果写者源源不断地出现的话,那么读者就始终处于阻塞状态(如何实现?)</p>
<p>读者今次完成读操作</p>
<p>哲学家就餐问题:</p>
<h5 id="经典同步问题2"><a href="#经典同步问题2" class="headerlink" title="经典同步问题2"></a>经典同步问题2</h5><p>图:经典同步问题2</p>
<p>写着优先的角度:<br>    读者要等待的写者有两类:<br>        1. 当前正在做写操作的写者<br>        2. 当前正在等待做写操作的写者.<br>    这两个只有有一个存在,就必须等待.<br>    只有两个写者都不存在,才可以读者进行读数据的操作,在读完数据后,考虑是不是有写者处于等待状态,如果有就把他唤醒,为什么没有写者在等呢?</p>
<p>这里靠写者完成相应的操作,</p>
<p>写者:<br>    1. 如果有读者或者写者在进行读操作或者写操作的话就必去等待,(这里的读者指的是正在读的读者,不是处于等待状态的读者)如果处于等待状态的读者就不需要读了,其他的都不需要等待,这就保证了写者优先.<br>    2. 确保了我们的临界区没有读者或者写者,就可以做写操作了,因为这时候临界区已经空出来,我们就可以做写操作,完成操作之后,唤醒readers和writes(读写操作)<br>    3. 如果用管程,就需要先定义好相关的变量,等待的读者写者的表示</p>
<p>后续补上</p>
<h5 id="经典同步问题3"><a href="#经典同步问题3" class="headerlink" title="经典同步问题3"></a>经典同步问题3</h5><h5 id="经典同步问题4"><a href="#经典同步问题4" class="headerlink" title="经典同步问题4"></a>经典同步问题4</h5><h5 id="经典同步问题5"><a href="#经典同步问题5" class="headerlink" title="经典同步问题5"></a>经典同步问题5</h5><h5 id="经典同步问题6"><a href="#经典同步问题6" class="headerlink" title="经典同步问题6"></a>经典同步问题6</h5><h4 id="死锁问题"><a href="#死锁问题" class="headerlink" title="死锁问题"></a>死锁问题</h4><p>图:车辆过桥模型<br>两个车堵在中桥,才会死锁,谁都不让路,换一种说法是发生饥饿.<br>车辆退出表示释放资源<br>一组阻塞的进程持有一种资源等待获取另一个进程所占有的一个资源.<br>例子:<br>    1. 系统有2个磁带驱动器<br>    2. P1和P2各有一个,都需要另外一个.</p>
<h4 id="系统模型"><a href="#系统模型" class="headerlink" title="系统模型"></a>系统模型</h4><p>图: 资源类型</p>
<p>每个进程使用资源如下:<br>    request/get  —free resource (有空闲的资源)<br>    use/hold —–requested/used resource (得到资源变为拥有状态,其他进程不得拥有这个资源,资源有互斥性,如果没有互斥性就不会出现死锁.)<br>    Release ——free resource(进程使用资源的时间是有限的不能无限的使用资源,确保用完释放,如果得不到释放,系统会出现资源耗尽的情况)(释放资源)</p>
<p>图: 资源和资源的使用定义</p>
<p>v表示两个点,中间建立一条边,pi-&gt;Rj 表是pi和rj之间有一条边,表示pi要Rj的资源.<br>Rj-&gt;Pi 表示资源被使用.边的指向与第一个相反,<br>图 : 资源分配表示<br>图: 资源分配表示图.(资源对应的图标表示)<br>图: 资源分配图的例子<br>讲解: p1,p2,p3三个进程,R1,R2,R3,R4四种资源,R2资源有两个实例,R4资源有三个实例.R2中一个资源分配给了P1,另一个分配给了P2,p1需要R1的资源,请求发出去之后并没有得到满足,因为R1这种资源正在被R2占用,p2拥有R1,和R2两个资源,但是对R3的资源发出请求,P3占用R3的资源,正在使用,这个图会不会有死锁呢 ?<br>不会产生死锁,P3用完资源给p2,p2用完资源给p1.都会得到满足.</p>
<p>图:资源分配图有死锁<br>加一条边p3需要R2的资源.<br>这里有两个环:<br>    1. p1-R1-p2-r3-p3-r2-p1.<br>    2. p2-r3-p3-r2-p2<br>R3需要r2的资源,这时一旦p1,p2,p3都sleep的时候,都没办法执行了.<br>分析: 死锁产生的最典型的特征形成有向的环,<br>链表有无环如何判断???思考 数据结构在做解析,这里不展开讲解</p>
<p>图: 有循环的资源分配图没有死锁</p>
<p>环: P1-R1-P3-R3-p1.如果只是这个环就会发生死锁<br>但是还有p2和p4有两份资源,一旦使用结束资源就会得到满足,一但p2或p4释放资源,就会解除P1,和P3的sleep状态,就不会发生死锁.</p>
<p>总结:(基本情况)<br>     产生死锁代表一定有环,但是有环不一定就代表死锁了.<br>    1. 如果图中不包含循环==&gt;没有死锁<br>    2. 如果图中包括循环==&gt;:<br>        1. 如果每个资源类只有一个实例,那么死锁.<br>        2. 如果每个资源类有几个实例,可能死锁.</p>
<h4 id="死锁特征"><a href="#死锁特征" class="headerlink" title="死锁特征"></a>死锁特征</h4><p>死锁出现后一定出现四个条件,四个条件出现不一定出现死锁.<br>死锁可能出现如果四个条件同时成立:<br>    1. 互斥:在一个时间只能有一个进程使用资源.<br>    2. 持有并等待;进程保持至少一个资源正在等待获取其他进程持有的额外资源.<br>    3. 无抢占:一个资源只能被进程自愿释放,进程已经完成了他的任务之后.<br>    4. 循环等待:存在等待进程集合{p0,p1,….,pn},p0正在等待p1所占用的资源,P1正在等待p2占用的资源,…,pn-1在等待pn所占用资源,pN正在等待p0所占用的资源.</p>
<p>出现死锁是因,产生四种现象是果.</p>
<h4 id="死锁处理办法"><a href="#死锁处理办法" class="headerlink" title="死锁处理办法"></a>死锁处理办法</h4><p>约束条件从强到弱.</p>
<ol>
<li>deadline prevention (死锁预防)</li>
<li>deadline avoidance (死锁避免)</li>
<li>deadline Detection(死锁检测)</li>
<li>Recovery from deadline(死锁恢复)</li>
</ol>
<p>处理的办法:<br>确保系统永远不会进入死锁状态<br>运行系统进入死锁状态,然后恢复.<br>忽略这个问题,假装系统中从来没有发生死锁;用于大多数操作系统,包括unix.(判断死锁并且恢复它消耗是很大的,如果用前边四个约束条件,会约束应用程序或者是操作系统,不能充分的占用cpu去执行)操作系统有一些手段,会在调试状态下完成这些操作,(对应c++编程理念,错误尽可能放在编译器查出)</p>
<h4 id="死锁预防和死锁避免"><a href="#死锁预防和死锁避免" class="headerlink" title="死锁预防和死锁避免"></a>死锁预防和死锁避免</h4><p>死锁预防手段:<br>四个死锁产生的条件我们打破其中一个就可以预防死锁或者避免.<br>下面打破死锁的四种情况<br>限制申请方式.</p>
<ol>
<li><p>互斥-共享资源不是必须的,必须占有非共享资源,(如果改成非互斥的就会使程序不稳定所以这个办法不太好)</p>
</li>
<li><p>占用并等待-必须保证当一个进程请求的资源,他不持有任何其他资源:(可以解决死锁,一次得到全部所需的资源才会执行,不会拿一部分资源,由于占有的资源过多,使得别的线程无法得到他们所需的资源结果是系统的利用率很低,系统的饥饿现象,)</p>
<ol>
<li>需要进程请求并分配其所有资源,它开始执行之前或允许进程请求资源仅当进程没有资源</li>
<li>资源利用率低,可能发生饥饿.</li>
</ol>
</li>
<li><p>无抢占:(前边说资源互斥,现在如果抢占,就需要把原来的进程kill掉,)</p>
<ol>
<li>如果进程占有某些资源,并请求其它不能被立即分配的资源,则释放当前正占有的资源</li>
<li>被抢占资源添加到资源列表中</li>
<li>只有当它能够获得旧的资源以及它请求新的资源,进程可以得到执行</li>
</ol>
</li>
<li><p>循环等待 - 对所有资源类型进行排序,并要求每个进程按照资源的顺序进行申请,(在传统的操作系统中用的不多,但是在嵌入式操作系统中用的多)</p>
</li>
</ol>
<p>死锁避免手段:在申请资源的阶段进行判断,申请的资源会不会出现死锁,如果会出现死锁我就不会答应你的请求(他知道你在申请资源中最大需要的资源是多少,也能限制分配资源的数量,你提供的数量一定不会大于进程需要的最大需求,如进程说我最大需要十个资源,在运行中第一次申请两个资源,第二次申请了四个资源,一共六个了,第三次申请五个,就不行了,与预先约定不符合)<br>    需要系统具有一些额外的先验信息提供.<br>    1. 最简单和最有效的模式是要求每个进程生命它可能需要的每个类型资源的最大数目<br>    2. 资源的分配状态是通过限定提供与分配的资源数量,和进程的最大需求.<br>    3. 死锁避免算法动态检查的资源分配状态,以确保永远不会有一个环形等待状态.(环形等待不一定死锁,但是很可能死锁,是不安全状态,不安全状态包含死锁状态)我们需要找出一种安全的状态.</p>
<p>图: 个状态包含图<br>    安全状态: 包含了死锁状态的,针对系统的所有进程存在一个执行序列,按照这个序列执行下来,不会出现某个进程等在那执行不下去的情况,重点是如何去找这个安全序列.<br>    图 :安全状态定义解释<br>    死锁状态:<br>    不安全状态:<br>如何找到安全状态?<br>图: 解决方案图</p>
<h4 id="银行家算法"><a href="#银行家算法" class="headerlink" title="银行家算法"></a>银行家算法</h4><p>图:银行家算法由来和背景<br>资金相当于资源,客户相当于进程,客户贷款怎么能确保收回这个点受到得到启发,<br>怎么实现的死锁避免:<br>    前提条件:<br>        1. 多个实例<br>        2. 每个进程都必须能最大限度的利用资源<br>        3. 当一个进程请求一个资源,就不得不等待.<br>        4. 当一个进程获得所有的资源就必须在一段有限的时间释放它们.<br>   基于上述描述我们就能来寻找一个安全序列,让所有进程都能正常的结束,正常运行就说明所有资源都能得到.如果没有这个序列,就说明出入unslfe状态,(unsalf状态包含unlock状态,如果要判断unlock开销会更发,所以判断unsalf状态就可以了)判断unsalf之后,就不能让这个进程获得资源. 基于上述前提条件银行家算法通过尝试寻找允许每个进程获得的最大资源并结束(把资源返还给系统)的进程请求的一个理想执行时序,来决定一个状态是否是安全的.<br>    不存在满足要求的执行时序的状态都是不安全的.</p>
<p>银行家算法数据结构:<br>    n = 进程数量, m = 资源类型数量.(每一行有多个类型,如a,b,c类型)<br>    Max(总需求) : n x m矩阵.如果Max {i,j] = k,表示进程Pi最多请求资源类型Rj的k个实例.<br>    Available剩余空闲量: 长度为m的向量,如果Available{j] = k, 有k个类型Rj的资源实例可用.<br>    Allocation(已分配量): n x m矩阵.如果Allocation{i,j] = k,则p{i] 分配了k个Rj的实例.<br>    Need(未来需要量): n x m矩阵,如果 Need{i, j] = k, 则pi可能需要k个Rj实例来完成任务.<br>    三者关系:<br>            Need{i,j] = Max{i,j] - Allocation{i, j];</p>
<p>银行家算法设计:<br>安全序列的生成<br>     work 表示当前资源剩余空闲量,</p>
<ol>
<li><pre><code>finish&#123;i]为true表示已经拿到了所有的资源,运行一段时间并结束,为false就得去申请资源,申请到资源才能结束,一开始都为false,怎么判断他能否申请到这是一关键,</code></pre>
</li>
<li>找到这样的i: 接下来找出Need比Work小的进程i.<br> a. Finish{i] = false<br> b. Needi ＜= work<br> 没有这样i,就转到4,表示处于不安全序列了.否者就是处于安全序列</li>
<li>Work = work + Allocation{i] 进程i的资源需求量小于当前剩余空闲资源.<br>Finish{i] = true 所以配置给它在回收.<br>转到2. </li>
<li>if Finish{i] = ture for all i. 不予分配, 所有进程的Finish为Ture,表明系统处于安全状态.<br>then the system is in a safe state.<br> 一开始进程会提出资源请求,我需要多少资源,资源A多少,资源B多少,就会有一个Request向量如果当前资源狗就会分配给你<br>就是如果 Requesr{i] ＜= need{i] ,转到步骤2,否则,提出错误条件,因为进程已经超过了其最大要求.</li>
</ol>
<p>Banker’s Algorithm :<br>图:银行家算法大致的设计思路</p>
<p>安全状态算法例子(安全序列生成):</p>
<p>15:18<br>!!! 掌握不太明确定，需要复习.</p>
<p>Max :所有进程需要资源的情况.<br>need: 当前进程需要资源的情况.<br>Available vector V:表示系统还剩多少资源的情况.<br>allocation matrix A:表示当前进程已经拥有的资源.<br>Resource vectoe R: 表示当前系统中所有资源的个数.</p>
<h4 id="死锁检测和死锁恢复"><a href="#死锁检测和死锁恢复" class="headerlink" title="死锁检测和死锁恢复"></a>死锁检测和死锁恢复</h4><p>死锁检测条件放宽了，前边说死锁避免：就是没有没有死锁，即使我检测出有可能出现不安全状态，就不会让你继续申请资源了，而死锁检测为什么说条件放宽了，因为他允许系统进入死锁状态，就继续运行吧没关系，一旦说到了某个阶段就会判断一下，当前系统是否死锁了，如果是死锁了，就启动恢复机制，如果判断没死锁，那就继续运行，这里他把死锁的检测挪到了更靠后的一个阶段，系统运行中，不是在每次发出请求就去判断．</p>
<p>死锁检测:<br>跟安全状态检测算法类似.<br>图: 简化资源分配图<br>图: 资源类型的数据结构</p>
<ol>
<li>把资源分配的图，变换为等待进程图，把每个资源节点去掉，如果说某一个进程需要一个资源且这个资源被另一个进程所拥有的话，就会在发出请求的线程和拥有资源的线程之间建立一条连线，这是有向图，判断是否有环，如果有环就说明死锁了</li>
</ol>
<p>图: 死锁检测算法<br>在检测操作系统的时候能用到，别的就很少用到．</p>
<ol>
<li>开销比较大，这就是操作系统很少使用检测算法的原因.</li>
<li>他还需要提前知道每个进程所需要的最大资源个数，一般程序来说这个信息很难获得，（每次都检测，开销很大）</li>
</ol>
<p>Allocation :以得到的资源.<br>Request : 当前需要申请的资源<br>Available: 现在系统中还剩余的资源<br>成功没有死锁<br>图: 例子１死锁检测算法<br>失败就是死锁了<br>图:　例子２死锁检测算法</p>
<p>图：检测算法使用（使用情况，使用频率）</p>
<p>已经产生死锁了<br>图: 死锁恢复办法<br>图; 进程恢复的手段（和上边一样）<br>第一条kill所有死锁进程，可以杀死一个进程，但是问题来了应该杀死哪个进程，大家都一样为啥要kill他呢，规则如何定.可以基于进程优先级，进程的运行时间，进程占用的资源一般来说优先级低的kill掉，进程运行时间久了也kill掉也说得过去，进程占用资源多的kill，让还没运行的进程去执行，好像也说得过去，无论那种方法都不能让进程正常执行，所以说这些方法都讯在一些强制性不合理性，实际过程确实这样做的，</p>
<p>死锁恢复总结三大类:</p>
<ol>
<li>选择一个受害者－最小的成本</li>
<li>回滚—返回到一些安全状态，重启进程到安全状态．(打破死锁的四个条件，这个就是把分配的资源抢回来，迫使不成环)</li>
<li>饥饿—统一进程可能一直被选作受害者，包括回滚的数量.</li>
</ol>
<p>操作系统更多用的是鸵鸟算法：忽略脑袋插土里．真出现了死锁恢复．不是一个很好的方法，还有待研究解决．（聪明的你论文题目来了，啊哈哈哈哈哈哈哈！关注操作系统研究的进展！！！！）</p>
<h4 id="IPC概述"><a href="#IPC概述" class="headerlink" title="IPC概述"></a>IPC概述</h4><p>进程间通信简称叫IPC:<br>    1. 概述:<br>        1. 通信模型<br>        2. 直接及间接通信<br>        3. 阻塞和非阻塞<br>        4. 通信链路缓冲<br>    2. 信号：<br>    3. 管道:<br>    4. 消息队列:<br>    5. 共享内存: </p>
<p>IPC的概述:<br>    1. 进程通信的机制及同步<br>    2. 不适用共享变量的进程通信<br>    3. IPC facility 提供2个操作:<br>        1. send(message) - 消息大小固定或者可变<br>        2. recelve(message)<br>    4. 如果P和Q想通信，需要:<br>        1. 在它们之间建立通信链路<br>        2. 通过send/receive交换消息<br>    5. 通信链路的实现:<br>        1. 物理（例如，共享内存，硬件总线）<br>        2. 逻辑（例如，逻辑属性）</p>
<p>为什么要进程间通信呢?<br>以前我们说过进程之间还要相对保持独立，一个进程不能访问另一个进程的地址空间．这是一个很重要的因素，就是进程地址空间不会随便被不相干的其他进程访问，这样可以确保整的进程正确的运行，另一方面我们知道进程和进程之间需要协作在一起完成一个大的任务，这时候需要一定的沟通，消息的通知，信息的传递，在保证进程相互独立的同时还要保证进程间的相互沟通，这就是为什么有进程间通信这个原因，进程间的机制，最常想到的机制就是send和receive两种，如果两个进程之间通信需要建立一个管道，跟打电话和电子邮件类似，通信管道有很多种情况，比如说基于内存，基于某个特殊的硬件，基于逻辑的资源等等，都可以建立通信链路或者通信管道，看具体实现:<br>    上例子:<br>图:进程间的通信模型<br>        图中ａ部分进程ａ和进程ｂ是一种间接的通信，为什么这么说，可以看到进程ａ把消息发送到内核，由内核再转发给进程ｂ．<br>图中ｂ部分进程ａ和进程ｂ直接可以通信，避免了通过内核倒一次<br>直接通信类似与打电话，间接通信就是写信．（转邮局再发送）</p>
<p>图: 直接通信<br>进程必须正确的命名对方:<br>    1. send(P,message) —发送信息到进程P（发送ID）<br>    2. receive(Q, message)–从进程Q接受消息．(接受ID)</p>
<p>在发送和接收数据之前，需要对链路有一个提前的建立，可以是单向也可以是双向的，取决于实现．<br>通信链路的属性:<br>    1. 自动建立链路（一般来说需要操作系统的支持，才能建立好，因为它打破了不同进程的隔离，没有操作系统的支持很难做到的操作系统可以访问到各种资源）<br>    2. 一条链路恰好对应一对通信进程<br>    3. 每对进程之间只有一个链路存在<br>    4. 链接可以是单向的．但是通常是双向的．</p>
<p>图: 间接通信:发送方:消息得放到某个地方去，这个地方是操作系统指定的一个共享的区域，在内核中的区域,接受方：指定我要从操作系统的那个地方接受数据就ｏｋ了，至于发送方的数据从哪里来的接收方不用管，对于发送方而言对于谁收到他的数据也不用关注，只要关注从某个地方发送或者从某个地方收数据就ｏｋ了，中间节点一般是内核中的一些共享的资源，这是一种间接通信的方式，两种通信手段，可以根据具体的通信需求来判断需要什么通信的手段．<br>    定向从消息队列接受消息:<br>        1. 每个消息队列都有一个唯一的ID,<br>        2. 只有他们共享了一个消息队列，进程才能够通信．<br>    通信链路的属性:<br>        1. 只有进程共享一个共用的消息队列，才建立链路<br>        2. 链接可以与许多进程相关联<br>        3. 没对进程可以共享多个通信链路<br>        4. 链接可以是单向或双向</p>
<p>间接通信:<br>    操作:这是他的一个操作过程<br>        1. 创建一个新的消息队列<br>        2. 通过消息队列发送和接收消息<br>        3. 销毁消息队列（没有用的缓存队列，及时销毁）<br>    原语的定义如下:发送到消息队列或者从消息队列接收．<br>        1. send(A, message) – 发送消息到队列A<br>        2. receive(A, message) – 从队列A接受消息.</p>
<p>从发送的方式来看直接和间接<br>另一个：消息传递可以是阻塞或非阻塞:<br>    阻断被认为是同步的：比如我要发送一个消息，如果没发送完成，就要阻塞在那，只有发送完成才能正常的返回去干下边的事情．<br>    1.<br>    2.<br>    非阻塞被认为是异步的:非阻塞发送send就完了，至于send成功与否还不知道，就是send这个操作会很快的返回，是异步的因为成功和结束的时间和（return ）返回时间有一段比较大的间距．间距是异步性的体现，<br>    1.<br>    2.<br>两种方式他们有各自适合的场景，根据具体应用需求来选择合适的应用手段，到底采取阻塞和非阻塞的方式或者同步的方式还是异步的方式，来完成消息的发送和接收．</p>
<h4 id="信号管道消息队列和共享内存"><a href="#信号管道消息队列和共享内存" class="headerlink" title="信号管道消息队列和共享内存"></a>信号管道消息队列和共享内存</h4><p>如果消息通过某种队列，把消息缓存起来，为什么要缓存，以前我们说过缓存的最主要目的就是提高效率，来避免发送方和接收方的不匹配，因为可能发的很快，收的很慢，或者在同时刻收的很快，发的很慢，因为有缓存，会把临时不能处理的信息，无论发送方还是接收方的数据，放到一个地方可以极大的提高效率，这样缓存就存在一个缓存多少，容量问题，下列三种方式．<br>队列的消息被附加到链路；可以时以下三种方式之一；</p>
<ol>
<li>0容量-0message:<br> 发送方必须等待接收方(renfezvous)</li>
<li>有限容量–n message的有限长度:<br> 发送方必须等待，如果队列满，接收方在队列空了，就得等待，有数据才能接收．</li>
<li>无限容量–无限长度:作分析模拟的时候才会用到，无限长度．<br> 发送方不需要等待.接受方不一样，如果没有数据，接收方不得不等待，或者返回一个错误信息，这是接受方的处理过程，</li>
</ol>
<p>概述讲完了，这些机制使得通信更加的灵活，适应各种不同的计算机通信情况．<br>接下来说计算机系统里边通用的通信手段！！！</p>
<h5 id="信号-轻量机制"><a href="#信号-轻量机制" class="headerlink" title="信号(轻量机制)"></a>信号(轻量机制)</h5><p>类比一下，最开始讲操作系统提到了，硬件，外设或者让ｃｐｕ知道现在该做些什么事或者我产生什么状态让ｃｐｕ注意一下，需要ｃｐｕ去处理一下，会产生一个硬件中断（interrupt）,这里的signal可以理解为软件level的interrupt,打断了当前的应用程序，说我当前有更紧急的事情要处理，这是signal大致的目标．<br>一旦操作系统由于某种原因，给某一个程序发出了signal信号，那应用程序会怎么处理呢，一般的缺省（catch）（就直接缺省运行，就退出正常执行）</p>
<p>signal(信号):只是一个很小的bit,来表明是哪种信号，不是传很多数据交换，起了一种通知的作用，这是他的特点也是他的不足．效率很高类似于异步打断的机制，如果说采用专门的中断处理函数处理，处理完之后怎么办，是执行呢，退出呢还是怎么样呢，根据操作系统的约定，一般会回到被打断的程序重新执行，这里说是信号的大致处理过程，了解完处理过程后，还要了解如何实现呢．<br>    1. 软件中断通知事件处理<br>    2. Example: SIGFPE,SIGKILL,SIGUSRI,SIGSTOP.SIGCONT</p>
<p>接收到信号时会发生什么:<br>    1. catch:指定信号处理函数被调用：信号来了，信号的处理函数就会被调用，来完成信号的响应，这种方式很灵活，为了某种响应某种信号就在程序里编写相对应的处理函数，来指定它是产生某个信号之后做哪些响应，这个是可实现的．<br>    2. Ignore:依靠操作系统的默认操作:<br>        Example:Abort.memory dump, suspend or resume process.<br>    3. Mask:闭塞信号因此不会传送:<br>        可能是暂时的(当处理同样类型的信号)<br>不足:<br>    1. 不能传输要交换的任何数据.</p>
<p>刚才那些功能，和那些表现形式，操作系统如何实现的（信号机制是操作系统完成的），想一想操作系统提供一种什么样的手段，就能完成刚才那种功能呢，上图:信号量机制图<br>解释图:<br>    第一步：如果针对某个信号单独处理的时候，首先在程序执行开始的时候，注册一个针对某个信号的handles，把这个作为系统调用，发给我们的操作系统，操作系统看这个信息之后，我可以当产生某个信号的时候，针对这个进程的信号的时候，我们会让应用程序写的专门的信号处理函数来执行，把这个信息注册好之后，操作系统就好，ｏｋ．<br>第二步：一旦产生了这个信号，操作系统怎么能让那个当前正在运行的进程把当前的工作停下来，跳到中断处理函数去执行，应该是信号处理函数，软中断，让中断处理函数去执行的，怎么来完成想一想？正在跑的好好一个程序怎么会被打断去执行另外一个函数去了，没错这个靠操作系统完成的，单靠应用程序很难完成，操作系统怎么做？首先想一想，操作系统接受信号的时候运行在内核态，当他从内核态返回用户态去执行那个要去响应信号的那个程序的时候，提前做好准备返回的那个点，调用信号处理函数的入口，这一步怎么实现呢？结合之前写操作系统system call系统调用的实现，他需要把系统调用的返回的用户空间的堆栈进行修改，返回本来应该返回到调用系统调用的后一条语句去执行呢变成信号处理函数入口，改了这一步，同时还需要把信号处理函数之后要执行的那个地址作为后边那个栈的返回地址，这样就没问题了，这样一旦从操作系统内核返回到应用程序去执行的时候会根据你留的栈信息跳到信号执行函数的入口去执行，这时候就回到了用户态，当这个函数执行完毕后，就会继续返回调它的那个函数，构造成那个被打断的点，使他可以被继续执行，怎么组合这是一个问题？<br>70年代，没图形界面，只有键盘还没鼠标，想一想如何把一个函数的输出作为一个函数的输入，一步一步的往前走完成一个更复杂的功能，这个就通过一个|(竖线)就完成了，意思就是一个命令ａ产生的输出会通过｜来作为命令ｂ的输入这样就形成了管道机制，写的时候我知道从键盘或者说文件读到数据，输出到键盘或文件，只知道这么编写就ｏｋ了，中间会有某种机制进行完成，从一个地方到另一个地方的重定向，这就是我们的管道机制．<br>％ｓ　｜　ｍｏｒｅ　使文件分页显示．<br>图:管道分析图</p>
<p>图中：shell进程，shell收到一条命令，创建两个子进程ls和more(共享文件)，ls的输出(stdout)做一个特殊的处理不是输出到屏幕上而是重定向一个管道，管道实际是内存中的一个buffer，这是ls就没在屏幕写了，而是在管道在写，more以为要从键盘或者屏幕来接收信息，stdin也重定向到了管道，more从缓冲区读入，管道有双重身份，一部分是接收部分，一部分是输出部分.buffer也是有限的，如果ls输出把buffer填满，就会阻塞（sleep）,more发现buffer没数据也会阻塞(sleep)等待被唤醒．ls和more之所以能协同起来是因为他们共同的父进程，就能继承父进程的资源，管道是一种文件的形式存在的．</p>
<h5 id="管道"><a href="#管道" class="headerlink" title="管道"></a>管道</h5><h5 id="消息队列"><a href="#消息队列" class="headerlink" title="消息队列"></a>消息队列</h5><p>也是一种消息传递的机制,跟管道的区别是我们所关注的．<br>管道是通过父进程帮助子进程建立好的通道，如果进程之间没有父子关系就不能建立管道，这是第一个缺陷，第二个呢管道里的数据是一种字节流没有一种结构化的表示形式，把里边的数据按照结构化的形式显示出来，可以实现但是比较复杂，这两个原因呢在消息队列里边都可以克服，消息队列可以实现多个不相干的进程通过消息队列来传递数据这么一个功能，一端send有多个receive只有一个，他们之间没关系也可以传数据，第二个呢send和receive传的是结构化的数据使得编写比较复杂的程序更加灵活方便，因为你传递的不是一个没有意义的字节流，传递完还需要解析，而是传递完成就是一个有意义的数据结构，这是消息队列的通信方式，但是和消息队列有一个类似的方式，是由buffer size限制，如果满了或者空了，发送或者接收方也会睡眠，<br>图:消息对垒（列）<br>消息队列是一种间接通信的方式</p>
<h5 id="共享内存"><a href="#共享内存" class="headerlink" title="共享内存"></a>共享内存</h5><p>共享内存是一种直接通信的方式，因为两个进程有一段特殊的内存空间是两个进程都能访问到的．一个进程写另一个进程就能访问到，不需要send和receive操作，相对于前边的通信方式是最快的，传输数据量是最大最快的方式，只需要操作系统在开始的时候创建好这样一块共享的区域，让多个进程共享这个区域，这是他的好处，方便高效没有多余的拷贝，不好的地方就是怎么保证我写了之后别人不能写到同一个地方去，这就需要一些同步互斥的机制来保证我们写的数据是对的，不会出现前边所说的同步互斥的情况．需要考虑．<br>进程:<br>    1. 每个进程都有私有地址空间<br>    2. 在每个地址空间内，明确的设置了共享内存段<br>优点:<br>    1. 快速，方便地共享数据<br>不足:<br>    1. 必须同步数据访问</p>
<p>操作系统如何进行共享内存的实现?<br>就是前面说的内存管理,你可以把同一块物理内存,映射到相同或者不同的地址空间中去,这样映射好之后就能通过不同进程的虚地址的时候,访问的就是同一块物理地址的物理空间,实现起来并不复杂,但是需要内存管理的充分支持,页表等相应的支持,第二个需要更好的同步互斥机制,确保不会重复写的等问题的出现,</p>
<p>根据不同的需求完成机制的选取.</p>
<h5 id="还有一种通信机制-socket"><a href="#还有一种通信机制-socket" class="headerlink" title="还有一种通信机制 socket()"></a>还有一种通信机制 socket()</h5><p>虽然tcp协议栈都实现在内核里边但是是计算机网络的内容就不进一步赘述了,有发布类似内容.</p>
<h4 id="文件系统．"><a href="#文件系统．" class="headerlink" title="文件系统．"></a>文件系统．</h4><p>文件系统是操作系统的子进程,完成文件的存储,读取,信息的恢复等操作,</p>
<h5 id="基本概念-文件系统和文件"><a href="#基本概念-文件系统和文件" class="headerlink" title="基本概念-文件系统和文件"></a>基本概念-文件系统和文件</h5><ol>
<li>文件描述符</li>
<li>目录</li>
<li>文件别名</li>
<li>文件系统种类</li>
</ol>
<p>文件系统: 一种用于持久性存储的系统抽象:硬盘(掉电存储在里边的数据不会丢失)<br>    1. 在存储器上:组织,控制,导航,访问和检索数据.<br>    2. 大多数计算机系统包含文件系统<br>    3. 个人电脑,服务器,笔记本电脑<br>    4. ipod,Tivo/机顶盒,手机/掌上电脑<br>    5. Google可能是由一个文件系统构成的<br>文件:文件系统中一个单元的相关数据在操作系统中的抽象,</p>
<p>考虑怎样查询,访问,处置放在持久化存储介质上的数据,这是文件系统需要去关心的.</p>
<h5 id="基本概念-文件系统的功能"><a href="#基本概念-文件系统的功能" class="headerlink" title="基本概念-文件系统的功能"></a>基本概念-文件系统的功能</h5><p>分配文件磁盘空间:<br>    1. 管理文件块(哪一块属于哪一个文件)<br>    2. 管理空闲空间(哪一块是空闲的)<br>    3. 分配算法(策略)</p>
<p>管理文件集合:<br>    1. 定位文件及其内容<br>    2. 命名: 通过名字找到文件的接口<br>    3. 最常见:分层文件系统<br>    4. 文件系统类型(组织文件的不同方式)</p>
<p>提供的边里及特征:<br>    1. 保护:分层来保护数据安全<br>    2. 可靠性/持久性: 保持文件的持久即使发生崩溃,媒体错误,攻击等.</p>
<h5 id="基本概念-文件和块"><a href="#基本概念-文件和块" class="headerlink" title="基本概念-文件和块"></a>基本概念-文件和块</h5><p>文件属性:<br>    名称,类型,位置,大小,保护,创建者,创建时间,最近修改时间,…<br>文件头:<br>    1. 在存储元数据中保存了每个文件的信息<br>    2. 保存文件的属性<br>    3. 跟踪哪一块存储块属于逻辑上文件结构的哪个偏移.</p>
<h5 id="基本概念-文件描述符"><a href="#基本概念-文件描述符" class="headerlink" title="基本概念-文件描述符"></a>基本概念-文件描述符</h5><p>图: 文件使用模式</p>
<p>需要元数据数据来管理打开文件:<br>    1. 文件指针: 指向最近的一次读写位置,每个打开了这个文件的进程都这个指针.<br>    2. 文件打开计数:记录文件打开的次数,—当最后一个进程关闭了文件时,允许将其从打开文件表中移除.<br>    3. 文件磁盘位置: 缓存数据访问信息<br>    4. 访问权限: 每个程序访问模式信息.</p>
<p>用户视图:<br>    持久的数据结构</p>
<p>系统访问接口:<br>    1. 字节的集合(UNIX)<br>    2. 系统不会关心你想存储在磁盘上的任何的数据结构</p>
<p>操作系统内部视角:<br>    1. 快的集合(块是逻辑转换单元,而扇区是物理转换单元)<br>    2. 块大小＜＞扇区大小；在UNIX中，块的大小是4KB.</p>
<p>当用户说: 给我2-12字节空间时会发生什么:<br>    1. 获取字节所在的块（磁盘块）<br>    2. 返回块内对应部分<br>如果说要写2-12字节呢:<br>    1. 获取块<br>    2. 修改块内对应部分<br>早文件系统中的所有操作都是在整个块空间上进行的:<br>    举个例子，getc(),和putc();即使每次只访问1字节的数据，也会缓存目标数据4096字节，</p>
<p>访问模式上：<br>用户怎么访问文件:<br>    1. 在系统层面需要知道用户的访问模式</p>
<p>顺序访问:按字节依次读取:<br>    1. 几乎所有的访问都是这种方式</p>
<p>随机访问: 从中间读写:<br>    1. 不常用,但是仍然重要,例如,虚拟内存支持文件:内存页存储在文件中.<br>    2. 更加快速—不希望获取文件中间的内容也必须获取块内所有字节.</p>
<p>基于内容访问:通过特征:<br>    许多系统不提供此种访问方式,相反,数据库是建立在索引内容的磁盘访问上(需要高效的随机访问)</p>
<p>文件内部的结构:<br>    无结构:<br>        单词,比特的对列<br>    简单记录结构:<br>        1. 列<br>        2. 固定长度<br>        3. 可变长度<br>    复杂结构:上边和操作系统有关,操作系统无关和应用有关<br>        1. 格式化的文档(如,MS Word,PDF)<br>        2. 可执行文件<br>        3. …</p>
<p>多用户系统中的文件共享是很必要的.<br>访问权限:<br>    1. 谁能够获得哪些文件的哪些访问权限.<br>    2. 访问模式:读,写,执行,删除,列举等.</p>
<p>文件访问控制列表(ACL):<br>    1. ＜文件实体,权限＞</p>
<p>UNIX模式:<br>    1. ＜用户|组|所有人, 读|写|可执行＞<br>    2. 用户ID识别用户,表明每个用户所允许的权限及保护模式<br>    3. 组ID允许用户组成组,并指定了组访问权限.</p>
<p>指定多用户/客户如何同时访问共享文件:<br>    1. 和过程同步算法相似<br>    2. 因磁盘I/O和网络延迟而设计简单.</p>
<p>Unix文件系统(UFS)语义:<br>    1. 对于打开的写入内容立即对其他打开同一文件的其他用户可见<br>    2. 共享文件指针允许多用户同时读取和写入文件</p>
<p>会话语义:<br>    1. 写入内容只有当文件关闭时可见</p>
<p>锁:<br>    1. 一些操作系统和文件系统提供该功能.</p>
<h5 id="基本概念-目录"><a href="#基本概念-目录" class="headerlink" title="基本概念-目录"></a>基本概念-目录</h5><p>图: 文件目录<br>图: 文件目录组织<br>图: 典型操作<br>图: 存目录中的文件<br>图: 路径的遍历<br>图: 文件挂载</p>
<h5 id="基本目录-文件别名"><a href="#基本目录-文件别名" class="headerlink" title="基本目录-文件别名"></a>基本目录-文件别名</h5><p>图: 两个或多个文件名关联同一个文件<br>快捷方式: 内容是原来文件的路径,查看内容根据路径访问.<br>图: 文件删除方案 图中有两个解决方式<br>如果是软连接的方式,把原来文件删了,会怎么样.指向一个空的地方,成为悬空指针,<br>图: 别名机制出现的问题</p>
<h5 id="基本目录-文件系统种类"><a href="#基本目录-文件系统种类" class="headerlink" title="基本目录-文件系统种类"></a>基本目录-文件系统种类</h5><p>图: 文件系统的种类<br>日志文件系统: 要么完成要么不完成,突然断电记住修改部分对数据的恢复操作<br>图 :分布式系统补充<br>网络使得分布式或者文件系统他的特征和单机上的特征很不一样,网络意味着延迟大不可靠访问时间不可控这些都是网络系统拥有的特点,但是单机中基于pci总线是一种稳固的快速的完成内存和地址之间的访问,中间有一个网络存在,这使得得考虑,一致性,安全性,访问延迟等问题,使得再设计网络或者分布式系统的时候更加复杂,需要更多的因素,也是我们研究的热点(论文题目又来了!!!!)</p>
<h5 id="虚拟文件系统"><a href="#虚拟文件系统" class="headerlink" title="虚拟文件系统"></a>虚拟文件系统</h5><p>如何组织设置管理运行<br>图 分层结构<br>图 虚拟文件系统目的和功能<br>图 控制块<br>图 抽象文件图<br>卷控制块,在卷控制块的控制下,会有一堆目录,这个目录可以管理子目录也可以管理文件,根节点会指向文件的内容(数据块)数据块放到磁盘里边,<br>图 文件系统数据结构讲解<br>文件系统数据结构: 这些都会映射到磁盘里的一个或多个扇区.有些专门的数据块存放数据的.<br>图: 再来文件抽象图 注意下边一行图</p>
<h5 id="数据缓存"><a href="#数据缓存" class="headerlink" title="数据缓存"></a>数据缓存</h5><p>为了提高速度需要在内存中放一个缓存,buffer数据缓存技术,<br>图 缓冲技术图.<br>图 数据缓冲的机制<br>图 缓存粒度<br>图 文件数据块的页缓存<br>效率高的体现,减少对硬盘的读取次数.</p>
<h5 id="打开文件的数据结构"><a href="#打开文件的数据结构" class="headerlink" title="打开文件的数据结构"></a>打开文件的数据结构</h5><p>图 打开文件描述<br>图 打开文件系统<br>下面是流程:<br>    当一个进程做了一个打开操作后,会返回一个index,index会指出在进程的打开文件表的哪个位置,基于这个项找到,系统层面打开的文件表,有可能是不同进程打开了同一个文件,在系统打开文件表里边只记录一项就ok了,基于这一项他会找到如果他是一个目录或者是一个文件他有不同处理简单点,如果是一个文件的话,我们可以知道文件的node信息,文件的节点信息会包含到底这个文件在什么地方,你在做read或write操作的时候会有一个偏移量offset来指出那个文件的哪个位置起的哪个数据或者读或者写,offset会经过文件控制块的转换,转换成一个disk(扇区的编号),要访问的那块数据对应着要访问的扇区,然后呢操作系统会把这些扇区的内容或者读或者写,以读为例就是读到内存中来,这样就可以读到内存的buffer里边取出这个应用程序所需要的数据,传回给应用程序,这就是打开文件之后做的读和写的操作,<br>    在打开文件之前要注意,文件是一个共享的资源,可能存在一个锁的保护机制,锁的设置请况:<br>        1. 强制–根据锁保持情况和需求拒绝访问<br>        2. 劝告–进程可以查找锁的状态来决定怎么做.</p>
<h5 id="文件分配"><a href="#文件分配" class="headerlink" title="文件分配"></a>文件分配</h5><h5 id="空闲空间列表"><a href="#空闲空间列表" class="headerlink" title="空闲空间列表"></a>空闲空间列表</h5><h5 id="多磁盘管理-RAID"><a href="#多磁盘管理-RAID" class="headerlink" title="多磁盘管理-RAID"></a>多磁盘管理-RAID</h5><h5 id="磁盘调度"><a href="#磁盘调度" class="headerlink" title="磁盘调度"></a>磁盘调度</h5><h5 id="地址安全检查"><a href="#地址安全检查" class="headerlink" title="地址安全检查"></a>地址安全检查</h5><p>####</p>
<h5 id="内存分层体系"><a href="#内存分层体系" class="headerlink" title="内存分层体系"></a>内存分层体系</h5><h5 id="在操作系统的内存管理范例"><a href="#在操作系统的内存管理范例" class="headerlink" title="在操作系统的内存管理范例"></a>在操作系统的内存管理范例</h5><h4 id=""><a href="#" class="headerlink" title=""></a></h4><h4 id="-1"><a href="#-1" class="headerlink" title=""></a></h4><h4 id="-2"><a href="#-2" class="headerlink" title=""></a></h4><h4 id="-3"><a href="#-3" class="headerlink" title=""></a></h4><h3 id="操作系统的内存管理-分页和分段的区别"><a href="#操作系统的内存管理-分页和分段的区别" class="headerlink" title="操作系统的内存管理, 分页和分段的区别"></a>操作系统的内存管理, 分页和分段的区别</h3><p>1、页是信息的物理单位，分页是为实现离散分配方式，以消减内存的外零头，提高内存的利用率；或者说，分页仅仅是由于系统管理的需要，而不是用户的需要。</p>
<p>段是信息的逻辑单位，它含有一组其意义相对完整的信息。分段的目的是为了能更好的满足用户的需要。</p>
<p>2、页的大小固定且由系统确定，把逻辑地址划分为页号和页内地址两部分，是由机器硬件实现的，因而一个系统只能有一种大小的页面。</p>
<p>段的长度却不固定，决定于用户所编写的程序，通常由编辑程序在对源程序进行编辑时，根据信息的性质来划分。</p>
<p>3、分页的作业地址空间是维一的，即单一的线性空间，程序员只须利用一个记忆符，即可表示一地址。</p>
<p>分段的作业地址空间是二维的，程序员在标识一个地址时，既需给出段名，又需给出段内地址。<br>4.页内位移溢出时，会传给下一页。段内位移溢出时，就会出现越界中断。</p>
<p>银行家算法原理</p>
<hr>
<hr>
</div><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="mailto:undefined">lys-studys</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="http://example.com/posts/47607/">http://example.com/posts/47607/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/linxu/">linxu</a></div><div class="post_share"><div class="social-share" data-image="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/posts/34955/"><img class="prev-cover" data-lazy-src="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">Previous Post</div><div class="prev_info">leedcode_动态规划</div></div></a></div><div class="next-post pull-right"><a href="/posts/1/"><img class="next-cover" data-lazy-src="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">Next Post</div><div class="next_info">堆排序</div></div></a></div></nav><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> Comment</span></div></div><div class="comment-wrap"><div><div class="vcomment" id="vcomment"></div></div></div></div></article></main><footer id="footer" data-type="color"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2021 By lys-studys</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">我们相遇不是意外~ <a target="_blank" rel="noopener" href="https://lys-studys.github.io//">blog</a>!</div><div class="icp"><a target="_blank" rel="noopener" href="http://www.beian.miit.gov.cn/state/outPortal/loginPortal.action"><img class="icp-icon" src="/img/icp.png"/><span>粵ICP備xxxx</span></a></div></div></footer></div><section id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="Switch Between Traditional Chinese And Simplified Chinese">繁</button><button id="darkmode" type="button" title="Switch Between Light And Dark Mode"><i class="fas fa-adjust"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog"></i></button><a id="to_comment" href="#post-comment" title="Scroll To Comments"><i class="fas fa-comments"></i></a><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><button id="chat_btn" type="button" title="rightside.chat_btn"><i class="fas fa-sms"></i></button><button id="go-up" type="button" title="Back To Top"><i class="fas fa-arrow-up"></i></button></div></section><div><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script>var endLoading = function () {
  document.body.style.overflow = 'auto';
  document.getElementById('loading-box').classList.add("loaded")
}
window.addEventListener('load',endLoading)</script><div class="js-pjax"><script>if (document.getElementsByClassName('mermaid').length) {
  if (window.mermaidJsLoad) mermaid.init()
  else {
    $.getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js', function () {
      window.mermaidJsLoad = true
      mermaid.initialize({
        theme: 'default',
      })
      false && mermaid.init()
    })
  }
}</script><script>function loadValine () {
  function initValine () {
    window.valine = new Valine({
      el: '#vcomment',
      appId: 'K6YAjTUpfqvIIJRgat2mpicY-gzGzoHsz',
      appKey: 'TiK1kxcHhW26MWKdEgTtxWlm',
      placeholder: 'Please leave your footprints',
      avatar: 'monsterid',
      meta: 'nick,mail,link'.split(','),
      pageSize: '10',
      lang: 'en',
      recordIP: false,
      serverURLs: '',
      emojiCDN: '',
      emojiMaps: "",
      enableQQ: false,
      path: window.location.pathname,
    });
    if ('nick,mail') { valine.config.requiredFields= 'nick,mail'.split(',') }
  }

  if (typeof Valine === 'function') initValine() 
  else $.getScript('https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js', initValine)
}

if ('Valine' === 'Valine' || !true) {
  if (true) btf.loadComment(document.querySelector('#vcomment'),loadValine)
  else setTimeout(() => loadValine(), 0)
} else {
  function loadOtherComment () {
    loadValine()
  }
}</script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><canvas class="fireworks"></canvas><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="/js/third-party/fireworks.js"></script><script defer="defer" id="ribbon" src="/js/third-party/canvas-ribbon.js" size="150" alpha="0.6" zIndex="-1" mobile="true" data-click="true"></script><script defer="defer" id="ribbon_piao" mobile="true" src="/js/third-party/piao.js"></script><script src="/js/third-party/activate-power-mode.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = false;
document.body.addEventListener('input', POWERMODE);
</script><script src="/js/third-party/click_heart.js" async="async"></script><script src="/js/third-party/ClickShowText.js" async="async"></script><script>(function(d, w, c) {
    w.ChatraID = '';
    var s = d.createElement('script');
    w[c] = w[c] || function() {
        (w[c].q = w[c].q || []).push(arguments);
    };
    s.async = true;
    s.src = 'https://call.chatra.io/chatra.js';
    if (d.head) d.head.appendChild(s);
})(document, window, 'Chatra');

if (true) {
  var chatBtnFn = () => {
    var chatBtn = document.getElementById("chat_btn")
    chatBtn.addEventListener("click", function(){
      Chatra('openChat')
    });
  }
  chatBtnFn()
} else {
  if (true) {
    function chatBtnHide () {
      Chatra('hide')
    }
    function chatBtnShow () {
      Chatra('show')
    }
  }
}</script></div><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"model":{"jsonPath":"/live2dw/assets/koharu.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":true},"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body></html>